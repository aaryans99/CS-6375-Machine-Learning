{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaryans99/CS-6375-Machine-Learning/blob/main/Assignment%202/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6375 ML - Assignment 2**\n",
        "\n",
        "Aaryan Singh - axc230019\n",
        "\n",
        "Nikunj Gohil - ndg220000\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yY8usvnMhUjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Networks**\n",
        "\n",
        "---\n",
        "\n",
        "Dataset Information\n",
        "\n",
        "> The inputs are as follows\\\n",
        "X1=the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\\\n",
        "X2=the house age (unit: year)\\\n",
        "X3=the distance to the nearest MRT station (unit: meter)\\\n",
        "X4=the number of convenience stores in the living circle on foot (integer)\\\n",
        "X5=the geographic coordinate, latitude. (unit: degree)\\\n",
        "X6=the geographic coordinate, longitude. (unit: degree)\n",
        "\n",
        "The output is as follow\n",
        "Y= house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)\n",
        "\n",
        "1. Importing Libraries\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8r22kOulfrhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "ux2UcXlFkq0v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importing Dataset and Preprocessing"
      ],
      "metadata": {
        "id": "8ysdSg31lk_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/aaryans99/CS-6375-Machine-Learning/raw/main/Real%20estate%20valuation%20data%20set.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "H8Y8Yd7tlwMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c20c2de-3ad2-497c-d390-2cacfe1dbfc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 414 entries, 0 to 413\n",
            "Data columns (total 8 columns):\n",
            " #   Column                                  Non-Null Count  Dtype  \n",
            "---  ------                                  --------------  -----  \n",
            " 0   No                                      414 non-null    int64  \n",
            " 1   X1 transaction date                     414 non-null    float64\n",
            " 2   X2 house age                            414 non-null    float64\n",
            " 3   X3 distance to the nearest MRT station  414 non-null    float64\n",
            " 4   X4 number of convenience stores         414 non-null    int64  \n",
            " 5   X5 latitude                             414 non-null    float64\n",
            " 6   X6 longitude                            414 non-null    float64\n",
            " 7   Y house price of unit area              414 non-null    float64\n",
            "dtypes: float64(6), int64(2)\n",
            "memory usage: 26.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for null values\n",
        "df.isna().sum()\n",
        "# remove unwanted column\n",
        "df = df.drop(columns=[\"No\"], axis=1)"
      ],
      "metadata": {
        "id": "QdEKwwpVm8uL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert TWD per Ping to USD per square meter\n",
        "exchange_rate_TWD_to_USD = 0.031\n",
        "ping_to_square_meter = 3.3\n",
        "df['Y house price of unit area'] = (df['Y house price of unit area'] * exchange_rate_TWD_to_USD) / ping_to_square_meter"
      ],
      "metadata": {
        "id": "zwh9rdEPndQu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Heat Map\n",
        "corr_matrix = df.corr()\n",
        "plt.imshow(corr_matrix, cmap='viridis', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(len(corr_matrix.columns)), corr_matrix.columns, rotation='vertical')\n",
        "plt.yticks(np.arange(len(corr_matrix.columns)), corr_matrix.columns)\n",
        "plt.title('Correlation Plot')\n",
        "plt.show()\n",
        "M=corr_matrix\n",
        "M"
      ],
      "metadata": {
        "id": "ZGcTqb6OoZpq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3649019-70f8-48a9-f3c0-e67908e2db83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        X1 transaction date  X2 house age  \\\n",
              "X1 transaction date                                1.000000      0.017549   \n",
              "X2 house age                                       0.017549      1.000000   \n",
              "X3 distance to the nearest MRT station             0.060880      0.025622   \n",
              "X4 number of convenience stores                    0.009635      0.049593   \n",
              "X5 latitude                                        0.035058      0.054420   \n",
              "X6 longitude                                      -0.041082     -0.048520   \n",
              "Y house price of unit area                         0.087491     -0.210567   \n",
              "\n",
              "                                        X3 distance to the nearest MRT station  \\\n",
              "X1 transaction date                                                   0.060880   \n",
              "X2 house age                                                          0.025622   \n",
              "X3 distance to the nearest MRT station                                1.000000   \n",
              "X4 number of convenience stores                                      -0.602519   \n",
              "X5 latitude                                                          -0.591067   \n",
              "X6 longitude                                                         -0.806317   \n",
              "Y house price of unit area                                           -0.673613   \n",
              "\n",
              "                                        X4 number of convenience stores  \\\n",
              "X1 transaction date                                            0.009635   \n",
              "X2 house age                                                   0.049593   \n",
              "X3 distance to the nearest MRT station                        -0.602519   \n",
              "X4 number of convenience stores                                1.000000   \n",
              "X5 latitude                                                    0.444143   \n",
              "X6 longitude                                                   0.449099   \n",
              "Y house price of unit area                                     0.571005   \n",
              "\n",
              "                                        X5 latitude  X6 longitude  \\\n",
              "X1 transaction date                        0.035058     -0.041082   \n",
              "X2 house age                               0.054420     -0.048520   \n",
              "X3 distance to the nearest MRT station    -0.591067     -0.806317   \n",
              "X4 number of convenience stores            0.444143      0.449099   \n",
              "X5 latitude                                1.000000      0.412924   \n",
              "X6 longitude                               0.412924      1.000000   \n",
              "Y house price of unit area                 0.546307      0.523287   \n",
              "\n",
              "                                        Y house price of unit area  \n",
              "X1 transaction date                                       0.087491  \n",
              "X2 house age                                             -0.210567  \n",
              "X3 distance to the nearest MRT station                   -0.673613  \n",
              "X4 number of convenience stores                           0.571005  \n",
              "X5 latitude                                               0.546307  \n",
              "X6 longitude                                              0.523287  \n",
              "Y house price of unit area                                1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a19af530-16c1-4b53-8777-4a97bddcdcb9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1 transaction date</th>\n",
              "      <th>X2 house age</th>\n",
              "      <th>X3 distance to the nearest MRT station</th>\n",
              "      <th>X4 number of convenience stores</th>\n",
              "      <th>X5 latitude</th>\n",
              "      <th>X6 longitude</th>\n",
              "      <th>Y house price of unit area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X1 transaction date</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.017549</td>\n",
              "      <td>0.060880</td>\n",
              "      <td>0.009635</td>\n",
              "      <td>0.035058</td>\n",
              "      <td>-0.041082</td>\n",
              "      <td>0.087491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X2 house age</th>\n",
              "      <td>0.017549</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>0.049593</td>\n",
              "      <td>0.054420</td>\n",
              "      <td>-0.048520</td>\n",
              "      <td>-0.210567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X3 distance to the nearest MRT station</th>\n",
              "      <td>0.060880</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.602519</td>\n",
              "      <td>-0.591067</td>\n",
              "      <td>-0.806317</td>\n",
              "      <td>-0.673613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X4 number of convenience stores</th>\n",
              "      <td>0.009635</td>\n",
              "      <td>0.049593</td>\n",
              "      <td>-0.602519</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.444143</td>\n",
              "      <td>0.449099</td>\n",
              "      <td>0.571005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X5 latitude</th>\n",
              "      <td>0.035058</td>\n",
              "      <td>0.054420</td>\n",
              "      <td>-0.591067</td>\n",
              "      <td>0.444143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.412924</td>\n",
              "      <td>0.546307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X6 longitude</th>\n",
              "      <td>-0.041082</td>\n",
              "      <td>-0.048520</td>\n",
              "      <td>-0.806317</td>\n",
              "      <td>0.449099</td>\n",
              "      <td>0.412924</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.523287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y house price of unit area</th>\n",
              "      <td>0.087491</td>\n",
              "      <td>-0.210567</td>\n",
              "      <td>-0.673613</td>\n",
              "      <td>0.571005</td>\n",
              "      <td>0.546307</td>\n",
              "      <td>0.523287</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a19af530-16c1-4b53-8777-4a97bddcdcb9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a19af530-16c1-4b53-8777-4a97bddcdcb9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a19af530-16c1-4b53-8777-4a97bddcdcb9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0cc9ba3e-01ec-475c-969a-22b0c6725efa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0cc9ba3e-01ec-475c-969a-22b0c6725efa')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0cc9ba3e-01ec-475c-969a-22b0c6725efa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardizing the features by removing the mean and scaling to unit variance.\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)"
      ],
      "metadata": {
        "id": "g1NKOaeno_FH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   Splitting Data\n",
        "\n"
      ],
      "metadata": {
        "id": "4d8S92UrpIQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = scaled_df['Y house price of unit area']\n",
        "X = scaled_df[['X4 number of convenience stores', 'X5 latitude', 'X6 longitude']]\n",
        "scaled_df.info()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=90)\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(Y_train))\n",
        "print(\"\\nTesting Set:\")\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV2QqOlmpLiF",
        "outputId": "5f769fc9-d086-4d18-f3a3-99bf6a5a5b65"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 414 entries, 0 to 413\n",
            "Data columns (total 7 columns):\n",
            " #   Column                                  Non-Null Count  Dtype  \n",
            "---  ------                                  --------------  -----  \n",
            " 0   X1 transaction date                     414 non-null    float64\n",
            " 1   X2 house age                            414 non-null    float64\n",
            " 2   X3 distance to the nearest MRT station  414 non-null    float64\n",
            " 3   X4 number of convenience stores         414 non-null    float64\n",
            " 4   X5 latitude                             414 non-null    float64\n",
            " 5   X6 longitude                            414 non-null    float64\n",
            " 6   Y house price of unit area              414 non-null    float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 22.8 KB\n",
            "Training Set:\n",
            "(331, 3)\n",
            "(331,)\n",
            "\n",
            "Testing Set:\n",
            "(83, 3)\n",
            "(83,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Neural Net Creation\n",
        "*   Defining the activation functions, their derivatives and the loss function.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gXfgj0IlqrGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
        "  fx = sigmoid(x)\n",
        "  return fx * (1 - fx)\n",
        "\n",
        "def tanh(x):\n",
        "  # tanh activation function: f(x) = (e^(x) - e^(-x)) / (e^(x) + e^(-x))\n",
        "  return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "def deriv_tanh(x):\n",
        "  # Derivative of tanh: f'(x) = (1 - f(x)**2)\n",
        "  fx = tanh(x)\n",
        "  return (1 - (fx)**2)\n",
        "\n",
        "def reLu(x):\n",
        "  # ReLu activation function: f(x) = 0 if x <= 0 else x\n",
        "  return max(0, x)\n",
        "\n",
        "def deriv_reLu(x):\n",
        "  # Derivative of ReLu: f'(x) = 0 if x <= 0 else 1\n",
        "  return max(0, 1)\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "  # y_true and y_pred are numpy arrays of the same length.\n",
        "  return ((y_true - y_pred) ** 2).mean()"
      ],
      "metadata": {
        "id": "j-KixilG-HJC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Defining our Neural Network\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pwFzAeBwr8uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OurNeuralNetwork:\n",
        "  '''\n",
        "  A neural network with:\n",
        "    - 3 inputs\n",
        "    - a hidden layer with 2 neurons (h1, h2)\n",
        "    - an output layer with 1 neuron (o1)\n",
        "  '''\n",
        "  def __init__(self, act):\n",
        "    # Assigning activation function\n",
        "    if act == 'sigmoid':\n",
        "      self.act = sigmoid\n",
        "      self.deriv_act = deriv_sigmoid\n",
        "    elif act == 'tanh':\n",
        "      self.act = tanh\n",
        "      self.deriv_act = deriv_tanh\n",
        "    elif act == 'reLu':\n",
        "      self.act = reLu\n",
        "      self.deriv_act = deriv_reLu\n",
        "    else:\n",
        "      print(\"Invalid activation fuction\")\n",
        "      exit(1)\n",
        "\n",
        "    # Weights\n",
        "    # i/p -> hidden\n",
        "    self.w1 = np.random.normal()\n",
        "    self.w2 = np.random.normal()\n",
        "    self.w3 = np.random.normal()\n",
        "    self.w4 = np.random.normal()\n",
        "    self.w5 = np.random.normal()\n",
        "    self.w6 = np.random.normal()\n",
        "\n",
        "    # hidden -> o/p\n",
        "    self.w7 = np.random.normal()\n",
        "    self.w8 = np.random.normal()\n",
        "\n",
        "    # Biases\n",
        "    # i/p\n",
        "    self.b1 = np.random.normal()\n",
        "    self.b2 = np.random.normal()\n",
        "\n",
        "    # hidden\n",
        "    self.b3 = np.random.normal()\n",
        "\n",
        "    print(\"Weights:\", self.w1, self.w2, self.w3, self.w4, self.w5, self.w6, self.w7, self.w8)\n",
        "    print(\"Bias:\", self.b1, self.b2, self.b3)\n",
        "\n",
        "    # Forward pass\n",
        "  def feedforward(self, x):\n",
        "    # x is a numpy array with 2 elements.\n",
        "    h1 = self.act(self.w1 * x[0] + self.w2 * x[1] + self.w3 * x[2] + self.b1)\n",
        "    h2 = self.act(self.w4 * x[0] + self.w5 * x[1] + self.w6 * x[2] + self.b2)\n",
        "    o1 = self.act(self.w7 * h1 + self.w8 * h2 + self.b3)\n",
        "    return o1\n",
        "\n",
        "  def train(self, data, all_y_trues, learn_rate, epochs):\n",
        "    '''\n",
        "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
        "    - all_y_trues is a numpy array with n elements.\n",
        "      Elements in all_y_trues correspond to those in data.\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for x, y_true in zip(data, all_y_trues):\n",
        "        # --- Do a feedforward (we'll need these values later)\n",
        "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.w3 * x[2] + self.b1\n",
        "        h1 = self.act(sum_h1)\n",
        "\n",
        "        sum_h2 = self.w4 * x[0] + self.w5 * x[1] + self.w6 * x[2] + self.b2\n",
        "        h2 = self.act(sum_h2)\n",
        "\n",
        "        sum_o1 = self.w7 * h1 + self.w8 * h2 + self.b3\n",
        "        o1 = self.act(sum_o1)\n",
        "        y_pred = o1\n",
        "\n",
        "        # --- Calculate partial derivatives.\n",
        "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
        "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
        "\n",
        "        # Neuron o1\n",
        "        d_ypred_d_w7 = h1 * self.deriv_act(sum_o1)\n",
        "        d_ypred_d_w8 = h2 * self.deriv_act(sum_o1)\n",
        "        d_ypred_d_b3 = self.deriv_act(sum_o1)\n",
        "\n",
        "        d_ypred_d_h1 = self.w7 * self.deriv_act(sum_o1)\n",
        "        d_ypred_d_h2 = self.w8 * self.deriv_act(sum_o1)\n",
        "\n",
        "        # Neuron h1\n",
        "        d_h1_d_w1 = x[0] * self.deriv_act(sum_h1)\n",
        "        d_h1_d_w2 = x[1] * self.deriv_act(sum_h1)\n",
        "        d_h1_d_w3 = x[2] * self.deriv_act(sum_h1)\n",
        "        d_h1_d_b1 = self.deriv_act(sum_h1)\n",
        "\n",
        "        # Neuron h2\n",
        "        d_h2_d_w4 = x[0] * self.deriv_act(sum_h2)\n",
        "        d_h2_d_w5 = x[1] * self.deriv_act(sum_h2)\n",
        "        d_h2_d_w6 = x[2] * self.deriv_act(sum_h2)\n",
        "        d_h2_d_b2 = self.deriv_act(sum_h2)\n",
        "\n",
        "        # --- Update weights and biases\n",
        "        # Neuron h1\n",
        "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
        "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
        "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
        "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
        "\n",
        "        # Neuron h2\n",
        "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
        "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
        "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6\n",
        "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
        "\n",
        "        # Neuron o1\n",
        "        self.w7 -= learn_rate * d_L_d_ypred * d_ypred_d_w7\n",
        "        self.w8 -= learn_rate * d_L_d_ypred * d_ypred_d_w8\n",
        "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
        "\n",
        "      # --- Calculate total loss at the end of each epoch\n",
        "      if epoch % 10 == 0:\n",
        "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
        "        loss = mse_loss(all_y_trues, y_preds)\n",
        "        r2_loss = r2_score(y_preds, all_y_trues)\n",
        "        print(\"Epoch %d loss: %.3f r2: %.3f\" % (epoch, loss, r2_loss))\n",
        "\n",
        "    return [self.w1, self.w2, self.w3, self.w4, self.w5, self.w6, self.w7, self.w8, self.b1, self.b2, self.b3]\n",
        "\n",
        "  def train_relu(self, data, all_y_trues, learn_rate, epochs):\n",
        "    '''\n",
        "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
        "    - all_y_trues is a numpy array with n elements.\n",
        "      Elements in all_y_trues correspond to those in data.\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for x, y_true in zip(data, all_y_trues):\n",
        "        # --- Do a feedforward (we'll need these values later)\n",
        "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.w3 * x[2] + self.b1\n",
        "        h1 = self.act(sum_h1)\n",
        "\n",
        "        sum_h2 = self.w4 * x[0] + self.w5 * x[1] + self.w6 * x[2] + self.b2\n",
        "        h2 = self.act(sum_h2)\n",
        "\n",
        "        sum_o1 = self.w7 * h1 + self.w8 * h2 + self.b3\n",
        "        o1 = sum_o1\n",
        "        y_pred = o1\n",
        "\n",
        "        # --- Calculate partial derivatives.\n",
        "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
        "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
        "\n",
        "        # Neuron o1\n",
        "        d_ypred_d_w7 = h1 * self.deriv_act(sum_o1)\n",
        "        d_ypred_d_w8 = h2 * self.deriv_act(sum_o1)\n",
        "        d_ypred_d_b3 = self.deriv_act(sum_o1)\n",
        "\n",
        "        d_ypred_d_h1 = self.w7 * self.deriv_act(sum_o1)\n",
        "        d_ypred_d_h2 = self.w8 * self.deriv_act(sum_o1)\n",
        "\n",
        "        # Neuron h1\n",
        "        d_h1_d_w1 = x[0] * self.deriv_act(sum_h1)\n",
        "        d_h1_d_w2 = x[1] * self.deriv_act(sum_h1)\n",
        "        d_h1_d_w3 = x[2] * self.deriv_act(sum_h1)\n",
        "        d_h1_d_b1 = self.deriv_act(sum_h1)\n",
        "\n",
        "        # Neuron h2\n",
        "        d_h2_d_w4 = x[0] * self.deriv_act(sum_h2)\n",
        "        d_h2_d_w5 = x[1] * self.deriv_act(sum_h2)\n",
        "        d_h2_d_w6 = x[2] * self.deriv_act(sum_h2)\n",
        "        d_h2_d_b2 = self.deriv_act(sum_h2)\n",
        "\n",
        "        # --- Update weights and biases\n",
        "        # Neuron h1\n",
        "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
        "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
        "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
        "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
        "\n",
        "        # Neuron h2\n",
        "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
        "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
        "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6\n",
        "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
        "\n",
        "        # Neuron o1\n",
        "        self.w7 -= learn_rate * d_L_d_ypred * d_ypred_d_w7\n",
        "        self.w8 -= learn_rate * d_L_d_ypred * d_ypred_d_w8\n",
        "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
        "\n",
        "      # --- Calculate total loss at the end of each epoch\n",
        "      if epoch % 10 == 0:\n",
        "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
        "        loss = mse_loss(all_y_trues, y_preds)\n",
        "        r2_loss = r2_score(y_preds, all_y_trues)\n",
        "        print(\"Epoch %d loss: %.3f r2: %.3f\" % (epoch, loss, r2_loss))\n",
        "\n",
        "    return [self.w1, self.w2, self.w3, self.w4, self.w5, self.w6, self.w7, self.w8, self.b1, self.b2, self.b3]\n",
        "\n",
        "  def test(self, data, all_y_trues, w):\n",
        "    self.w1 = w[0]\n",
        "    self.w2 = w[1]\n",
        "    self.w3 = w[2]\n",
        "    self.w4 = w[3]\n",
        "    self.w5 = w[4]\n",
        "    self.w6 = w[5]\n",
        "    self.w7 = w[6]\n",
        "    self.w8 = w[7]\n",
        "    self.b1 = w[8]\n",
        "    self.b2 = w[9]\n",
        "    self.b3 = w[10]\n",
        "    y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
        "    loss = mse_loss(all_y_trues, y_preds)\n",
        "    r2_loss = r2_score(y_preds, all_y_trues)\n",
        "    print(\"Test loss: %.3f, r2: %.3f\" % (loss, r2_loss))"
      ],
      "metadata": {
        "id": "SDt5IYY5r_K-"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Training neural network with different activation functions\n",
        "\n"
      ],
      "metadata": {
        "id": "UGit1ljssZPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = OurNeuralNetwork('sigmoid')\n",
        "for i in range(1,100,10):\n",
        "  weights = network.train(np.array(X_train), np.array(Y_train),i/100,1000)\n",
        "  print(\"Weights:\", weights[:8])\n",
        "  print(\"Bias:\",weights[8:])\n",
        "  print(\"Loss for test dataset\")\n",
        "  network.test(np.array(X_test), np.array(Y_test), weights)\n",
        "  print(\"Loss for training dataset\")\n",
        "  network.test(np.array(X_train), np.array(Y_train), weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndiH2JV0se77",
        "outputId": "02f47202-ac1c-488b-b194-f5c65c4b2ae9"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: -0.9469265993874116 0.35881192172430265 -0.46495863291245665 -1.2916618876746917 0.02039992346110446 0.186747412622391 0.43228268154289357 -0.2464373459881748\n",
            "Bias: -0.3272646950942305 -0.15450323940218155 -1.0809993861323859\n",
            "Epoch 0 loss: 1.048 r2: -5069.873\n",
            "Epoch 10 loss: 0.975 r2: -314.121\n",
            "Epoch 20 loss: 0.919 r2: -52.616\n",
            "Epoch 30 loss: 0.883 r2: -20.894\n",
            "Epoch 40 loss: 0.869 r2: -14.715\n",
            "Epoch 50 loss: 0.863 r2: -12.516\n",
            "Epoch 60 loss: 0.860 r2: -11.438\n",
            "Epoch 70 loss: 0.858 r2: -10.803\n",
            "Epoch 80 loss: 0.856 r2: -10.382\n",
            "Epoch 90 loss: 0.855 r2: -10.077\n",
            "Epoch 100 loss: 0.854 r2: -9.843\n",
            "Epoch 110 loss: 0.854 r2: -9.653\n",
            "Epoch 120 loss: 0.853 r2: -9.497\n",
            "Epoch 130 loss: 0.853 r2: -9.366\n",
            "Epoch 140 loss: 0.852 r2: -9.256\n",
            "Epoch 150 loss: 0.852 r2: -9.163\n",
            "Epoch 160 loss: 0.851 r2: -9.084\n",
            "Epoch 170 loss: 0.851 r2: -9.018\n",
            "Epoch 180 loss: 0.850 r2: -8.962\n",
            "Epoch 190 loss: 0.850 r2: -8.916\n",
            "Epoch 200 loss: 0.849 r2: -8.877\n",
            "Epoch 210 loss: 0.849 r2: -8.845\n",
            "Epoch 220 loss: 0.848 r2: -8.820\n",
            "Epoch 230 loss: 0.848 r2: -8.800\n",
            "Epoch 240 loss: 0.847 r2: -8.784\n",
            "Epoch 250 loss: 0.847 r2: -8.771\n",
            "Epoch 260 loss: 0.846 r2: -8.761\n",
            "Epoch 270 loss: 0.845 r2: -8.751\n",
            "Epoch 280 loss: 0.845 r2: -8.739\n",
            "Epoch 290 loss: 0.844 r2: -8.723\n",
            "Epoch 300 loss: 0.843 r2: -8.701\n",
            "Epoch 310 loss: 0.842 r2: -8.671\n",
            "Epoch 320 loss: 0.842 r2: -8.632\n",
            "Epoch 330 loss: 0.841 r2: -8.585\n",
            "Epoch 340 loss: 0.840 r2: -8.531\n",
            "Epoch 350 loss: 0.840 r2: -8.472\n",
            "Epoch 360 loss: 0.839 r2: -8.409\n",
            "Epoch 370 loss: 0.839 r2: -8.344\n",
            "Epoch 380 loss: 0.838 r2: -8.280\n",
            "Epoch 390 loss: 0.838 r2: -8.216\n",
            "Epoch 400 loss: 0.837 r2: -8.154\n",
            "Epoch 410 loss: 0.837 r2: -8.095\n",
            "Epoch 420 loss: 0.836 r2: -8.038\n",
            "Epoch 430 loss: 0.836 r2: -7.984\n",
            "Epoch 440 loss: 0.835 r2: -7.933\n",
            "Epoch 450 loss: 0.835 r2: -7.885\n",
            "Epoch 460 loss: 0.835 r2: -7.839\n",
            "Epoch 470 loss: 0.834 r2: -7.796\n",
            "Epoch 480 loss: 0.834 r2: -7.756\n",
            "Epoch 490 loss: 0.834 r2: -7.717\n",
            "Epoch 500 loss: 0.834 r2: -7.681\n",
            "Epoch 510 loss: 0.833 r2: -7.647\n",
            "Epoch 520 loss: 0.833 r2: -7.615\n",
            "Epoch 530 loss: 0.833 r2: -7.585\n",
            "Epoch 540 loss: 0.833 r2: -7.556\n",
            "Epoch 550 loss: 0.832 r2: -7.529\n",
            "Epoch 560 loss: 0.832 r2: -7.503\n",
            "Epoch 570 loss: 0.832 r2: -7.478\n",
            "Epoch 580 loss: 0.832 r2: -7.455\n",
            "Epoch 590 loss: 0.832 r2: -7.432\n",
            "Epoch 600 loss: 0.831 r2: -7.411\n",
            "Epoch 610 loss: 0.831 r2: -7.390\n",
            "Epoch 620 loss: 0.831 r2: -7.371\n",
            "Epoch 630 loss: 0.831 r2: -7.352\n",
            "Epoch 640 loss: 0.831 r2: -7.333\n",
            "Epoch 650 loss: 0.831 r2: -7.316\n",
            "Epoch 660 loss: 0.831 r2: -7.299\n",
            "Epoch 670 loss: 0.830 r2: -7.282\n",
            "Epoch 680 loss: 0.830 r2: -7.267\n",
            "Epoch 690 loss: 0.830 r2: -7.251\n",
            "Epoch 700 loss: 0.830 r2: -7.236\n",
            "Epoch 710 loss: 0.830 r2: -7.222\n",
            "Epoch 720 loss: 0.830 r2: -7.207\n",
            "Epoch 730 loss: 0.830 r2: -7.193\n",
            "Epoch 740 loss: 0.830 r2: -7.180\n",
            "Epoch 750 loss: 0.829 r2: -7.167\n",
            "Epoch 760 loss: 0.829 r2: -7.154\n",
            "Epoch 770 loss: 0.829 r2: -7.141\n",
            "Epoch 780 loss: 0.829 r2: -7.129\n",
            "Epoch 790 loss: 0.829 r2: -7.116\n",
            "Epoch 800 loss: 0.829 r2: -7.104\n",
            "Epoch 810 loss: 0.829 r2: -7.093\n",
            "Epoch 820 loss: 0.829 r2: -7.081\n",
            "Epoch 830 loss: 0.829 r2: -7.070\n",
            "Epoch 840 loss: 0.828 r2: -7.058\n",
            "Epoch 850 loss: 0.828 r2: -7.047\n",
            "Epoch 860 loss: 0.828 r2: -7.036\n",
            "Epoch 870 loss: 0.828 r2: -7.026\n",
            "Epoch 880 loss: 0.828 r2: -7.015\n",
            "Epoch 890 loss: 0.828 r2: -7.005\n",
            "Epoch 900 loss: 0.828 r2: -6.994\n",
            "Epoch 910 loss: 0.828 r2: -6.984\n",
            "Epoch 920 loss: 0.828 r2: -6.974\n",
            "Epoch 930 loss: 0.828 r2: -6.964\n",
            "Epoch 940 loss: 0.828 r2: -6.955\n",
            "Epoch 950 loss: 0.827 r2: -6.945\n",
            "Epoch 960 loss: 0.827 r2: -6.935\n",
            "Epoch 970 loss: 0.827 r2: -6.926\n",
            "Epoch 980 loss: 0.827 r2: -6.917\n",
            "Epoch 990 loss: 0.827 r2: -6.908\n",
            "Weights: [-0.9422485219346095, 1.2332349253886192, -5.899695666362884, -3.0734670143305354, -2.8013051501993886, 1.3831933984998679, -6.1645919385048895, -7.442892883586996]\n",
            "Bias: [0.9595160373660648, -1.4701221901260146, 1.5585240172652368]\n",
            "Loss for test dataset\n",
            "Test loss: 0.618, r2: -4.330\n",
            "Loss for training dataset\n",
            "Test loss: 0.827, r2: -6.900\n",
            "Epoch 0 loss: 0.827 r2: -6.738\n",
            "Epoch 10 loss: 0.826 r2: -6.736\n",
            "Epoch 20 loss: 0.826 r2: -6.668\n",
            "Epoch 30 loss: 0.825 r2: -6.591\n",
            "Epoch 40 loss: 0.824 r2: -6.513\n",
            "Epoch 50 loss: 0.823 r2: -6.436\n",
            "Epoch 60 loss: 0.822 r2: -6.361\n",
            "Epoch 70 loss: 0.821 r2: -6.290\n",
            "Epoch 80 loss: 0.820 r2: -6.222\n",
            "Epoch 90 loss: 0.819 r2: -6.161\n",
            "Epoch 100 loss: 0.818 r2: -6.113\n",
            "Epoch 110 loss: 0.817 r2: -6.070\n",
            "Epoch 120 loss: 0.813 r2: -5.983\n",
            "Epoch 130 loss: 0.809 r2: -5.723\n",
            "Epoch 140 loss: 0.806 r2: -5.480\n",
            "Epoch 150 loss: 0.804 r2: -5.307\n",
            "Epoch 160 loss: 0.802 r2: -5.178\n",
            "Epoch 170 loss: 0.800 r2: -5.073\n",
            "Epoch 180 loss: 0.799 r2: -4.985\n",
            "Epoch 190 loss: 0.798 r2: -4.908\n",
            "Epoch 200 loss: 0.797 r2: -4.840\n",
            "Epoch 210 loss: 0.796 r2: -4.781\n",
            "Epoch 220 loss: 0.795 r2: -4.730\n",
            "Epoch 230 loss: 0.795 r2: -4.684\n",
            "Epoch 240 loss: 0.794 r2: -4.645\n",
            "Epoch 250 loss: 0.794 r2: -4.610\n",
            "Epoch 260 loss: 0.793 r2: -4.580\n",
            "Epoch 270 loss: 0.793 r2: -4.554\n",
            "Epoch 280 loss: 0.793 r2: -4.531\n",
            "Epoch 290 loss: 0.792 r2: -4.510\n",
            "Epoch 300 loss: 0.792 r2: -4.493\n",
            "Epoch 310 loss: 0.792 r2: -4.477\n",
            "Epoch 320 loss: 0.792 r2: -4.463\n",
            "Epoch 330 loss: 0.791 r2: -4.451\n",
            "Epoch 340 loss: 0.791 r2: -4.440\n",
            "Epoch 350 loss: 0.791 r2: -4.431\n",
            "Epoch 360 loss: 0.791 r2: -4.422\n",
            "Epoch 370 loss: 0.791 r2: -4.414\n",
            "Epoch 380 loss: 0.791 r2: -4.407\n",
            "Epoch 390 loss: 0.790 r2: -4.401\n",
            "Epoch 400 loss: 0.790 r2: -4.395\n",
            "Epoch 410 loss: 0.790 r2: -4.390\n",
            "Epoch 420 loss: 0.790 r2: -4.385\n",
            "Epoch 430 loss: 0.790 r2: -4.380\n",
            "Epoch 440 loss: 0.790 r2: -4.376\n",
            "Epoch 450 loss: 0.790 r2: -4.372\n",
            "Epoch 460 loss: 0.790 r2: -4.368\n",
            "Epoch 470 loss: 0.789 r2: -4.365\n",
            "Epoch 480 loss: 0.789 r2: -4.361\n",
            "Epoch 490 loss: 0.789 r2: -4.358\n",
            "Epoch 500 loss: 0.789 r2: -4.355\n",
            "Epoch 510 loss: 0.789 r2: -4.352\n",
            "Epoch 520 loss: 0.789 r2: -4.349\n",
            "Epoch 530 loss: 0.789 r2: -4.347\n",
            "Epoch 540 loss: 0.789 r2: -4.344\n",
            "Epoch 550 loss: 0.789 r2: -4.342\n",
            "Epoch 560 loss: 0.789 r2: -4.339\n",
            "Epoch 570 loss: 0.788 r2: -4.337\n",
            "Epoch 580 loss: 0.788 r2: -4.334\n",
            "Epoch 590 loss: 0.788 r2: -4.332\n",
            "Epoch 600 loss: 0.788 r2: -4.330\n",
            "Epoch 610 loss: 0.788 r2: -4.328\n",
            "Epoch 620 loss: 0.788 r2: -4.325\n",
            "Epoch 630 loss: 0.788 r2: -4.323\n",
            "Epoch 640 loss: 0.788 r2: -4.321\n",
            "Epoch 650 loss: 0.788 r2: -4.319\n",
            "Epoch 660 loss: 0.788 r2: -4.317\n",
            "Epoch 670 loss: 0.788 r2: -4.315\n",
            "Epoch 680 loss: 0.788 r2: -4.313\n",
            "Epoch 690 loss: 0.788 r2: -4.311\n",
            "Epoch 700 loss: 0.788 r2: -4.309\n",
            "Epoch 710 loss: 0.788 r2: -4.307\n",
            "Epoch 720 loss: 0.787 r2: -4.305\n",
            "Epoch 730 loss: 0.787 r2: -4.303\n",
            "Epoch 740 loss: 0.787 r2: -4.301\n",
            "Epoch 750 loss: 0.787 r2: -4.299\n",
            "Epoch 760 loss: 0.787 r2: -4.297\n",
            "Epoch 770 loss: 0.787 r2: -4.295\n",
            "Epoch 780 loss: 0.787 r2: -4.293\n",
            "Epoch 790 loss: 0.787 r2: -4.291\n",
            "Epoch 800 loss: 0.787 r2: -4.289\n",
            "Epoch 810 loss: 0.787 r2: -4.287\n",
            "Epoch 820 loss: 0.787 r2: -4.285\n",
            "Epoch 830 loss: 0.787 r2: -4.283\n",
            "Epoch 840 loss: 0.787 r2: -4.281\n",
            "Epoch 850 loss: 0.787 r2: -4.279\n",
            "Epoch 860 loss: 0.787 r2: -4.277\n",
            "Epoch 870 loss: 0.787 r2: -4.275\n",
            "Epoch 880 loss: 0.787 r2: -4.273\n",
            "Epoch 890 loss: 0.787 r2: -4.271\n",
            "Epoch 900 loss: 0.787 r2: -4.269\n",
            "Epoch 910 loss: 0.787 r2: -4.267\n",
            "Epoch 920 loss: 0.787 r2: -4.265\n",
            "Epoch 930 loss: 0.786 r2: -4.263\n",
            "Epoch 940 loss: 0.786 r2: -4.261\n",
            "Epoch 950 loss: 0.786 r2: -4.259\n",
            "Epoch 960 loss: 0.786 r2: -4.257\n",
            "Epoch 970 loss: 0.786 r2: -4.255\n",
            "Epoch 980 loss: 0.786 r2: -4.253\n",
            "Epoch 990 loss: 0.786 r2: -4.251\n",
            "Weights: [-3.5858920906168006, 2.0196267675313173, -15.583506974410822, 1.2512199804294357, -7.170518036033508, 19.715337822734654, -11.428572349748174, -13.836466061136635]\n",
            "Bias: [7.5529615409049295, -16.002363521716614, 3.070932206295834]\n",
            "Loss for test dataset\n",
            "Test loss: 0.605, r2: -2.638\n",
            "Loss for training dataset\n",
            "Test loss: 0.786, r2: -4.250\n",
            "Epoch 0 loss: 0.790 r2: -3.919\n",
            "Epoch 10 loss: 0.790 r2: -4.050\n",
            "Epoch 20 loss: 0.790 r2: -4.079\n",
            "Epoch 30 loss: 0.790 r2: -4.080\n",
            "Epoch 40 loss: 0.790 r2: -4.079\n",
            "Epoch 50 loss: 0.790 r2: -4.076\n",
            "Epoch 60 loss: 0.790 r2: -4.074\n",
            "Epoch 70 loss: 0.790 r2: -4.072\n",
            "Epoch 80 loss: 0.790 r2: -4.070\n",
            "Epoch 90 loss: 0.790 r2: -4.068\n",
            "Epoch 100 loss: 0.790 r2: -4.067\n",
            "Epoch 110 loss: 0.789 r2: -4.065\n",
            "Epoch 120 loss: 0.789 r2: -4.063\n",
            "Epoch 130 loss: 0.789 r2: -4.062\n",
            "Epoch 140 loss: 0.789 r2: -4.060\n",
            "Epoch 150 loss: 0.789 r2: -4.059\n",
            "Epoch 160 loss: 0.789 r2: -4.058\n",
            "Epoch 170 loss: 0.789 r2: -4.056\n",
            "Epoch 180 loss: 0.789 r2: -4.055\n",
            "Epoch 190 loss: 0.789 r2: -4.054\n",
            "Epoch 200 loss: 0.789 r2: -4.053\n",
            "Epoch 210 loss: 0.789 r2: -4.052\n",
            "Epoch 220 loss: 0.789 r2: -4.051\n",
            "Epoch 230 loss: 0.788 r2: -4.050\n",
            "Epoch 240 loss: 0.788 r2: -4.049\n",
            "Epoch 250 loss: 0.788 r2: -4.048\n",
            "Epoch 260 loss: 0.788 r2: -4.048\n",
            "Epoch 270 loss: 0.788 r2: -4.047\n",
            "Epoch 280 loss: 0.788 r2: -4.046\n",
            "Epoch 290 loss: 0.788 r2: -4.046\n",
            "Epoch 300 loss: 0.788 r2: -4.045\n",
            "Epoch 310 loss: 0.788 r2: -4.045\n",
            "Epoch 320 loss: 0.788 r2: -4.044\n",
            "Epoch 330 loss: 0.788 r2: -4.044\n",
            "Epoch 340 loss: 0.788 r2: -4.043\n",
            "Epoch 350 loss: 0.788 r2: -4.043\n",
            "Epoch 360 loss: 0.788 r2: -4.043\n",
            "Epoch 370 loss: 0.787 r2: -4.042\n",
            "Epoch 380 loss: 0.787 r2: -4.042\n",
            "Epoch 390 loss: 0.787 r2: -4.042\n",
            "Epoch 400 loss: 0.787 r2: -4.042\n",
            "Epoch 410 loss: 0.787 r2: -4.042\n",
            "Epoch 420 loss: 0.787 r2: -4.042\n",
            "Epoch 430 loss: 0.787 r2: -4.041\n",
            "Epoch 440 loss: 0.787 r2: -4.041\n",
            "Epoch 450 loss: 0.787 r2: -4.041\n",
            "Epoch 460 loss: 0.787 r2: -4.041\n",
            "Epoch 470 loss: 0.787 r2: -4.041\n",
            "Epoch 480 loss: 0.787 r2: -4.041\n",
            "Epoch 490 loss: 0.787 r2: -4.041\n",
            "Epoch 500 loss: 0.787 r2: -4.041\n",
            "Epoch 510 loss: 0.787 r2: -4.040\n",
            "Epoch 520 loss: 0.787 r2: -4.040\n",
            "Epoch 530 loss: 0.786 r2: -4.040\n",
            "Epoch 540 loss: 0.786 r2: -4.039\n",
            "Epoch 550 loss: 0.786 r2: -4.039\n",
            "Epoch 560 loss: 0.786 r2: -4.038\n",
            "Epoch 570 loss: 0.786 r2: -4.038\n",
            "Epoch 580 loss: 0.786 r2: -4.037\n",
            "Epoch 590 loss: 0.786 r2: -4.036\n",
            "Epoch 600 loss: 0.786 r2: -4.035\n",
            "Epoch 610 loss: 0.786 r2: -4.033\n",
            "Epoch 620 loss: 0.786 r2: -4.032\n",
            "Epoch 630 loss: 0.786 r2: -4.030\n",
            "Epoch 640 loss: 0.786 r2: -4.028\n",
            "Epoch 650 loss: 0.786 r2: -4.027\n",
            "Epoch 660 loss: 0.786 r2: -4.024\n",
            "Epoch 670 loss: 0.786 r2: -4.022\n",
            "Epoch 680 loss: 0.786 r2: -4.020\n",
            "Epoch 690 loss: 0.786 r2: -4.017\n",
            "Epoch 700 loss: 0.786 r2: -4.015\n",
            "Epoch 710 loss: 0.786 r2: -4.012\n",
            "Epoch 720 loss: 0.786 r2: -4.009\n",
            "Epoch 730 loss: 0.786 r2: -4.006\n",
            "Epoch 740 loss: 0.786 r2: -4.003\n",
            "Epoch 750 loss: 0.786 r2: -4.000\n",
            "Epoch 760 loss: 0.786 r2: -3.997\n",
            "Epoch 770 loss: 0.786 r2: -3.993\n",
            "Epoch 780 loss: 0.786 r2: -3.990\n",
            "Epoch 790 loss: 0.786 r2: -3.987\n",
            "Epoch 800 loss: 0.786 r2: -3.983\n",
            "Epoch 810 loss: 0.786 r2: -3.980\n",
            "Epoch 820 loss: 0.786 r2: -3.976\n",
            "Epoch 830 loss: 0.786 r2: -3.973\n",
            "Epoch 840 loss: 0.786 r2: -3.969\n",
            "Epoch 850 loss: 0.786 r2: -3.966\n",
            "Epoch 860 loss: 0.786 r2: -3.962\n",
            "Epoch 870 loss: 0.786 r2: -3.959\n",
            "Epoch 880 loss: 0.786 r2: -3.955\n",
            "Epoch 890 loss: 0.786 r2: -3.952\n",
            "Epoch 900 loss: 0.786 r2: -3.948\n",
            "Epoch 910 loss: 0.786 r2: -3.945\n",
            "Epoch 920 loss: 0.786 r2: -3.941\n",
            "Epoch 930 loss: 0.786 r2: -3.938\n",
            "Epoch 940 loss: 0.786 r2: -3.934\n",
            "Epoch 950 loss: 0.786 r2: -3.931\n",
            "Epoch 960 loss: 0.786 r2: -3.928\n",
            "Epoch 970 loss: 0.786 r2: -3.924\n",
            "Epoch 980 loss: 0.786 r2: -3.921\n",
            "Epoch 990 loss: 0.786 r2: -3.918\n",
            "Weights: [-6.366974074900695, 3.4420399562830295, -26.6483675670558, 1.9597588918274942, -10.727853871849293, 28.543905520368224, -11.56024244166763, -14.7994277402771]\n",
            "Bias: [13.604288861791414, -22.917597146411836, 2.7123689280268777]\n",
            "Loss for test dataset\n",
            "Test loss: 0.611, r2: -2.512\n",
            "Loss for training dataset\n",
            "Test loss: 0.786, r2: -3.915\n",
            "Epoch 0 loss: 0.790 r2: -3.766\n",
            "Epoch 10 loss: 0.787 r2: -3.918\n",
            "Epoch 20 loss: 0.787 r2: -3.929\n",
            "Epoch 30 loss: 0.787 r2: -3.931\n",
            "Epoch 40 loss: 0.787 r2: -3.929\n",
            "Epoch 50 loss: 0.787 r2: -3.927\n",
            "Epoch 60 loss: 0.787 r2: -3.924\n",
            "Epoch 70 loss: 0.787 r2: -3.921\n",
            "Epoch 80 loss: 0.787 r2: -3.917\n",
            "Epoch 90 loss: 0.787 r2: -3.914\n",
            "Epoch 100 loss: 0.788 r2: -3.910\n",
            "Epoch 110 loss: 0.788 r2: -3.906\n",
            "Epoch 120 loss: 0.788 r2: -3.902\n",
            "Epoch 130 loss: 0.788 r2: -3.898\n",
            "Epoch 140 loss: 0.788 r2: -3.894\n",
            "Epoch 150 loss: 0.788 r2: -3.890\n",
            "Epoch 160 loss: 0.788 r2: -3.885\n",
            "Epoch 170 loss: 0.789 r2: -3.879\n",
            "Epoch 180 loss: 0.789 r2: -3.874\n",
            "Epoch 190 loss: 0.789 r2: -3.868\n",
            "Epoch 200 loss: 0.789 r2: -3.863\n",
            "Epoch 210 loss: 0.789 r2: -3.858\n",
            "Epoch 220 loss: 0.789 r2: -3.854\n",
            "Epoch 230 loss: 0.789 r2: -3.849\n",
            "Epoch 240 loss: 0.790 r2: -3.845\n",
            "Epoch 250 loss: 0.790 r2: -3.841\n",
            "Epoch 260 loss: 0.790 r2: -3.836\n",
            "Epoch 270 loss: 0.790 r2: -3.832\n",
            "Epoch 280 loss: 0.790 r2: -3.828\n",
            "Epoch 290 loss: 0.790 r2: -3.823\n",
            "Epoch 300 loss: 0.790 r2: -3.819\n",
            "Epoch 310 loss: 0.790 r2: -3.815\n",
            "Epoch 320 loss: 0.790 r2: -3.811\n",
            "Epoch 330 loss: 0.790 r2: -3.807\n",
            "Epoch 340 loss: 0.790 r2: -3.803\n",
            "Epoch 350 loss: 0.790 r2: -3.799\n",
            "Epoch 360 loss: 0.790 r2: -3.795\n",
            "Epoch 370 loss: 0.790 r2: -3.791\n",
            "Epoch 380 loss: 0.790 r2: -3.787\n",
            "Epoch 390 loss: 0.790 r2: -3.784\n",
            "Epoch 400 loss: 0.789 r2: -3.780\n",
            "Epoch 410 loss: 0.789 r2: -3.777\n",
            "Epoch 420 loss: 0.789 r2: -3.774\n",
            "Epoch 430 loss: 0.789 r2: -3.770\n",
            "Epoch 440 loss: 0.789 r2: -3.767\n",
            "Epoch 450 loss: 0.789 r2: -3.764\n",
            "Epoch 460 loss: 0.789 r2: -3.761\n",
            "Epoch 470 loss: 0.789 r2: -3.758\n",
            "Epoch 480 loss: 0.789 r2: -3.756\n",
            "Epoch 490 loss: 0.789 r2: -3.753\n",
            "Epoch 500 loss: 0.789 r2: -3.751\n",
            "Epoch 510 loss: 0.789 r2: -3.748\n",
            "Epoch 520 loss: 0.789 r2: -3.746\n",
            "Epoch 530 loss: 0.789 r2: -3.744\n",
            "Epoch 540 loss: 0.789 r2: -3.742\n",
            "Epoch 550 loss: 0.789 r2: -3.740\n",
            "Epoch 560 loss: 0.789 r2: -3.739\n",
            "Epoch 570 loss: 0.789 r2: -3.737\n",
            "Epoch 580 loss: 0.789 r2: -3.735\n",
            "Epoch 590 loss: 0.788 r2: -3.734\n",
            "Epoch 600 loss: 0.788 r2: -3.733\n",
            "Epoch 610 loss: 0.788 r2: -3.732\n",
            "Epoch 620 loss: 0.788 r2: -3.731\n",
            "Epoch 630 loss: 0.788 r2: -3.730\n",
            "Epoch 640 loss: 0.788 r2: -3.729\n",
            "Epoch 650 loss: 0.788 r2: -3.730\n",
            "Epoch 660 loss: 0.787 r2: -3.731\n",
            "Epoch 670 loss: 0.786 r2: -3.735\n",
            "Epoch 680 loss: 0.786 r2: -3.742\n",
            "Epoch 690 loss: 0.786 r2: -3.746\n",
            "Epoch 700 loss: 0.786 r2: -3.746\n",
            "Epoch 710 loss: 0.786 r2: -3.745\n",
            "Epoch 720 loss: 0.786 r2: -3.744\n",
            "Epoch 730 loss: 0.786 r2: -3.743\n",
            "Epoch 740 loss: 0.786 r2: -3.742\n",
            "Epoch 750 loss: 0.785 r2: -3.741\n",
            "Epoch 760 loss: 0.785 r2: -3.740\n",
            "Epoch 770 loss: 0.785 r2: -3.739\n",
            "Epoch 780 loss: 0.785 r2: -3.738\n",
            "Epoch 790 loss: 0.785 r2: -3.736\n",
            "Epoch 800 loss: 0.785 r2: -3.735\n",
            "Epoch 810 loss: 0.785 r2: -3.734\n",
            "Epoch 820 loss: 0.785 r2: -3.733\n",
            "Epoch 830 loss: 0.785 r2: -3.731\n",
            "Epoch 840 loss: 0.785 r2: -3.730\n",
            "Epoch 850 loss: 0.785 r2: -3.729\n",
            "Epoch 860 loss: 0.785 r2: -3.728\n",
            "Epoch 870 loss: 0.785 r2: -3.726\n",
            "Epoch 880 loss: 0.785 r2: -3.725\n",
            "Epoch 890 loss: 0.785 r2: -3.724\n",
            "Epoch 900 loss: 0.785 r2: -3.722\n",
            "Epoch 910 loss: 0.785 r2: -3.721\n",
            "Epoch 920 loss: 0.785 r2: -3.720\n",
            "Epoch 930 loss: 0.785 r2: -3.719\n",
            "Epoch 940 loss: 0.785 r2: -3.717\n",
            "Epoch 950 loss: 0.785 r2: -3.716\n",
            "Epoch 960 loss: 0.785 r2: -3.715\n",
            "Epoch 970 loss: 0.785 r2: -3.713\n",
            "Epoch 980 loss: 0.785 r2: -3.712\n",
            "Epoch 990 loss: 0.785 r2: -3.711\n",
            "Weights: [-8.644203303874512, 4.876484243757065, -38.286154303231925, 2.694406191547898, -14.684079577841148, 37.501526384802, -11.744569698614368, -15.609607847690492]\n",
            "Bias: [19.759433245389015, -29.697861431658982, 2.6372018995078284]\n",
            "Loss for test dataset\n",
            "Test loss: 0.615, r2: -2.419\n",
            "Loss for training dataset\n",
            "Test loss: 0.785, r2: -3.710\n",
            "Epoch 0 loss: 0.787 r2: -3.632\n",
            "Epoch 10 loss: 0.787 r2: -3.690\n",
            "Epoch 20 loss: 0.787 r2: -3.694\n",
            "Epoch 30 loss: 0.787 r2: -3.695\n",
            "Epoch 40 loss: 0.787 r2: -3.696\n",
            "Epoch 50 loss: 0.787 r2: -3.697\n",
            "Epoch 60 loss: 0.787 r2: -3.698\n",
            "Epoch 70 loss: 0.787 r2: -3.699\n",
            "Epoch 80 loss: 0.787 r2: -3.701\n",
            "Epoch 90 loss: 0.787 r2: -3.702\n",
            "Epoch 100 loss: 0.786 r2: -3.704\n",
            "Epoch 110 loss: 0.786 r2: -3.706\n",
            "Epoch 120 loss: 0.786 r2: -3.709\n",
            "Epoch 130 loss: 0.786 r2: -3.711\n",
            "Epoch 140 loss: 0.786 r2: -3.714\n",
            "Epoch 150 loss: 0.786 r2: -3.716\n",
            "Epoch 160 loss: 0.786 r2: -3.718\n",
            "Epoch 170 loss: 0.786 r2: -3.720\n",
            "Epoch 180 loss: 0.786 r2: -3.721\n",
            "Epoch 190 loss: 0.786 r2: -3.721\n",
            "Epoch 200 loss: 0.786 r2: -3.720\n",
            "Epoch 210 loss: 0.786 r2: -3.719\n",
            "Epoch 220 loss: 0.786 r2: -3.718\n",
            "Epoch 230 loss: 0.786 r2: -3.717\n",
            "Epoch 240 loss: 0.786 r2: -3.715\n",
            "Epoch 250 loss: 0.785 r2: -3.713\n",
            "Epoch 260 loss: 0.785 r2: -3.712\n",
            "Epoch 270 loss: 0.785 r2: -3.710\n",
            "Epoch 280 loss: 0.785 r2: -3.708\n",
            "Epoch 290 loss: 0.785 r2: -3.706\n",
            "Epoch 300 loss: 0.785 r2: -3.704\n",
            "Epoch 310 loss: 0.785 r2: -3.702\n",
            "Epoch 320 loss: 0.785 r2: -3.700\n",
            "Epoch 330 loss: 0.785 r2: -3.698\n",
            "Epoch 340 loss: 0.785 r2: -3.696\n",
            "Epoch 350 loss: 0.785 r2: -3.694\n",
            "Epoch 360 loss: 0.785 r2: -3.692\n",
            "Epoch 370 loss: 0.785 r2: -3.691\n",
            "Epoch 380 loss: 0.785 r2: -3.689\n",
            "Epoch 390 loss: 0.785 r2: -3.687\n",
            "Epoch 400 loss: 0.785 r2: -3.686\n",
            "Epoch 410 loss: 0.785 r2: -3.684\n",
            "Epoch 420 loss: 0.785 r2: -3.682\n",
            "Epoch 430 loss: 0.785 r2: -3.681\n",
            "Epoch 440 loss: 0.785 r2: -3.679\n",
            "Epoch 450 loss: 0.785 r2: -3.678\n",
            "Epoch 460 loss: 0.785 r2: -3.676\n",
            "Epoch 470 loss: 0.785 r2: -3.675\n",
            "Epoch 480 loss: 0.785 r2: -3.674\n",
            "Epoch 490 loss: 0.785 r2: -3.672\n",
            "Epoch 500 loss: 0.785 r2: -3.671\n",
            "Epoch 510 loss: 0.785 r2: -3.670\n",
            "Epoch 520 loss: 0.785 r2: -3.669\n",
            "Epoch 530 loss: 0.785 r2: -3.668\n",
            "Epoch 540 loss: 0.785 r2: -3.667\n",
            "Epoch 550 loss: 0.785 r2: -3.665\n",
            "Epoch 560 loss: 0.785 r2: -3.664\n",
            "Epoch 570 loss: 0.785 r2: -3.663\n",
            "Epoch 580 loss: 0.785 r2: -3.662\n",
            "Epoch 590 loss: 0.785 r2: -3.661\n",
            "Epoch 600 loss: 0.785 r2: -3.660\n",
            "Epoch 610 loss: 0.785 r2: -3.659\n",
            "Epoch 620 loss: 0.785 r2: -3.658\n",
            "Epoch 630 loss: 0.785 r2: -3.658\n",
            "Epoch 640 loss: 0.785 r2: -3.657\n",
            "Epoch 650 loss: 0.785 r2: -3.656\n",
            "Epoch 660 loss: 0.785 r2: -3.655\n",
            "Epoch 670 loss: 0.785 r2: -3.654\n",
            "Epoch 680 loss: 0.784 r2: -3.653\n",
            "Epoch 690 loss: 0.784 r2: -3.652\n",
            "Epoch 700 loss: 0.784 r2: -3.652\n",
            "Epoch 710 loss: 0.784 r2: -3.651\n",
            "Epoch 720 loss: 0.784 r2: -3.650\n",
            "Epoch 730 loss: 0.784 r2: -3.649\n",
            "Epoch 740 loss: 0.784 r2: -3.649\n",
            "Epoch 750 loss: 0.784 r2: -3.648\n",
            "Epoch 760 loss: 0.784 r2: -3.647\n",
            "Epoch 770 loss: 0.784 r2: -3.646\n",
            "Epoch 780 loss: 0.784 r2: -3.646\n",
            "Epoch 790 loss: 0.784 r2: -3.645\n",
            "Epoch 800 loss: 0.784 r2: -3.644\n",
            "Epoch 810 loss: 0.784 r2: -3.644\n",
            "Epoch 820 loss: 0.784 r2: -3.643\n",
            "Epoch 830 loss: 0.784 r2: -3.642\n",
            "Epoch 840 loss: 0.784 r2: -3.642\n",
            "Epoch 850 loss: 0.784 r2: -3.641\n",
            "Epoch 860 loss: 0.784 r2: -3.641\n",
            "Epoch 870 loss: 0.784 r2: -3.640\n",
            "Epoch 880 loss: 0.784 r2: -3.640\n",
            "Epoch 890 loss: 0.784 r2: -3.639\n",
            "Epoch 900 loss: 0.784 r2: -3.638\n",
            "Epoch 910 loss: 0.784 r2: -3.638\n",
            "Epoch 920 loss: 0.784 r2: -3.637\n",
            "Epoch 930 loss: 0.784 r2: -3.637\n",
            "Epoch 940 loss: 0.784 r2: -3.636\n",
            "Epoch 950 loss: 0.784 r2: -3.636\n",
            "Epoch 960 loss: 0.784 r2: -3.635\n",
            "Epoch 970 loss: 0.784 r2: -3.635\n",
            "Epoch 980 loss: 0.784 r2: -3.634\n",
            "Epoch 990 loss: 0.784 r2: -3.634\n",
            "Weights: [-10.222509192908747, 5.786700089967442, -46.03139150639421, 3.463679749287116, -19.087450882094917, 47.75037380057917, -11.336973046689975, -18.735407035891356]\n",
            "Bias: [23.95410278441784, -37.5470888494252, 2.579711166912015]\n",
            "Loss for test dataset\n",
            "Test loss: 0.617, r2: -2.401\n",
            "Loss for training dataset\n",
            "Test loss: 0.784, r2: -3.634\n",
            "Epoch 0 loss: 0.786 r2: -3.591\n",
            "Epoch 10 loss: 0.785 r2: -3.644\n",
            "Epoch 20 loss: 0.785 r2: -3.625\n",
            "Epoch 30 loss: 0.785 r2: -3.621\n",
            "Epoch 40 loss: 0.785 r2: -3.621\n",
            "Epoch 50 loss: 0.785 r2: -3.622\n",
            "Epoch 60 loss: 0.785 r2: -3.624\n",
            "Epoch 70 loss: 0.785 r2: -3.626\n",
            "Epoch 80 loss: 0.785 r2: -3.628\n",
            "Epoch 90 loss: 0.785 r2: -3.630\n",
            "Epoch 100 loss: 0.785 r2: -3.632\n",
            "Epoch 110 loss: 0.785 r2: -3.633\n",
            "Epoch 120 loss: 0.785 r2: -3.635\n",
            "Epoch 130 loss: 0.785 r2: -3.637\n",
            "Epoch 140 loss: 0.785 r2: -3.638\n",
            "Epoch 150 loss: 0.785 r2: -3.640\n",
            "Epoch 160 loss: 0.785 r2: -3.641\n",
            "Epoch 170 loss: 0.785 r2: -3.642\n",
            "Epoch 180 loss: 0.785 r2: -3.642\n",
            "Epoch 190 loss: 0.785 r2: -3.643\n",
            "Epoch 200 loss: 0.785 r2: -3.643\n",
            "Epoch 210 loss: 0.785 r2: -3.643\n",
            "Epoch 220 loss: 0.785 r2: -3.643\n",
            "Epoch 230 loss: 0.785 r2: -3.643\n",
            "Epoch 240 loss: 0.785 r2: -3.643\n",
            "Epoch 250 loss: 0.785 r2: -3.643\n",
            "Epoch 260 loss: 0.785 r2: -3.642\n",
            "Epoch 270 loss: 0.785 r2: -3.642\n",
            "Epoch 280 loss: 0.785 r2: -3.642\n",
            "Epoch 290 loss: 0.785 r2: -3.641\n",
            "Epoch 300 loss: 0.785 r2: -3.641\n",
            "Epoch 310 loss: 0.785 r2: -3.640\n",
            "Epoch 320 loss: 0.785 r2: -3.639\n",
            "Epoch 330 loss: 0.785 r2: -3.639\n",
            "Epoch 340 loss: 0.785 r2: -3.638\n",
            "Epoch 350 loss: 0.785 r2: -3.638\n",
            "Epoch 360 loss: 0.785 r2: -3.637\n",
            "Epoch 370 loss: 0.785 r2: -3.636\n",
            "Epoch 380 loss: 0.785 r2: -3.636\n",
            "Epoch 390 loss: 0.785 r2: -3.635\n",
            "Epoch 400 loss: 0.785 r2: -3.634\n",
            "Epoch 410 loss: 0.785 r2: -3.633\n",
            "Epoch 420 loss: 0.785 r2: -3.633\n",
            "Epoch 430 loss: 0.785 r2: -3.632\n",
            "Epoch 440 loss: 0.785 r2: -3.631\n",
            "Epoch 450 loss: 0.785 r2: -3.631\n",
            "Epoch 460 loss: 0.785 r2: -3.630\n",
            "Epoch 470 loss: 0.785 r2: -3.629\n",
            "Epoch 480 loss: 0.785 r2: -3.629\n",
            "Epoch 490 loss: 0.785 r2: -3.628\n",
            "Epoch 500 loss: 0.785 r2: -3.627\n",
            "Epoch 510 loss: 0.785 r2: -3.626\n",
            "Epoch 520 loss: 0.785 r2: -3.626\n",
            "Epoch 530 loss: 0.785 r2: -3.625\n",
            "Epoch 540 loss: 0.785 r2: -3.624\n",
            "Epoch 550 loss: 0.785 r2: -3.624\n",
            "Epoch 560 loss: 0.784 r2: -3.623\n",
            "Epoch 570 loss: 0.784 r2: -3.622\n",
            "Epoch 580 loss: 0.784 r2: -3.622\n",
            "Epoch 590 loss: 0.784 r2: -3.621\n",
            "Epoch 600 loss: 0.784 r2: -3.620\n",
            "Epoch 610 loss: 0.784 r2: -3.620\n",
            "Epoch 620 loss: 0.784 r2: -3.619\n",
            "Epoch 630 loss: 0.784 r2: -3.619\n",
            "Epoch 640 loss: 0.784 r2: -3.618\n",
            "Epoch 650 loss: 0.784 r2: -3.617\n",
            "Epoch 660 loss: 0.784 r2: -3.617\n",
            "Epoch 670 loss: 0.784 r2: -3.616\n",
            "Epoch 680 loss: 0.784 r2: -3.616\n",
            "Epoch 690 loss: 0.784 r2: -3.615\n",
            "Epoch 700 loss: 0.784 r2: -3.615\n",
            "Epoch 710 loss: 0.784 r2: -3.614\n",
            "Epoch 720 loss: 0.784 r2: -3.614\n",
            "Epoch 730 loss: 0.784 r2: -3.613\n",
            "Epoch 740 loss: 0.784 r2: -3.613\n",
            "Epoch 750 loss: 0.784 r2: -3.612\n",
            "Epoch 760 loss: 0.784 r2: -3.612\n",
            "Epoch 770 loss: 0.784 r2: -3.611\n",
            "Epoch 780 loss: 0.784 r2: -3.611\n",
            "Epoch 790 loss: 0.784 r2: -3.610\n",
            "Epoch 800 loss: 0.784 r2: -3.610\n",
            "Epoch 810 loss: 0.784 r2: -3.609\n",
            "Epoch 820 loss: 0.784 r2: -3.609\n",
            "Epoch 830 loss: 0.784 r2: -3.608\n",
            "Epoch 840 loss: 0.784 r2: -3.608\n",
            "Epoch 850 loss: 0.784 r2: -3.607\n",
            "Epoch 860 loss: 0.784 r2: -3.607\n",
            "Epoch 870 loss: 0.784 r2: -3.607\n",
            "Epoch 880 loss: 0.784 r2: -3.606\n",
            "Epoch 890 loss: 0.784 r2: -3.606\n",
            "Epoch 900 loss: 0.784 r2: -3.605\n",
            "Epoch 910 loss: 0.784 r2: -3.605\n",
            "Epoch 920 loss: 0.784 r2: -3.605\n",
            "Epoch 930 loss: 0.784 r2: -3.604\n",
            "Epoch 940 loss: 0.784 r2: -3.604\n",
            "Epoch 950 loss: 0.784 r2: -3.603\n",
            "Epoch 960 loss: 0.784 r2: -3.603\n",
            "Epoch 970 loss: 0.784 r2: -3.603\n",
            "Epoch 980 loss: 0.784 r2: -3.602\n",
            "Epoch 990 loss: 0.784 r2: -3.602\n",
            "Weights: [-12.037168671979794, 6.732434571737563, -53.87645418980302, 4.058507887848248, -22.94947974310754, 56.68534357983108, -11.076468420988617, -21.79489194929873]\n",
            "Bias: [28.31438978198876, -44.39148953977213, 2.517435884280973]\n",
            "Loss for test dataset\n",
            "Test loss: 0.618, r2: -2.400\n",
            "Loss for training dataset\n",
            "Test loss: 0.784, r2: -3.602\n",
            "Epoch 0 loss: 0.786 r2: -3.598\n",
            "Epoch 10 loss: 0.785 r2: -3.615\n",
            "Epoch 20 loss: 0.785 r2: -3.607\n",
            "Epoch 30 loss: 0.785 r2: -3.608\n",
            "Epoch 40 loss: 0.785 r2: -3.607\n",
            "Epoch 50 loss: 0.785 r2: -3.607\n",
            "Epoch 60 loss: 0.785 r2: -3.606\n",
            "Epoch 70 loss: 0.785 r2: -3.606\n",
            "Epoch 80 loss: 0.785 r2: -3.605\n",
            "Epoch 90 loss: 0.785 r2: -3.604\n",
            "Epoch 100 loss: 0.785 r2: -3.603\n",
            "Epoch 110 loss: 0.785 r2: -3.603\n",
            "Epoch 120 loss: 0.785 r2: -3.602\n",
            "Epoch 130 loss: 0.785 r2: -3.601\n",
            "Epoch 140 loss: 0.785 r2: -3.600\n",
            "Epoch 150 loss: 0.785 r2: -3.599\n",
            "Epoch 160 loss: 0.785 r2: -3.598\n",
            "Epoch 170 loss: 0.785 r2: -3.597\n",
            "Epoch 180 loss: 0.785 r2: -3.596\n",
            "Epoch 190 loss: 0.785 r2: -3.595\n",
            "Epoch 200 loss: 0.785 r2: -3.594\n",
            "Epoch 210 loss: 0.785 r2: -3.593\n",
            "Epoch 220 loss: 0.785 r2: -3.592\n",
            "Epoch 230 loss: 0.785 r2: -3.591\n",
            "Epoch 240 loss: 0.785 r2: -3.590\n",
            "Epoch 250 loss: 0.785 r2: -3.589\n",
            "Epoch 260 loss: 0.785 r2: -3.588\n",
            "Epoch 270 loss: 0.785 r2: -3.587\n",
            "Epoch 280 loss: 0.785 r2: -3.586\n",
            "Epoch 290 loss: 0.785 r2: -3.585\n",
            "Epoch 300 loss: 0.785 r2: -3.584\n",
            "Epoch 310 loss: 0.785 r2: -3.583\n",
            "Epoch 320 loss: 0.785 r2: -3.582\n",
            "Epoch 330 loss: 0.785 r2: -3.581\n",
            "Epoch 340 loss: 0.785 r2: -3.580\n",
            "Epoch 350 loss: 0.785 r2: -3.579\n",
            "Epoch 360 loss: 0.785 r2: -3.579\n",
            "Epoch 370 loss: 0.785 r2: -3.578\n",
            "Epoch 380 loss: 0.785 r2: -3.577\n",
            "Epoch 390 loss: 0.785 r2: -3.576\n",
            "Epoch 400 loss: 0.785 r2: -3.575\n",
            "Epoch 410 loss: 0.785 r2: -3.575\n",
            "Epoch 420 loss: 0.785 r2: -3.574\n",
            "Epoch 430 loss: 0.785 r2: -3.573\n",
            "Epoch 440 loss: 0.785 r2: -3.572\n",
            "Epoch 450 loss: 0.785 r2: -3.572\n",
            "Epoch 460 loss: 0.785 r2: -3.571\n",
            "Epoch 470 loss: 0.785 r2: -3.570\n",
            "Epoch 480 loss: 0.785 r2: -3.570\n",
            "Epoch 490 loss: 0.784 r2: -3.569\n",
            "Epoch 500 loss: 0.784 r2: -3.568\n",
            "Epoch 510 loss: 0.784 r2: -3.568\n",
            "Epoch 520 loss: 0.784 r2: -3.567\n",
            "Epoch 530 loss: 0.784 r2: -3.567\n",
            "Epoch 540 loss: 0.784 r2: -3.566\n",
            "Epoch 550 loss: 0.784 r2: -3.565\n",
            "Epoch 560 loss: 0.784 r2: -3.565\n",
            "Epoch 570 loss: 0.784 r2: -3.564\n",
            "Epoch 580 loss: 0.784 r2: -3.564\n",
            "Epoch 590 loss: 0.784 r2: -3.563\n",
            "Epoch 600 loss: 0.784 r2: -3.563\n",
            "Epoch 610 loss: 0.784 r2: -3.562\n",
            "Epoch 620 loss: 0.784 r2: -3.562\n",
            "Epoch 630 loss: 0.784 r2: -3.561\n",
            "Epoch 640 loss: 0.784 r2: -3.561\n",
            "Epoch 650 loss: 0.784 r2: -3.560\n",
            "Epoch 660 loss: 0.784 r2: -3.559\n",
            "Epoch 670 loss: 0.784 r2: -3.559\n",
            "Epoch 680 loss: 0.784 r2: -3.558\n",
            "Epoch 690 loss: 0.784 r2: -3.558\n",
            "Epoch 700 loss: 0.784 r2: -3.557\n",
            "Epoch 710 loss: 0.784 r2: -3.557\n",
            "Epoch 720 loss: 0.784 r2: -3.556\n",
            "Epoch 730 loss: 0.784 r2: -3.556\n",
            "Epoch 740 loss: 0.784 r2: -3.555\n",
            "Epoch 750 loss: 0.784 r2: -3.555\n",
            "Epoch 760 loss: 0.784 r2: -3.554\n",
            "Epoch 770 loss: 0.784 r2: -3.554\n",
            "Epoch 780 loss: 0.784 r2: -3.553\n",
            "Epoch 790 loss: 0.784 r2: -3.553\n",
            "Epoch 800 loss: 0.784 r2: -3.552\n",
            "Epoch 810 loss: 0.784 r2: -3.552\n",
            "Epoch 820 loss: 0.784 r2: -3.551\n",
            "Epoch 830 loss: 0.784 r2: -3.551\n",
            "Epoch 840 loss: 0.783 r2: -3.550\n",
            "Epoch 850 loss: 0.783 r2: -3.550\n",
            "Epoch 860 loss: 0.783 r2: -3.549\n",
            "Epoch 870 loss: 0.783 r2: -3.548\n",
            "Epoch 880 loss: 0.783 r2: -3.548\n",
            "Epoch 890 loss: 0.783 r2: -3.547\n",
            "Epoch 900 loss: 0.783 r2: -3.547\n",
            "Epoch 910 loss: 0.783 r2: -3.547\n",
            "Epoch 920 loss: 0.783 r2: -3.546\n",
            "Epoch 930 loss: 0.783 r2: -3.546\n",
            "Epoch 940 loss: 0.783 r2: -3.545\n",
            "Epoch 950 loss: 0.783 r2: -3.545\n",
            "Epoch 960 loss: 0.783 r2: -3.544\n",
            "Epoch 970 loss: 0.783 r2: -3.544\n",
            "Epoch 980 loss: 0.783 r2: -3.543\n",
            "Epoch 990 loss: 0.783 r2: -3.543\n",
            "Weights: [-13.99526560132141, 7.760271038402538, -62.61881957549153, 4.496667089367691, -26.08374222602529, 63.966480156157594, -10.9910936206335, -24.025142152566684]\n",
            "Bias: [33.15383923396736, -50.04165953332461, 2.494498087868896]\n",
            "Loss for test dataset\n",
            "Test loss: 0.617, r2: -2.375\n",
            "Loss for training dataset\n",
            "Test loss: 0.783, r2: -3.543\n",
            "Epoch 0 loss: 0.786 r2: -3.513\n",
            "Epoch 10 loss: 0.786 r2: -3.523\n",
            "Epoch 20 loss: 0.786 r2: -3.530\n",
            "Epoch 30 loss: 0.786 r2: -3.533\n",
            "Epoch 40 loss: 0.786 r2: -3.532\n",
            "Epoch 50 loss: 0.786 r2: -3.532\n",
            "Epoch 60 loss: 0.786 r2: -3.530\n",
            "Epoch 70 loss: 0.786 r2: -3.530\n",
            "Epoch 80 loss: 0.786 r2: -3.529\n",
            "Epoch 90 loss: 0.786 r2: -3.527\n",
            "Epoch 100 loss: 0.786 r2: -3.527\n",
            "Epoch 110 loss: 0.786 r2: -3.525\n",
            "Epoch 120 loss: 0.786 r2: -3.524\n",
            "Epoch 130 loss: 0.785 r2: -3.523\n",
            "Epoch 140 loss: 0.785 r2: -3.522\n",
            "Epoch 150 loss: 0.785 r2: -3.521\n",
            "Epoch 160 loss: 0.785 r2: -3.521\n",
            "Epoch 170 loss: 0.785 r2: -3.518\n",
            "Epoch 180 loss: 0.785 r2: -3.521\n",
            "Epoch 190 loss: 0.785 r2: -3.514\n",
            "Epoch 200 loss: 0.785 r2: -3.519\n",
            "Epoch 210 loss: 0.785 r2: -3.513\n",
            "Epoch 220 loss: 0.785 r2: -3.516\n",
            "Epoch 230 loss: 0.785 r2: -3.511\n",
            "Epoch 240 loss: 0.785 r2: -3.514\n",
            "Epoch 250 loss: 0.785 r2: -3.510\n",
            "Epoch 260 loss: 0.785 r2: -3.512\n",
            "Epoch 270 loss: 0.785 r2: -3.508\n",
            "Epoch 280 loss: 0.785 r2: -3.510\n",
            "Epoch 290 loss: 0.785 r2: -3.507\n",
            "Epoch 300 loss: 0.785 r2: -3.508\n",
            "Epoch 310 loss: 0.785 r2: -3.506\n",
            "Epoch 320 loss: 0.785 r2: -3.506\n",
            "Epoch 330 loss: 0.785 r2: -3.505\n",
            "Epoch 340 loss: 0.785 r2: -3.505\n",
            "Epoch 350 loss: 0.785 r2: -3.504\n",
            "Epoch 360 loss: 0.785 r2: -3.504\n",
            "Epoch 370 loss: 0.785 r2: -3.503\n",
            "Epoch 380 loss: 0.785 r2: -3.503\n",
            "Epoch 390 loss: 0.785 r2: -3.502\n",
            "Epoch 400 loss: 0.785 r2: -3.502\n",
            "Epoch 410 loss: 0.785 r2: -3.501\n",
            "Epoch 420 loss: 0.785 r2: -3.501\n",
            "Epoch 430 loss: 0.785 r2: -3.500\n",
            "Epoch 440 loss: 0.785 r2: -3.500\n",
            "Epoch 450 loss: 0.785 r2: -3.500\n",
            "Epoch 460 loss: 0.785 r2: -3.499\n",
            "Epoch 470 loss: 0.785 r2: -3.499\n",
            "Epoch 480 loss: 0.785 r2: -3.499\n",
            "Epoch 490 loss: 0.785 r2: -3.498\n",
            "Epoch 500 loss: 0.785 r2: -3.498\n",
            "Epoch 510 loss: 0.785 r2: -3.498\n",
            "Epoch 520 loss: 0.785 r2: -3.497\n",
            "Epoch 530 loss: 0.784 r2: -3.497\n",
            "Epoch 540 loss: 0.784 r2: -3.497\n",
            "Epoch 550 loss: 0.784 r2: -3.497\n",
            "Epoch 560 loss: 0.784 r2: -3.496\n",
            "Epoch 570 loss: 0.784 r2: -3.496\n",
            "Epoch 580 loss: 0.784 r2: -3.496\n",
            "Epoch 590 loss: 0.784 r2: -3.496\n",
            "Epoch 600 loss: 0.784 r2: -3.495\n",
            "Epoch 610 loss: 0.784 r2: -3.495\n",
            "Epoch 620 loss: 0.784 r2: -3.494\n",
            "Epoch 630 loss: 0.784 r2: -3.493\n",
            "Epoch 640 loss: 0.784 r2: -3.492\n",
            "Epoch 650 loss: 0.783 r2: -3.489\n",
            "Epoch 660 loss: 0.783 r2: -3.488\n",
            "Epoch 670 loss: 0.783 r2: -3.488\n",
            "Epoch 680 loss: 0.783 r2: -3.487\n",
            "Epoch 690 loss: 0.783 r2: -3.487\n",
            "Epoch 700 loss: 0.783 r2: -3.487\n",
            "Epoch 710 loss: 0.783 r2: -3.487\n",
            "Epoch 720 loss: 0.783 r2: -3.486\n",
            "Epoch 730 loss: 0.783 r2: -3.486\n",
            "Epoch 740 loss: 0.783 r2: -3.486\n",
            "Epoch 750 loss: 0.783 r2: -3.486\n",
            "Epoch 760 loss: 0.783 r2: -3.486\n",
            "Epoch 770 loss: 0.783 r2: -3.486\n",
            "Epoch 780 loss: 0.783 r2: -3.486\n",
            "Epoch 790 loss: 0.783 r2: -3.487\n",
            "Epoch 800 loss: 0.783 r2: -3.487\n",
            "Epoch 810 loss: 0.783 r2: -3.487\n",
            "Epoch 820 loss: 0.783 r2: -3.488\n",
            "Epoch 830 loss: 0.783 r2: -3.488\n",
            "Epoch 840 loss: 0.783 r2: -3.489\n",
            "Epoch 850 loss: 0.783 r2: -3.490\n",
            "Epoch 860 loss: 0.783 r2: -3.491\n",
            "Epoch 870 loss: 0.783 r2: -3.492\n",
            "Epoch 880 loss: 0.783 r2: -3.493\n",
            "Epoch 890 loss: 0.783 r2: -3.494\n",
            "Epoch 900 loss: 0.783 r2: -3.495\n",
            "Epoch 910 loss: 0.783 r2: -3.497\n",
            "Epoch 920 loss: 0.783 r2: -3.499\n",
            "Epoch 930 loss: 0.783 r2: -3.501\n",
            "Epoch 940 loss: 0.783 r2: -3.503\n",
            "Epoch 950 loss: 0.783 r2: -3.505\n",
            "Epoch 960 loss: 0.783 r2: -3.508\n",
            "Epoch 970 loss: 0.783 r2: -3.510\n",
            "Epoch 980 loss: 0.783 r2: -3.513\n",
            "Epoch 990 loss: 0.783 r2: -3.515\n",
            "Weights: [-15.892996908104724, 8.812940329899272, -71.53667823746069, 4.844804232007496, -28.375627499823274, 69.48204675637143, -10.895342002780184, -25.6665947338536]\n",
            "Bias: [38.03582988588465, -54.33464989541357, 2.459176010848054]\n",
            "Loss for test dataset\n",
            "Test loss: 0.617, r2: -2.372\n",
            "Loss for training dataset\n",
            "Test loss: 0.783, r2: -3.515\n",
            "Epoch 0 loss: 0.785 r2: -3.457\n",
            "Epoch 10 loss: 0.787 r2: -3.434\n",
            "Epoch 20 loss: 0.785 r2: -3.456\n",
            "Epoch 30 loss: 0.785 r2: -3.456\n",
            "Epoch 40 loss: 0.784 r2: -3.476\n",
            "Epoch 50 loss: 0.784 r2: -3.474\n",
            "Epoch 60 loss: 0.784 r2: -3.495\n",
            "Epoch 70 loss: 0.785 r2: -3.470\n",
            "Epoch 80 loss: 0.785 r2: -3.457\n",
            "Epoch 90 loss: 0.786 r2: -3.448\n",
            "Epoch 100 loss: 0.786 r2: -3.437\n",
            "Epoch 110 loss: 0.785 r2: -3.470\n",
            "Epoch 120 loss: 0.786 r2: -3.440\n",
            "Epoch 130 loss: 0.786 r2: -3.430\n",
            "Epoch 140 loss: 0.785 r2: -3.474\n",
            "Epoch 150 loss: 0.785 r2: -3.452\n",
            "Epoch 160 loss: 0.784 r2: -3.470\n",
            "Epoch 170 loss: 0.784 r2: -3.450\n",
            "Epoch 180 loss: 0.784 r2: -3.458\n",
            "Epoch 190 loss: 0.784 r2: -3.475\n",
            "Epoch 200 loss: 0.784 r2: -3.476\n",
            "Epoch 210 loss: 0.784 r2: -3.464\n",
            "Epoch 220 loss: 0.784 r2: -3.476\n",
            "Epoch 230 loss: 0.784 r2: -3.474\n",
            "Epoch 240 loss: 0.784 r2: -3.474\n",
            "Epoch 250 loss: 0.784 r2: -3.474\n",
            "Epoch 260 loss: 0.784 r2: -3.476\n",
            "Epoch 270 loss: 0.784 r2: -3.475\n",
            "Epoch 280 loss: 0.784 r2: -3.476\n",
            "Epoch 290 loss: 0.784 r2: -3.475\n",
            "Epoch 300 loss: 0.784 r2: -3.476\n",
            "Epoch 310 loss: 0.784 r2: -3.476\n",
            "Epoch 320 loss: 0.784 r2: -3.476\n",
            "Epoch 330 loss: 0.784 r2: -3.476\n",
            "Epoch 340 loss: 0.784 r2: -3.475\n",
            "Epoch 350 loss: 0.784 r2: -3.475\n",
            "Epoch 360 loss: 0.784 r2: -3.475\n",
            "Epoch 370 loss: 0.784 r2: -3.475\n",
            "Epoch 380 loss: 0.784 r2: -3.475\n",
            "Epoch 390 loss: 0.784 r2: -3.475\n",
            "Epoch 400 loss: 0.783 r2: -3.475\n",
            "Epoch 410 loss: 0.783 r2: -3.474\n",
            "Epoch 420 loss: 0.783 r2: -3.474\n",
            "Epoch 430 loss: 0.783 r2: -3.473\n",
            "Epoch 440 loss: 0.783 r2: -3.473\n",
            "Epoch 450 loss: 0.783 r2: -3.472\n",
            "Epoch 460 loss: 0.783 r2: -3.471\n",
            "Epoch 470 loss: 0.783 r2: -3.470\n",
            "Epoch 480 loss: 0.783 r2: -3.468\n",
            "Epoch 490 loss: 0.783 r2: -3.467\n",
            "Epoch 500 loss: 0.783 r2: -3.465\n",
            "Epoch 510 loss: 0.783 r2: -3.463\n",
            "Epoch 520 loss: 0.783 r2: -3.461\n",
            "Epoch 530 loss: 0.783 r2: -3.459\n",
            "Epoch 540 loss: 0.783 r2: -3.457\n",
            "Epoch 550 loss: 0.783 r2: -3.455\n",
            "Epoch 560 loss: 0.783 r2: -3.453\n",
            "Epoch 570 loss: 0.784 r2: -3.448\n",
            "Epoch 580 loss: 0.784 r2: -3.434\n",
            "Epoch 590 loss: 0.784 r2: -3.436\n",
            "Epoch 600 loss: 0.784 r2: -3.444\n",
            "Epoch 610 loss: 0.784 r2: -3.451\n",
            "Epoch 620 loss: 0.784 r2: -3.450\n",
            "Epoch 630 loss: 0.784 r2: -3.449\n",
            "Epoch 640 loss: 0.784 r2: -3.448\n",
            "Epoch 650 loss: 0.784 r2: -3.447\n",
            "Epoch 660 loss: 0.784 r2: -3.446\n",
            "Epoch 670 loss: 0.784 r2: -3.446\n",
            "Epoch 680 loss: 0.784 r2: -3.447\n",
            "Epoch 690 loss: 0.784 r2: -3.450\n",
            "Epoch 700 loss: 0.784 r2: -3.453\n",
            "Epoch 710 loss: 0.784 r2: -3.457\n",
            "Epoch 720 loss: 0.784 r2: -3.461\n",
            "Epoch 730 loss: 0.783 r2: -3.465\n",
            "Epoch 740 loss: 0.783 r2: -3.469\n",
            "Epoch 750 loss: 0.783 r2: -3.472\n",
            "Epoch 760 loss: 0.783 r2: -3.472\n",
            "Epoch 770 loss: 0.783 r2: -3.471\n",
            "Epoch 780 loss: 0.783 r2: -3.469\n",
            "Epoch 790 loss: 0.783 r2: -3.507\n",
            "Epoch 800 loss: 0.782 r2: -3.719\n",
            "Epoch 810 loss: 0.782 r2: -3.700\n",
            "Epoch 820 loss: 0.783 r2: -3.549\n",
            "Epoch 830 loss: 0.782 r2: -3.710\n",
            "Epoch 840 loss: 0.782 r2: -3.727\n",
            "Epoch 850 loss: 0.783 r2: -3.501\n",
            "Epoch 860 loss: 0.782 r2: -3.685\n",
            "Epoch 870 loss: 0.782 r2: -3.735\n",
            "Epoch 880 loss: 0.783 r2: -3.492\n",
            "Epoch 890 loss: 0.782 r2: -3.680\n",
            "Epoch 900 loss: 0.782 r2: -3.725\n",
            "Epoch 910 loss: 0.783 r2: -3.495\n",
            "Epoch 920 loss: 0.782 r2: -3.723\n",
            "Epoch 930 loss: 0.782 r2: -3.632\n",
            "Epoch 940 loss: 0.782 r2: -3.543\n",
            "Epoch 950 loss: 0.782 r2: -3.730\n",
            "Epoch 960 loss: 0.783 r2: -3.477\n",
            "Epoch 970 loss: 0.782 r2: -3.679\n",
            "Epoch 980 loss: 0.782 r2: -3.693\n",
            "Epoch 990 loss: 0.783 r2: -3.458\n",
            "Weights: [-17.303073539635534, 9.8062408339807, -81.60243525296589, 5.1397678835755505, -30.23125908492759, 73.87695348607907, -12.057447658719594, -26.998885888788088]\n",
            "Bias: [43.00104139826516, -57.77000172511116, 2.4108290754864234]\n",
            "Loss for test dataset\n",
            "Test loss: 0.618, r2: -2.374\n",
            "Loss for training dataset\n",
            "Test loss: 0.783, r2: -3.454\n",
            "Epoch 0 loss: 0.784 r2: -3.621\n",
            "Epoch 10 loss: 0.783 r2: -3.758\n",
            "Epoch 20 loss: 0.783 r2: -3.507\n",
            "Epoch 30 loss: 0.785 r2: -3.331\n",
            "Epoch 40 loss: 0.784 r2: -3.770\n",
            "Epoch 50 loss: 0.785 r2: -3.344\n",
            "Epoch 60 loss: 0.786 r2: -3.327\n",
            "Epoch 70 loss: 0.784 r2: -3.722\n",
            "Epoch 80 loss: 0.783 r2: -3.736\n",
            "Epoch 90 loss: 0.783 r2: -3.716\n",
            "Epoch 100 loss: 0.785 r2: -3.657\n",
            "Epoch 110 loss: 0.783 r2: -3.629\n",
            "Epoch 120 loss: 0.783 r2: -3.658\n",
            "Epoch 130 loss: 0.783 r2: -3.706\n",
            "Epoch 140 loss: 0.783 r2: -3.665\n",
            "Epoch 150 loss: 0.784 r2: -3.407\n",
            "Epoch 160 loss: 0.783 r2: -3.727\n",
            "Epoch 170 loss: 0.783 r2: -3.632\n",
            "Epoch 180 loss: 0.783 r2: -3.494\n",
            "Epoch 190 loss: 0.783 r2: -3.727\n",
            "Epoch 200 loss: 0.783 r2: -3.566\n",
            "Epoch 210 loss: 0.784 r2: -3.409\n",
            "Epoch 220 loss: 0.783 r2: -3.704\n",
            "Epoch 230 loss: 0.783 r2: -3.571\n",
            "Epoch 240 loss: 0.784 r2: -3.473\n",
            "Epoch 250 loss: 0.783 r2: -3.627\n",
            "Epoch 260 loss: 0.783 r2: -3.624\n",
            "Epoch 270 loss: 0.784 r2: -3.439\n",
            "Epoch 280 loss: 0.783 r2: -3.614\n",
            "Epoch 290 loss: 0.783 r2: -3.576\n",
            "Epoch 300 loss: 0.784 r2: -3.371\n",
            "Epoch 310 loss: 0.783 r2: -3.611\n",
            "Epoch 320 loss: 0.783 r2: -3.597\n",
            "Epoch 330 loss: 0.784 r2: -3.310\n",
            "Epoch 340 loss: 0.783 r2: -3.589\n",
            "Epoch 350 loss: 0.783 r2: -3.605\n",
            "Epoch 360 loss: 0.783 r2: -3.599\n",
            "Epoch 370 loss: 0.783 r2: -3.348\n",
            "Epoch 380 loss: 0.783 r2: -3.327\n",
            "Epoch 390 loss: 0.783 r2: -3.311\n",
            "Epoch 400 loss: 0.783 r2: -3.302\n",
            "Epoch 410 loss: 0.783 r2: -3.299\n",
            "Epoch 420 loss: 0.783 r2: -3.298\n",
            "Epoch 430 loss: 0.783 r2: -3.299\n",
            "Epoch 440 loss: 0.783 r2: -3.301\n",
            "Epoch 450 loss: 0.783 r2: -3.304\n",
            "Epoch 460 loss: 0.783 r2: -3.307\n",
            "Epoch 470 loss: 0.783 r2: -3.310\n",
            "Epoch 480 loss: 0.783 r2: -3.313\n",
            "Epoch 490 loss: 0.783 r2: -3.315\n",
            "Epoch 500 loss: 0.783 r2: -3.317\n",
            "Epoch 510 loss: 0.783 r2: -3.318\n",
            "Epoch 520 loss: 0.783 r2: -3.318\n",
            "Epoch 530 loss: 0.783 r2: -3.318\n",
            "Epoch 540 loss: 0.783 r2: -3.317\n",
            "Epoch 550 loss: 0.783 r2: -3.316\n",
            "Epoch 560 loss: 0.783 r2: -3.314\n",
            "Epoch 570 loss: 0.783 r2: -3.312\n",
            "Epoch 580 loss: 0.783 r2: -3.310\n",
            "Epoch 590 loss: 0.783 r2: -3.308\n",
            "Epoch 600 loss: 0.783 r2: -3.306\n",
            "Epoch 610 loss: 0.783 r2: -3.304\n",
            "Epoch 620 loss: 0.783 r2: -3.302\n",
            "Epoch 630 loss: 0.783 r2: -3.301\n",
            "Epoch 640 loss: 0.783 r2: -3.299\n",
            "Epoch 650 loss: 0.783 r2: -3.298\n",
            "Epoch 660 loss: 0.783 r2: -3.296\n",
            "Epoch 670 loss: 0.783 r2: -3.296\n",
            "Epoch 680 loss: 0.783 r2: -3.295\n",
            "Epoch 690 loss: 0.783 r2: -3.294\n",
            "Epoch 700 loss: 0.783 r2: -3.294\n",
            "Epoch 710 loss: 0.783 r2: -3.294\n",
            "Epoch 720 loss: 0.783 r2: -3.294\n",
            "Epoch 730 loss: 0.783 r2: -3.294\n",
            "Epoch 740 loss: 0.783 r2: -3.294\n",
            "Epoch 750 loss: 0.783 r2: -3.294\n",
            "Epoch 760 loss: 0.783 r2: -3.294\n",
            "Epoch 770 loss: 0.783 r2: -3.295\n",
            "Epoch 780 loss: 0.783 r2: -3.295\n",
            "Epoch 790 loss: 0.783 r2: -3.295\n",
            "Epoch 800 loss: 0.783 r2: -3.296\n",
            "Epoch 810 loss: 0.783 r2: -3.296\n",
            "Epoch 820 loss: 0.783 r2: -3.297\n",
            "Epoch 830 loss: 0.783 r2: -3.297\n",
            "Epoch 840 loss: 0.783 r2: -3.298\n",
            "Epoch 850 loss: 0.783 r2: -3.299\n",
            "Epoch 860 loss: 0.783 r2: -3.299\n",
            "Epoch 870 loss: 0.783 r2: -3.300\n",
            "Epoch 880 loss: 0.783 r2: -3.301\n",
            "Epoch 890 loss: 0.783 r2: -3.301\n",
            "Epoch 900 loss: 0.783 r2: -3.302\n",
            "Epoch 910 loss: 0.783 r2: -3.302\n",
            "Epoch 920 loss: 0.783 r2: -3.303\n",
            "Epoch 930 loss: 0.783 r2: -3.304\n",
            "Epoch 940 loss: 0.783 r2: -3.304\n",
            "Epoch 950 loss: 0.783 r2: -3.305\n",
            "Epoch 960 loss: 0.783 r2: -3.306\n",
            "Epoch 970 loss: 0.783 r2: -3.306\n",
            "Epoch 980 loss: 0.783 r2: -3.307\n",
            "Epoch 990 loss: 0.783 r2: -3.308\n",
            "Weights: [-20.06372470579988, 11.364293889436905, -95.24797468545091, 5.3982034978674704, -31.692998361139637, 77.76511798063852, -13.996702638406529, -28.058269023870576]\n",
            "Bias: [50.37779491399087, -60.78741791313644, 2.554766048233936]\n",
            "Loss for test dataset\n",
            "Test loss: 0.619, r2: -2.274\n",
            "Loss for training dataset\n",
            "Test loss: 0.783, r2: -3.308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = OurNeuralNetwork('tanh')\n",
        "for i in range(1,100,10):\n",
        "  weights = network.train(np.array(X_train), np.array(Y_train),i/100,1000)\n",
        "  print(\"Weights:\", weights[:8])\n",
        "  print(\"Bias:\",weights[8:])\n",
        "  print(\"Loss for test dataset\")\n",
        "  network.test(np.array(X_test), np.array(Y_test), weights)\n",
        "  print(\"Loss for training dataset\")\n",
        "  network.test(np.array(X_train), np.array(Y_train), weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txRPkBxU7PUg",
        "outputId": "1a76fd1b-0eee-43e8-d8bf-703e7901067b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: -1.1504426372103493 -0.19933292252202103 -0.4423220068700846 0.2385979785625798 -1.996956546625807 0.3826116457579378 -2.4563900308554625 -0.9098494421013029\n",
            "Bias: -1.7615194122162483 -1.3181731914392547 -0.7046505960167386\n",
            "Epoch 0 loss: 0.660 r2: 0.046\n",
            "Epoch 10 loss: 0.544 r2: -0.396\n",
            "Epoch 20 loss: 0.544 r2: -0.398\n",
            "Epoch 30 loss: 0.544 r2: -0.399\n",
            "Epoch 40 loss: 0.545 r2: -0.400\n",
            "Epoch 50 loss: 0.545 r2: -0.400\n",
            "Epoch 60 loss: 0.545 r2: -0.399\n",
            "Epoch 70 loss: 0.545 r2: -0.398\n",
            "Epoch 80 loss: 0.545 r2: -0.396\n",
            "Epoch 90 loss: 0.545 r2: -0.395\n",
            "Epoch 100 loss: 0.545 r2: -0.394\n",
            "Epoch 110 loss: 0.545 r2: -0.393\n",
            "Epoch 120 loss: 0.546 r2: -0.393\n",
            "Epoch 130 loss: 0.546 r2: -0.393\n",
            "Epoch 140 loss: 0.546 r2: -0.390\n",
            "Epoch 150 loss: 0.544 r2: -0.374\n",
            "Epoch 160 loss: 0.537 r2: -0.321\n",
            "Epoch 170 loss: 0.532 r2: -0.288\n",
            "Epoch 180 loss: 0.530 r2: -0.280\n",
            "Epoch 190 loss: 0.511 r2: -0.228\n",
            "Epoch 200 loss: 0.486 r2: -0.134\n",
            "Epoch 210 loss: 0.482 r2: -0.123\n",
            "Epoch 220 loss: 0.479 r2: -0.116\n",
            "Epoch 230 loss: 0.473 r2: -0.084\n",
            "Epoch 240 loss: 0.472 r2: -0.055\n",
            "Epoch 250 loss: 0.472 r2: -0.045\n",
            "Epoch 260 loss: 0.472 r2: -0.041\n",
            "Epoch 270 loss: 0.472 r2: -0.038\n",
            "Epoch 280 loss: 0.471 r2: -0.036\n",
            "Epoch 290 loss: 0.471 r2: -0.035\n",
            "Epoch 300 loss: 0.471 r2: -0.034\n",
            "Epoch 310 loss: 0.471 r2: -0.033\n",
            "Epoch 320 loss: 0.471 r2: -0.033\n",
            "Epoch 330 loss: 0.471 r2: -0.032\n",
            "Epoch 340 loss: 0.471 r2: -0.032\n",
            "Epoch 350 loss: 0.471 r2: -0.031\n",
            "Epoch 360 loss: 0.471 r2: -0.031\n",
            "Epoch 370 loss: 0.471 r2: -0.031\n",
            "Epoch 380 loss: 0.471 r2: -0.031\n",
            "Epoch 390 loss: 0.471 r2: -0.030\n",
            "Epoch 400 loss: 0.471 r2: -0.030\n",
            "Epoch 410 loss: 0.471 r2: -0.030\n",
            "Epoch 420 loss: 0.471 r2: -0.030\n",
            "Epoch 430 loss: 0.471 r2: -0.030\n",
            "Epoch 440 loss: 0.471 r2: -0.030\n",
            "Epoch 450 loss: 0.471 r2: -0.030\n",
            "Epoch 460 loss: 0.471 r2: -0.029\n",
            "Epoch 470 loss: 0.471 r2: -0.029\n",
            "Epoch 480 loss: 0.471 r2: -0.029\n",
            "Epoch 490 loss: 0.471 r2: -0.029\n",
            "Epoch 500 loss: 0.471 r2: -0.029\n",
            "Epoch 510 loss: 0.471 r2: -0.029\n",
            "Epoch 520 loss: 0.471 r2: -0.029\n",
            "Epoch 530 loss: 0.471 r2: -0.029\n",
            "Epoch 540 loss: 0.471 r2: -0.029\n",
            "Epoch 550 loss: 0.471 r2: -0.029\n",
            "Epoch 560 loss: 0.471 r2: -0.029\n",
            "Epoch 570 loss: 0.471 r2: -0.029\n",
            "Epoch 580 loss: 0.471 r2: -0.029\n",
            "Epoch 590 loss: 0.471 r2: -0.029\n",
            "Epoch 600 loss: 0.471 r2: -0.029\n",
            "Epoch 610 loss: 0.471 r2: -0.029\n",
            "Epoch 620 loss: 0.471 r2: -0.029\n",
            "Epoch 630 loss: 0.471 r2: -0.029\n",
            "Epoch 640 loss: 0.471 r2: -0.029\n",
            "Epoch 650 loss: 0.471 r2: -0.029\n",
            "Epoch 660 loss: 0.471 r2: -0.029\n",
            "Epoch 670 loss: 0.471 r2: -0.029\n",
            "Epoch 680 loss: 0.471 r2: -0.029\n",
            "Epoch 690 loss: 0.471 r2: -0.029\n",
            "Epoch 700 loss: 0.471 r2: -0.029\n",
            "Epoch 710 loss: 0.471 r2: -0.029\n",
            "Epoch 720 loss: 0.471 r2: -0.029\n",
            "Epoch 730 loss: 0.471 r2: -0.029\n",
            "Epoch 740 loss: 0.471 r2: -0.029\n",
            "Epoch 750 loss: 0.471 r2: -0.029\n",
            "Epoch 760 loss: 0.471 r2: -0.029\n",
            "Epoch 770 loss: 0.471 r2: -0.029\n",
            "Epoch 780 loss: 0.471 r2: -0.029\n",
            "Epoch 790 loss: 0.471 r2: -0.029\n",
            "Epoch 800 loss: 0.471 r2: -0.029\n",
            "Epoch 810 loss: 0.471 r2: -0.029\n",
            "Epoch 820 loss: 0.471 r2: -0.029\n",
            "Epoch 830 loss: 0.471 r2: -0.028\n",
            "Epoch 840 loss: 0.471 r2: -0.028\n",
            "Epoch 850 loss: 0.471 r2: -0.028\n",
            "Epoch 860 loss: 0.471 r2: -0.028\n",
            "Epoch 870 loss: 0.471 r2: -0.028\n",
            "Epoch 880 loss: 0.471 r2: -0.028\n",
            "Epoch 890 loss: 0.471 r2: -0.028\n",
            "Epoch 900 loss: 0.471 r2: -0.028\n",
            "Epoch 910 loss: 0.471 r2: -0.028\n",
            "Epoch 920 loss: 0.471 r2: -0.028\n",
            "Epoch 930 loss: 0.471 r2: -0.028\n",
            "Epoch 940 loss: 0.471 r2: -0.028\n",
            "Epoch 950 loss: 0.471 r2: -0.028\n",
            "Epoch 960 loss: 0.471 r2: -0.028\n",
            "Epoch 970 loss: 0.471 r2: -0.028\n",
            "Epoch 980 loss: 0.471 r2: -0.028\n",
            "Epoch 990 loss: 0.471 r2: -0.028\n",
            "Weights: [-0.6701154246266631, -0.897565492837958, 0.9736958666581346, -0.3307062958247178, -0.6083468149121445, 1.863558471759228, -1.526434719181292, 1.5782986756934105]\n",
            "Bias: [-1.228054223670131, 1.5089852152234475, -2.1867894115020503]\n",
            "Loss for test dataset\n",
            "Test loss: 0.360, r2: 0.158\n",
            "Loss for training dataset\n",
            "Test loss: 0.471, r2: -0.028\n",
            "Epoch 0 loss: 0.558 r2: -0.455\n",
            "Epoch 10 loss: 0.546 r2: -0.308\n",
            "Epoch 20 loss: 0.509 r2: -0.162\n",
            "Epoch 30 loss: 0.503 r2: 0.089\n",
            "Epoch 40 loss: 0.509 r2: 0.018\n",
            "Epoch 50 loss: 0.495 r2: 0.016\n",
            "Epoch 60 loss: 0.509 r2: -0.030\n",
            "Epoch 70 loss: 0.496 r2: -0.089\n",
            "Epoch 80 loss: 0.493 r2: -0.059\n",
            "Epoch 90 loss: 0.489 r2: 0.003\n",
            "Epoch 100 loss: 0.499 r2: 0.116\n",
            "Epoch 110 loss: 0.487 r2: 0.123\n",
            "Epoch 120 loss: 0.501 r2: 0.142\n",
            "Epoch 130 loss: 0.480 r2: 0.074\n",
            "Epoch 140 loss: 0.480 r2: 0.104\n",
            "Epoch 150 loss: 0.480 r2: 0.083\n",
            "Epoch 160 loss: 0.487 r2: 0.182\n",
            "Epoch 170 loss: 0.480 r2: 0.087\n",
            "Epoch 180 loss: 0.478 r2: 0.110\n",
            "Epoch 190 loss: 0.483 r2: 0.149\n",
            "Epoch 200 loss: 0.487 r2: 0.192\n",
            "Epoch 210 loss: 0.481 r2: 0.155\n",
            "Epoch 220 loss: 0.477 r2: 0.112\n",
            "Epoch 230 loss: 0.484 r2: 0.180\n",
            "Epoch 240 loss: 0.476 r2: 0.113\n",
            "Epoch 250 loss: 0.476 r2: 0.120\n",
            "Epoch 260 loss: 0.497 r2: 0.230\n",
            "Epoch 270 loss: 0.505 r2: 0.241\n",
            "Epoch 280 loss: 0.505 r2: 0.240\n",
            "Epoch 290 loss: 0.505 r2: 0.239\n",
            "Epoch 300 loss: 0.495 r2: 0.230\n",
            "Epoch 310 loss: 0.497 r2: 0.236\n",
            "Epoch 320 loss: 0.476 r2: 0.121\n",
            "Epoch 330 loss: 0.487 r2: 0.206\n",
            "Epoch 340 loss: 0.496 r2: 0.233\n",
            "Epoch 350 loss: 0.477 r2: 0.131\n",
            "Epoch 360 loss: 0.491 r2: 0.219\n",
            "Epoch 370 loss: 0.493 r2: 0.223\n",
            "Epoch 380 loss: 0.493 r2: 0.221\n",
            "Epoch 390 loss: 0.492 r2: 0.218\n",
            "Epoch 400 loss: 0.477 r2: 0.098\n",
            "Epoch 410 loss: 0.492 r2: 0.213\n",
            "Epoch 420 loss: 0.492 r2: 0.213\n",
            "Epoch 430 loss: 0.485 r2: 0.180\n",
            "Epoch 440 loss: 0.493 r2: 0.207\n",
            "Epoch 450 loss: 0.490 r2: 0.201\n",
            "Epoch 460 loss: 0.491 r2: 0.200\n",
            "Epoch 470 loss: 0.491 r2: 0.198\n",
            "Epoch 480 loss: 0.491 r2: 0.197\n",
            "Epoch 490 loss: 0.492 r2: 0.196\n",
            "Epoch 500 loss: 0.489 r2: 0.172\n",
            "Epoch 510 loss: 0.488 r2: 0.142\n",
            "Epoch 520 loss: 0.491 r2: 0.194\n",
            "Epoch 530 loss: 0.480 r2: 0.086\n",
            "Epoch 540 loss: 0.487 r2: 0.122\n",
            "Epoch 550 loss: 0.492 r2: 0.190\n",
            "Epoch 560 loss: 0.489 r2: 0.181\n",
            "Epoch 570 loss: 0.493 r2: 0.192\n",
            "Epoch 580 loss: 0.498 r2: 0.197\n",
            "Epoch 590 loss: 0.492 r2: 0.190\n",
            "Epoch 600 loss: 0.492 r2: 0.187\n",
            "Epoch 610 loss: 0.487 r2: 0.152\n",
            "Epoch 620 loss: 0.492 r2: 0.186\n",
            "Epoch 630 loss: 0.478 r2: 0.071\n",
            "Epoch 640 loss: 0.478 r2: 0.070\n",
            "Epoch 650 loss: 0.493 r2: 0.186\n",
            "Epoch 660 loss: 0.492 r2: 0.175\n",
            "Epoch 670 loss: 0.497 r2: 0.189\n",
            "Epoch 680 loss: 0.496 r2: 0.184\n",
            "Epoch 690 loss: 0.496 r2: 0.187\n",
            "Epoch 700 loss: 0.494 r2: 0.183\n",
            "Epoch 710 loss: 0.493 r2: 0.174\n",
            "Epoch 720 loss: 0.492 r2: 0.178\n",
            "Epoch 730 loss: 0.490 r2: 0.167\n",
            "Epoch 740 loss: 0.494 r2: 0.178\n",
            "Epoch 750 loss: 0.491 r2: 0.166\n",
            "Epoch 760 loss: 0.493 r2: 0.176\n",
            "Epoch 770 loss: 0.494 r2: 0.181\n",
            "Epoch 780 loss: 0.494 r2: 0.172\n",
            "Epoch 790 loss: 0.495 r2: 0.173\n",
            "Epoch 800 loss: 0.495 r2: 0.177\n",
            "Epoch 810 loss: 0.494 r2: 0.171\n",
            "Epoch 820 loss: 0.500 r2: 0.188\n",
            "Epoch 830 loss: 0.494 r2: 0.179\n",
            "Epoch 840 loss: 0.496 r2: 0.162\n",
            "Epoch 850 loss: 0.493 r2: 0.174\n",
            "Epoch 860 loss: 0.492 r2: 0.169\n",
            "Epoch 870 loss: 0.495 r2: 0.177\n",
            "Epoch 880 loss: 0.495 r2: 0.169\n",
            "Epoch 890 loss: 0.494 r2: 0.172\n",
            "Epoch 900 loss: 0.497 r2: 0.178\n",
            "Epoch 910 loss: 0.498 r2: 0.187\n",
            "Epoch 920 loss: 0.481 r2: 0.070\n",
            "Epoch 930 loss: 0.478 r2: 0.065\n",
            "Epoch 940 loss: 0.492 r2: 0.165\n",
            "Epoch 950 loss: 0.497 r2: 0.180\n",
            "Epoch 960 loss: 0.493 r2: 0.174\n",
            "Epoch 970 loss: 0.493 r2: 0.166\n",
            "Epoch 980 loss: 0.495 r2: 0.174\n",
            "Epoch 990 loss: 0.496 r2: 0.173\n",
            "Weights: [0.5764371945697995, -3.9661736764799262, 10.644171839946372, -1.13175433459353, 5.279445876404365, 15.96133817067749, -1.2299409324847594, 3.039062099214427]\n",
            "Bias: [-8.718611075894945, 5.206937513089724, -3.493199134381485]\n",
            "Loss for test dataset\n",
            "Test loss: 0.461, r2: 0.123\n",
            "Loss for training dataset\n",
            "Test loss: 0.490, r2: 0.151\n",
            "Epoch 0 loss: 0.631 r2: 0.244\n",
            "Epoch 10 loss: 0.639 r2: 0.246\n",
            "Epoch 20 loss: 0.667 r2: 0.265\n",
            "Epoch 30 loss: 0.501 r2: 0.106\n",
            "Epoch 40 loss: 0.564 r2: 0.226\n",
            "Epoch 50 loss: 0.658 r2: 0.246\n",
            "Epoch 60 loss: 0.519 r2: 0.193\n",
            "Epoch 70 loss: 0.632 r2: 0.253\n",
            "Epoch 80 loss: 0.646 r2: 0.293\n",
            "Epoch 90 loss: 0.668 r2: 0.220\n",
            "Epoch 100 loss: 0.727 r2: 0.183\n",
            "Epoch 110 loss: 0.668 r2: 0.222\n",
            "Epoch 120 loss: 0.661 r2: 0.232\n",
            "Epoch 130 loss: 0.654 r2: 0.247\n",
            "Epoch 140 loss: 0.651 r2: 0.117\n",
            "Epoch 150 loss: 0.646 r2: 0.274\n",
            "Epoch 160 loss: 0.561 r2: 0.198\n",
            "Epoch 170 loss: 0.601 r2: 0.182\n",
            "Epoch 180 loss: 0.598 r2: 0.285\n",
            "Epoch 190 loss: 0.652 r2: 0.254\n",
            "Epoch 200 loss: 0.662 r2: 0.149\n",
            "Epoch 210 loss: 0.671 r2: 0.206\n",
            "Epoch 220 loss: 0.692 r2: 0.183\n",
            "Epoch 230 loss: 0.721 r2: 0.085\n",
            "Epoch 240 loss: 0.676 r2: 0.224\n",
            "Epoch 250 loss: 0.579 r2: 0.207\n",
            "Epoch 260 loss: 0.561 r2: 0.182\n",
            "Epoch 270 loss: 0.684 r2: 0.206\n",
            "Epoch 280 loss: 0.565 r2: 0.205\n",
            "Epoch 290 loss: 0.562 r2: 0.193\n",
            "Epoch 300 loss: 0.562 r2: 0.194\n",
            "Epoch 310 loss: 0.562 r2: 0.194\n",
            "Epoch 320 loss: 0.563 r2: 0.194\n",
            "Epoch 330 loss: 0.567 r2: 0.185\n",
            "Epoch 340 loss: 0.565 r2: 0.208\n",
            "Epoch 350 loss: 0.561 r2: 0.194\n",
            "Epoch 360 loss: 0.563 r2: 0.197\n",
            "Epoch 370 loss: 0.567 r2: 0.186\n",
            "Epoch 380 loss: 0.565 r2: 0.197\n",
            "Epoch 390 loss: 0.563 r2: 0.199\n",
            "Epoch 400 loss: 0.563 r2: 0.192\n",
            "Epoch 410 loss: 0.565 r2: 0.201\n",
            "Epoch 420 loss: 0.566 r2: 0.201\n",
            "Epoch 430 loss: 0.564 r2: 0.200\n",
            "Epoch 440 loss: 0.564 r2: 0.199\n",
            "Epoch 450 loss: 0.591 r2: 0.241\n",
            "Epoch 460 loss: 0.563 r2: 0.198\n",
            "Epoch 470 loss: 0.562 r2: 0.198\n",
            "Epoch 480 loss: 0.567 r2: 0.198\n",
            "Epoch 490 loss: 0.565 r2: 0.202\n",
            "Epoch 500 loss: 0.566 r2: 0.193\n",
            "Epoch 510 loss: 0.562 r2: 0.201\n",
            "Epoch 520 loss: 0.564 r2: 0.203\n",
            "Epoch 530 loss: 0.564 r2: 0.199\n",
            "Epoch 540 loss: 0.563 r2: 0.201\n",
            "Epoch 550 loss: 0.562 r2: 0.200\n",
            "Epoch 560 loss: 0.564 r2: 0.201\n",
            "Epoch 570 loss: 0.649 r2: 0.237\n",
            "Epoch 580 loss: 0.565 r2: 0.199\n",
            "Epoch 590 loss: 0.567 r2: 0.201\n",
            "Epoch 600 loss: 0.563 r2: 0.198\n",
            "Epoch 610 loss: 0.563 r2: 0.207\n",
            "Epoch 620 loss: 0.565 r2: 0.194\n",
            "Epoch 630 loss: 0.566 r2: 0.215\n",
            "Epoch 640 loss: 0.562 r2: 0.199\n",
            "Epoch 650 loss: 0.563 r2: 0.205\n",
            "Epoch 660 loss: 0.563 r2: 0.201\n",
            "Epoch 670 loss: 0.562 r2: 0.198\n",
            "Epoch 680 loss: 0.565 r2: 0.201\n",
            "Epoch 690 loss: 0.568 r2: 0.204\n",
            "Epoch 700 loss: 0.557 r2: 0.193\n",
            "Epoch 710 loss: 0.553 r2: 0.177\n",
            "Epoch 720 loss: 0.563 r2: 0.201\n",
            "Epoch 730 loss: 0.568 r2: 0.203\n",
            "Epoch 740 loss: 0.565 r2: 0.196\n",
            "Epoch 750 loss: 0.557 r2: 0.194\n",
            "Epoch 760 loss: 0.564 r2: 0.202\n",
            "Epoch 770 loss: 0.565 r2: 0.197\n",
            "Epoch 780 loss: 0.571 r2: 0.192\n",
            "Epoch 790 loss: 0.562 r2: 0.205\n",
            "Epoch 800 loss: 0.564 r2: 0.206\n",
            "Epoch 810 loss: 0.568 r2: 0.185\n",
            "Epoch 820 loss: 0.569 r2: 0.205\n",
            "Epoch 830 loss: 0.566 r2: 0.205\n",
            "Epoch 840 loss: 0.634 r2: 0.261\n",
            "Epoch 850 loss: 0.566 r2: 0.203\n",
            "Epoch 860 loss: 0.566 r2: 0.202\n",
            "Epoch 870 loss: 0.566 r2: 0.202\n",
            "Epoch 880 loss: 0.566 r2: 0.202\n",
            "Epoch 890 loss: 0.566 r2: 0.202\n",
            "Epoch 900 loss: 0.566 r2: 0.203\n",
            "Epoch 910 loss: 0.566 r2: 0.203\n",
            "Epoch 920 loss: 0.565 r2: 0.202\n",
            "Epoch 930 loss: 0.565 r2: 0.202\n",
            "Epoch 940 loss: 0.565 r2: 0.202\n",
            "Epoch 950 loss: 0.565 r2: 0.203\n",
            "Epoch 960 loss: 0.565 r2: 0.203\n",
            "Epoch 970 loss: 0.565 r2: 0.202\n",
            "Epoch 980 loss: 0.563 r2: 0.207\n",
            "Epoch 990 loss: 0.563 r2: 0.209\n",
            "Weights: [-3.388939511058048, -17.43011109106766, 17.043788001589686, -3.8653912616648625, 5.943184452472634, 25.389407755110515, -1.1028157707975024, 3.061309120797216]\n",
            "Bias: [-12.242173354022617, 8.181905579461915, -3.0153276254565973]\n",
            "Loss for test dataset\n",
            "Test loss: 0.556, r2: 0.204\n",
            "Loss for training dataset\n",
            "Test loss: 0.565, r2: 0.203\n",
            "Epoch 0 loss: 0.623 r2: 0.230\n",
            "Epoch 10 loss: 0.657 r2: 0.245\n",
            "Epoch 20 loss: 0.646 r2: 0.263\n",
            "Epoch 30 loss: 0.601 r2: 0.260\n",
            "Epoch 40 loss: 0.624 r2: 0.258\n",
            "Epoch 50 loss: 0.624 r2: 0.267\n",
            "Epoch 60 loss: 0.669 r2: 0.275\n",
            "Epoch 70 loss: 0.661 r2: 0.260\n",
            "Epoch 80 loss: 0.650 r2: 0.253\n",
            "Epoch 90 loss: 0.632 r2: 0.281\n",
            "Epoch 100 loss: 0.622 r2: 0.270\n",
            "Epoch 110 loss: 0.644 r2: 0.264\n",
            "Epoch 120 loss: 0.644 r2: 0.264\n",
            "Epoch 130 loss: 0.645 r2: 0.273\n",
            "Epoch 140 loss: 0.646 r2: 0.262\n",
            "Epoch 150 loss: 0.642 r2: 0.271\n",
            "Epoch 160 loss: 0.623 r2: 0.269\n",
            "Epoch 170 loss: 0.638 r2: 0.272\n",
            "Epoch 180 loss: 0.645 r2: 0.262\n",
            "Epoch 190 loss: 0.647 r2: 0.259\n",
            "Epoch 200 loss: 0.551 r2: 0.250\n",
            "Epoch 210 loss: 0.647 r2: 0.256\n",
            "Epoch 220 loss: 0.646 r2: 0.248\n",
            "Epoch 230 loss: 0.625 r2: 0.273\n",
            "Epoch 240 loss: 0.625 r2: 0.271\n",
            "Epoch 250 loss: 0.622 r2: 0.262\n",
            "Epoch 260 loss: 0.624 r2: 0.264\n",
            "Epoch 270 loss: 0.649 r2: 0.277\n",
            "Epoch 280 loss: 0.660 r2: 0.248\n",
            "Epoch 290 loss: 0.649 r2: 0.263\n",
            "Epoch 300 loss: 0.644 r2: 0.266\n",
            "Epoch 310 loss: 0.643 r2: 0.277\n",
            "Epoch 320 loss: 0.720 r2: 0.188\n",
            "Epoch 330 loss: 0.649 r2: 0.266\n",
            "Epoch 340 loss: 0.648 r2: 0.270\n",
            "Epoch 350 loss: 0.642 r2: 0.260\n",
            "Epoch 360 loss: 0.657 r2: 0.259\n",
            "Epoch 370 loss: 0.656 r2: 0.257\n",
            "Epoch 380 loss: 0.656 r2: 0.257\n",
            "Epoch 390 loss: 0.656 r2: 0.249\n",
            "Epoch 400 loss: 0.721 r2: 0.200\n",
            "Epoch 410 loss: 0.704 r2: 0.203\n",
            "Epoch 420 loss: 0.658 r2: 0.242\n",
            "Epoch 430 loss: 0.668 r2: 0.239\n",
            "Epoch 440 loss: 0.665 r2: 0.235\n",
            "Epoch 450 loss: 0.655 r2: 0.259\n",
            "Epoch 460 loss: 0.613 r2: 0.266\n",
            "Epoch 470 loss: 0.659 r2: 0.265\n",
            "Epoch 480 loss: 0.652 r2: 0.248\n",
            "Epoch 490 loss: 0.658 r2: 0.267\n",
            "Epoch 500 loss: 0.652 r2: 0.252\n",
            "Epoch 510 loss: 0.651 r2: 0.251\n",
            "Epoch 520 loss: 0.656 r2: 0.259\n",
            "Epoch 530 loss: 0.656 r2: 0.259\n",
            "Epoch 540 loss: 0.656 r2: 0.259\n",
            "Epoch 550 loss: 0.654 r2: 0.256\n",
            "Epoch 560 loss: 0.648 r2: 0.257\n",
            "Epoch 570 loss: 0.650 r2: 0.258\n",
            "Epoch 580 loss: 0.642 r2: 0.272\n",
            "Epoch 590 loss: 0.653 r2: 0.275\n",
            "Epoch 600 loss: 0.648 r2: 0.257\n",
            "Epoch 610 loss: 0.648 r2: 0.256\n",
            "Epoch 620 loss: 0.648 r2: 0.257\n",
            "Epoch 630 loss: 0.647 r2: 0.257\n",
            "Epoch 640 loss: 0.648 r2: 0.256\n",
            "Epoch 650 loss: 0.641 r2: 0.251\n",
            "Epoch 660 loss: 0.651 r2: 0.273\n",
            "Epoch 670 loss: 0.648 r2: 0.257\n",
            "Epoch 680 loss: 0.662 r2: 0.259\n",
            "Epoch 690 loss: 0.648 r2: 0.257\n",
            "Epoch 700 loss: 0.645 r2: 0.259\n",
            "Epoch 710 loss: 0.649 r2: 0.261\n",
            "Epoch 720 loss: 0.649 r2: 0.262\n",
            "Epoch 730 loss: 0.648 r2: 0.262\n",
            "Epoch 740 loss: 0.642 r2: 0.257\n",
            "Epoch 750 loss: 0.644 r2: 0.264\n",
            "Epoch 760 loss: 0.641 r2: 0.266\n",
            "Epoch 770 loss: 0.646 r2: 0.263\n",
            "Epoch 780 loss: 0.645 r2: 0.265\n",
            "Epoch 790 loss: 0.650 r2: 0.268\n",
            "Epoch 800 loss: 0.650 r2: 0.267\n",
            "Epoch 810 loss: 0.649 r2: 0.263\n",
            "Epoch 820 loss: 0.649 r2: 0.258\n",
            "Epoch 830 loss: 0.647 r2: 0.257\n",
            "Epoch 840 loss: 0.649 r2: 0.269\n",
            "Epoch 850 loss: 0.647 r2: 0.280\n",
            "Epoch 860 loss: 0.628 r2: 0.279\n",
            "Epoch 870 loss: 0.624 r2: 0.273\n",
            "Epoch 880 loss: 0.646 r2: 0.261\n",
            "Epoch 890 loss: 0.646 r2: 0.276\n",
            "Epoch 900 loss: 0.650 r2: 0.268\n",
            "Epoch 910 loss: 0.648 r2: 0.267\n",
            "Epoch 920 loss: 0.650 r2: 0.267\n",
            "Epoch 930 loss: 0.647 r2: 0.264\n",
            "Epoch 940 loss: 0.649 r2: 0.264\n",
            "Epoch 950 loss: 0.649 r2: 0.262\n",
            "Epoch 960 loss: 0.648 r2: 0.253\n",
            "Epoch 970 loss: 0.652 r2: 0.270\n",
            "Epoch 980 loss: 0.648 r2: 0.253\n",
            "Epoch 990 loss: 0.624 r2: 0.264\n",
            "Weights: [-12.252939295442935, -20.411394625334363, 12.8140239101779, -5.00670719900612, 7.29841252575487, 29.918994085320644, -4.447513769148066, 4.690090287502753]\n",
            "Bias: [-15.461761956955, 8.572736657143782, -1.7008373878787406]\n",
            "Loss for test dataset\n",
            "Test loss: 0.597, r2: 0.289\n",
            "Loss for training dataset\n",
            "Test loss: 0.647, r2: 0.251\n",
            "Epoch 0 loss: 0.652 r2: 0.271\n",
            "Epoch 10 loss: 0.653 r2: 0.276\n",
            "Epoch 20 loss: 0.652 r2: 0.271\n",
            "Epoch 30 loss: 0.654 r2: 0.249\n",
            "Epoch 40 loss: 0.649 r2: 0.261\n",
            "Epoch 50 loss: 0.653 r2: 0.276\n",
            "Epoch 60 loss: 0.649 r2: 0.261\n",
            "Epoch 70 loss: 0.649 r2: 0.261\n",
            "Epoch 80 loss: 0.649 r2: 0.264\n",
            "Epoch 90 loss: 0.648 r2: 0.261\n",
            "Epoch 100 loss: 0.649 r2: 0.261\n",
            "Epoch 110 loss: 0.649 r2: 0.260\n",
            "Epoch 120 loss: 0.649 r2: 0.260\n",
            "Epoch 130 loss: 0.648 r2: 0.261\n",
            "Epoch 140 loss: 0.652 r2: 0.245\n",
            "Epoch 150 loss: 0.654 r2: 0.250\n",
            "Epoch 160 loss: 0.654 r2: 0.251\n",
            "Epoch 170 loss: 0.654 r2: 0.251\n",
            "Epoch 180 loss: 0.633 r2: 0.234\n",
            "Epoch 190 loss: 0.568 r2: 0.168\n",
            "Epoch 200 loss: 0.686 r2: 0.235\n",
            "Epoch 210 loss: 0.689 r2: 0.240\n",
            "Epoch 220 loss: 0.682 r2: 0.233\n",
            "Epoch 230 loss: 0.683 r2: 0.233\n",
            "Epoch 240 loss: 0.679 r2: 0.230\n",
            "Epoch 250 loss: 0.684 r2: 0.233\n",
            "Epoch 260 loss: 0.682 r2: 0.231\n",
            "Epoch 270 loss: 0.686 r2: 0.235\n",
            "Epoch 280 loss: 0.685 r2: 0.231\n",
            "Epoch 290 loss: 0.685 r2: 0.259\n",
            "Epoch 300 loss: 0.962 r2: -0.298\n",
            "Epoch 310 loss: 0.962 r2: -0.298\n",
            "Epoch 320 loss: 0.962 r2: -0.298\n",
            "Epoch 330 loss: 0.962 r2: -0.297\n",
            "Epoch 340 loss: 0.962 r2: -0.297\n",
            "Epoch 350 loss: 0.962 r2: -0.297\n",
            "Epoch 360 loss: 0.962 r2: -0.297\n",
            "Epoch 370 loss: 0.962 r2: -0.297\n",
            "Epoch 380 loss: 0.962 r2: -0.297\n",
            "Epoch 390 loss: 0.962 r2: -0.297\n",
            "Epoch 400 loss: 0.962 r2: -0.297\n",
            "Epoch 410 loss: 0.962 r2: -0.297\n",
            "Epoch 420 loss: 0.962 r2: -0.297\n",
            "Epoch 430 loss: 0.962 r2: -0.297\n",
            "Epoch 440 loss: 0.962 r2: -0.297\n",
            "Epoch 450 loss: 0.962 r2: -0.297\n",
            "Epoch 460 loss: 0.962 r2: -0.297\n",
            "Epoch 470 loss: 0.962 r2: -0.297\n",
            "Epoch 480 loss: 0.962 r2: -0.297\n",
            "Epoch 490 loss: 0.962 r2: -0.297\n",
            "Epoch 500 loss: 0.962 r2: -0.297\n",
            "Epoch 510 loss: 0.962 r2: -0.297\n",
            "Epoch 520 loss: 0.962 r2: -0.297\n",
            "Epoch 530 loss: 0.962 r2: -0.297\n",
            "Epoch 540 loss: 0.962 r2: -0.297\n",
            "Epoch 550 loss: 0.962 r2: -0.297\n",
            "Epoch 560 loss: 0.962 r2: -0.297\n",
            "Epoch 570 loss: 0.962 r2: -0.297\n",
            "Epoch 580 loss: 0.962 r2: -0.297\n",
            "Epoch 590 loss: 0.962 r2: -0.297\n",
            "Epoch 600 loss: 0.962 r2: -0.297\n",
            "Epoch 610 loss: 0.962 r2: -0.297\n",
            "Epoch 620 loss: 0.962 r2: -0.297\n",
            "Epoch 630 loss: 0.962 r2: -0.297\n",
            "Epoch 640 loss: 0.962 r2: -0.297\n",
            "Epoch 650 loss: 0.962 r2: -0.297\n",
            "Epoch 660 loss: 0.962 r2: -0.297\n",
            "Epoch 670 loss: 0.962 r2: -0.297\n",
            "Epoch 680 loss: 0.962 r2: -0.297\n",
            "Epoch 690 loss: 0.962 r2: -0.297\n",
            "Epoch 700 loss: 0.962 r2: -0.297\n",
            "Epoch 710 loss: 0.962 r2: -0.297\n",
            "Epoch 720 loss: 0.962 r2: -0.297\n",
            "Epoch 730 loss: 0.962 r2: -0.297\n",
            "Epoch 740 loss: 0.962 r2: -0.297\n",
            "Epoch 750 loss: 0.962 r2: -0.297\n",
            "Epoch 760 loss: 0.962 r2: -0.297\n",
            "Epoch 770 loss: 0.962 r2: -0.297\n",
            "Epoch 780 loss: 0.962 r2: -0.297\n",
            "Epoch 790 loss: 0.962 r2: -0.297\n",
            "Epoch 800 loss: 0.962 r2: -0.297\n",
            "Epoch 810 loss: 0.962 r2: -0.297\n",
            "Epoch 820 loss: 0.962 r2: -0.297\n",
            "Epoch 830 loss: 0.962 r2: -0.297\n",
            "Epoch 840 loss: 0.962 r2: -0.297\n",
            "Epoch 850 loss: 0.962 r2: -0.297\n",
            "Epoch 860 loss: 0.962 r2: -0.297\n",
            "Epoch 870 loss: 0.962 r2: -0.297\n",
            "Epoch 880 loss: 0.962 r2: -0.297\n",
            "Epoch 890 loss: 0.962 r2: -0.297\n",
            "Epoch 900 loss: 0.962 r2: -0.297\n",
            "Epoch 910 loss: 0.962 r2: -0.297\n",
            "Epoch 920 loss: 0.962 r2: -0.297\n",
            "Epoch 930 loss: 0.962 r2: -0.298\n",
            "Epoch 940 loss: 0.974 r2: -0.324\n",
            "Epoch 950 loss: 0.974 r2: -0.325\n",
            "Epoch 960 loss: 0.974 r2: -0.325\n",
            "Epoch 970 loss: 0.974 r2: -0.325\n",
            "Epoch 980 loss: 0.974 r2: -0.325\n",
            "Epoch 990 loss: 0.974 r2: -0.325\n",
            "Weights: [-2.9565174568932537, -28.03133865069354, 18.801963182835586, -3.8196281830756, 7.969611291422635, 31.561744767575593, -2.4623579759295, 7.507203970357229]\n",
            "Bias: [-23.877975893198386, 11.791613402210768, 2.2679681959869296]\n",
            "Loss for test dataset\n",
            "Test loss: 0.823, r2: -0.231\n",
            "Loss for training dataset\n",
            "Test loss: 0.974, r2: -0.325\n",
            "Epoch 0 loss: 0.974 r2: -0.324\n",
            "Epoch 10 loss: 0.974 r2: -0.324\n",
            "Epoch 20 loss: 0.974 r2: -0.324\n",
            "Epoch 30 loss: 0.974 r2: -0.324\n",
            "Epoch 40 loss: 0.974 r2: -0.324\n",
            "Epoch 50 loss: 0.974 r2: -0.324\n",
            "Epoch 60 loss: 0.974 r2: -0.324\n",
            "Epoch 70 loss: 0.974 r2: -0.324\n",
            "Epoch 80 loss: 0.974 r2: -0.324\n",
            "Epoch 90 loss: 0.974 r2: -0.324\n",
            "Epoch 100 loss: 0.974 r2: -0.324\n",
            "Epoch 110 loss: 0.974 r2: -0.324\n",
            "Epoch 120 loss: 0.974 r2: -0.324\n",
            "Epoch 130 loss: 0.974 r2: -0.324\n",
            "Epoch 140 loss: 0.974 r2: -0.324\n",
            "Epoch 150 loss: 0.974 r2: -0.324\n",
            "Epoch 160 loss: 0.974 r2: -0.324\n",
            "Epoch 170 loss: 0.974 r2: -0.324\n",
            "Epoch 180 loss: 0.974 r2: -0.323\n",
            "Epoch 190 loss: 0.968 r2: -0.305\n",
            "Epoch 200 loss: 0.968 r2: -0.307\n",
            "Epoch 210 loss: 0.968 r2: -0.308\n",
            "Epoch 220 loss: 0.968 r2: -0.308\n",
            "Epoch 230 loss: 0.968 r2: -0.309\n",
            "Epoch 240 loss: 0.968 r2: -0.309\n",
            "Epoch 250 loss: 0.974 r2: -0.329\n",
            "Epoch 260 loss: 0.974 r2: -0.325\n",
            "Epoch 270 loss: 1.118 r2: -0.240\n",
            "Epoch 280 loss: 1.385 r2: -1.255\n",
            "Epoch 290 loss: 1.375 r2: -1.428\n",
            "Epoch 300 loss: 1.373 r2: -1.481\n",
            "Epoch 310 loss: 1.372 r2: -1.447\n",
            "Epoch 320 loss: 1.121 r2: -0.678\n",
            "Epoch 330 loss: 1.121 r2: -0.679\n",
            "Epoch 340 loss: 1.124 r2: -0.647\n",
            "Epoch 350 loss: 1.124 r2: -0.646\n",
            "Epoch 360 loss: 1.124 r2: -0.646\n",
            "Epoch 370 loss: 1.124 r2: -0.646\n",
            "Epoch 380 loss: 1.124 r2: -0.646\n",
            "Epoch 390 loss: 1.124 r2: -0.646\n",
            "Epoch 400 loss: 1.124 r2: -0.646\n",
            "Epoch 410 loss: 1.124 r2: -0.646\n",
            "Epoch 420 loss: 1.124 r2: -0.646\n",
            "Epoch 430 loss: 1.124 r2: -0.646\n",
            "Epoch 440 loss: 1.124 r2: -0.646\n",
            "Epoch 450 loss: 1.124 r2: -0.646\n",
            "Epoch 460 loss: 1.124 r2: -0.646\n",
            "Epoch 470 loss: 1.124 r2: -0.646\n",
            "Epoch 480 loss: 1.124 r2: -0.646\n",
            "Epoch 490 loss: 1.124 r2: -0.646\n",
            "Epoch 500 loss: 1.124 r2: -0.646\n",
            "Epoch 510 loss: 1.124 r2: -0.646\n",
            "Epoch 520 loss: 1.124 r2: -0.646\n",
            "Epoch 530 loss: 1.124 r2: -0.646\n",
            "Epoch 540 loss: 1.124 r2: -0.646\n",
            "Epoch 550 loss: 1.124 r2: -0.646\n",
            "Epoch 560 loss: 1.124 r2: -0.646\n",
            "Epoch 570 loss: 1.124 r2: -0.646\n",
            "Epoch 580 loss: 1.124 r2: -0.646\n",
            "Epoch 590 loss: 1.124 r2: -0.646\n",
            "Epoch 600 loss: 1.124 r2: -0.646\n",
            "Epoch 610 loss: 1.124 r2: -0.646\n",
            "Epoch 620 loss: 1.124 r2: -0.646\n",
            "Epoch 630 loss: 1.124 r2: -0.646\n",
            "Epoch 640 loss: 1.124 r2: -0.646\n",
            "Epoch 650 loss: 1.124 r2: -0.646\n",
            "Epoch 660 loss: 1.124 r2: -0.646\n",
            "Epoch 670 loss: 1.124 r2: -0.646\n",
            "Epoch 680 loss: 1.124 r2: -0.646\n",
            "Epoch 690 loss: 1.124 r2: -0.646\n",
            "Epoch 700 loss: 1.124 r2: -0.646\n",
            "Epoch 710 loss: 1.124 r2: -0.646\n",
            "Epoch 720 loss: 1.124 r2: -0.646\n",
            "Epoch 730 loss: 1.124 r2: -0.646\n",
            "Epoch 740 loss: 1.124 r2: -0.646\n",
            "Epoch 750 loss: 1.124 r2: -0.646\n",
            "Epoch 760 loss: 1.124 r2: -0.646\n",
            "Epoch 770 loss: 1.124 r2: -0.646\n",
            "Epoch 780 loss: 1.124 r2: -0.646\n",
            "Epoch 790 loss: 1.124 r2: -0.646\n",
            "Epoch 800 loss: 1.124 r2: -0.646\n",
            "Epoch 810 loss: 1.124 r2: -0.646\n",
            "Epoch 820 loss: 1.124 r2: -0.646\n",
            "Epoch 830 loss: 1.124 r2: -0.646\n",
            "Epoch 840 loss: 1.124 r2: -0.646\n",
            "Epoch 850 loss: 1.124 r2: -0.646\n",
            "Epoch 860 loss: 1.124 r2: -0.646\n",
            "Epoch 870 loss: 1.124 r2: -0.646\n",
            "Epoch 880 loss: 1.124 r2: -0.646\n",
            "Epoch 890 loss: 1.124 r2: -0.646\n",
            "Epoch 900 loss: 1.124 r2: -0.646\n",
            "Epoch 910 loss: 1.124 r2: -0.646\n",
            "Epoch 920 loss: 1.124 r2: -0.646\n",
            "Epoch 930 loss: 1.124 r2: -0.646\n",
            "Epoch 940 loss: 1.124 r2: -0.646\n",
            "Epoch 950 loss: 1.124 r2: -0.646\n",
            "Epoch 960 loss: 1.124 r2: -0.646\n",
            "Epoch 970 loss: 1.124 r2: -0.646\n",
            "Epoch 980 loss: 1.124 r2: -0.646\n",
            "Epoch 990 loss: 1.124 r2: -0.646\n",
            "Weights: [-8.087736899179774, -39.02746462990261, 9.771738045338152, 7.792259011577745, 11.852843099528961, 35.766082986500514, -9.63326144967415, 2.6420505421313516]\n",
            "Bias: [-14.826816260778493, 1.8220801490814966, 5.715964233801407]\n",
            "Loss for test dataset\n",
            "Test loss: 1.051, r2: -0.619\n",
            "Loss for training dataset\n",
            "Test loss: 1.124, r2: -0.646\n",
            "Epoch 0 loss: 1.129 r2: -0.597\n",
            "Epoch 10 loss: 1.131 r2: -0.581\n",
            "Epoch 20 loss: 1.129 r2: -0.600\n",
            "Epoch 30 loss: 1.142 r2: -0.577\n",
            "Epoch 40 loss: 0.831 r2: 0.054\n",
            "Epoch 50 loss: 0.831 r2: 0.052\n",
            "Epoch 60 loss: 0.828 r2: 0.046\n",
            "Epoch 70 loss: 0.831 r2: 0.052\n",
            "Epoch 80 loss: 0.829 r2: 0.048\n",
            "Epoch 90 loss: 0.830 r2: 0.049\n",
            "Epoch 100 loss: 0.829 r2: 0.047\n",
            "Epoch 110 loss: 0.829 r2: 0.047\n",
            "Epoch 120 loss: 0.832 r2: 0.054\n",
            "Epoch 130 loss: 0.821 r2: 0.026\n",
            "Epoch 140 loss: 0.832 r2: 0.054\n",
            "Epoch 150 loss: 0.832 r2: 0.054\n",
            "Epoch 160 loss: 0.819 r2: 0.018\n",
            "Epoch 170 loss: 0.831 r2: 0.052\n",
            "Epoch 180 loss: 0.823 r2: 0.031\n",
            "Epoch 190 loss: 0.829 r2: 0.048\n",
            "Epoch 200 loss: 0.832 r2: 0.054\n",
            "Epoch 210 loss: 0.831 r2: 0.053\n",
            "Epoch 220 loss: 0.832 r2: 0.054\n",
            "Epoch 230 loss: 0.831 r2: 0.052\n",
            "Epoch 240 loss: 0.831 r2: 0.053\n",
            "Epoch 250 loss: 0.832 r2: 0.054\n",
            "Epoch 260 loss: 0.832 r2: 0.054\n",
            "Epoch 270 loss: 0.832 r2: 0.054\n",
            "Epoch 280 loss: 0.832 r2: 0.054\n",
            "Epoch 290 loss: 0.831 r2: 0.053\n",
            "Epoch 300 loss: 0.829 r2: 0.047\n",
            "Epoch 310 loss: 0.831 r2: 0.054\n",
            "Epoch 320 loss: 0.829 r2: 0.047\n",
            "Epoch 330 loss: 0.831 r2: 0.053\n",
            "Epoch 340 loss: 0.829 r2: 0.048\n",
            "Epoch 350 loss: 0.832 r2: 0.054\n",
            "Epoch 360 loss: 0.832 r2: 0.054\n",
            "Epoch 370 loss: 0.831 r2: 0.053\n",
            "Epoch 380 loss: 0.828 r2: 0.046\n",
            "Epoch 390 loss: 0.821 r2: 0.025\n",
            "Epoch 400 loss: 0.832 r2: 0.054\n",
            "Epoch 410 loss: 0.832 r2: 0.054\n",
            "Epoch 420 loss: 0.822 r2: 0.027\n",
            "Epoch 430 loss: 0.828 r2: 0.046\n",
            "Epoch 440 loss: 0.831 r2: 0.053\n",
            "Epoch 450 loss: 0.830 r2: 0.050\n",
            "Epoch 460 loss: 0.831 r2: 0.053\n",
            "Epoch 470 loss: 0.831 r2: 0.053\n",
            "Epoch 480 loss: 0.817 r2: 0.009\n",
            "Epoch 490 loss: 0.832 r2: 0.054\n",
            "Epoch 500 loss: 0.832 r2: 0.054\n",
            "Epoch 510 loss: 0.832 r2: 0.054\n",
            "Epoch 520 loss: 0.832 r2: 0.054\n",
            "Epoch 530 loss: 0.831 r2: 0.051\n",
            "Epoch 540 loss: 0.832 r2: 0.054\n",
            "Epoch 550 loss: 0.830 r2: 0.049\n",
            "Epoch 560 loss: 0.832 r2: 0.054\n",
            "Epoch 570 loss: 0.831 r2: 0.053\n",
            "Epoch 580 loss: 0.832 r2: 0.054\n",
            "Epoch 590 loss: 0.830 r2: 0.050\n",
            "Epoch 600 loss: 0.832 r2: 0.054\n",
            "Epoch 610 loss: 0.829 r2: 0.047\n",
            "Epoch 620 loss: 0.832 r2: 0.054\n",
            "Epoch 630 loss: 0.830 r2: 0.051\n",
            "Epoch 640 loss: 0.820 r2: 0.019\n",
            "Epoch 650 loss: 0.832 r2: 0.054\n",
            "Epoch 660 loss: 0.818 r2: 0.010\n",
            "Epoch 670 loss: 0.828 r2: 0.046\n",
            "Epoch 680 loss: 0.832 r2: 0.054\n",
            "Epoch 690 loss: 0.829 r2: 0.048\n",
            "Epoch 700 loss: 0.828 r2: 0.046\n",
            "Epoch 710 loss: 0.831 r2: 0.051\n",
            "Epoch 720 loss: 0.828 r2: 0.046\n",
            "Epoch 730 loss: 0.832 r2: 0.054\n",
            "Epoch 740 loss: 0.819 r2: 0.015\n",
            "Epoch 750 loss: 0.832 r2: 0.054\n",
            "Epoch 760 loss: 0.832 r2: 0.054\n",
            "Epoch 770 loss: 0.832 r2: 0.054\n",
            "Epoch 780 loss: 0.818 r2: 0.010\n",
            "Epoch 790 loss: 0.817 r2: 0.009\n",
            "Epoch 800 loss: 0.830 r2: 0.051\n",
            "Epoch 810 loss: 0.832 r2: 0.054\n",
            "Epoch 820 loss: 0.827 r2: 0.042\n",
            "Epoch 830 loss: 0.832 r2: 0.054\n",
            "Epoch 840 loss: 0.832 r2: 0.054\n",
            "Epoch 850 loss: 0.830 r2: 0.051\n",
            "Epoch 860 loss: 0.831 r2: 0.053\n",
            "Epoch 870 loss: 0.822 r2: 0.027\n",
            "Epoch 880 loss: 0.832 r2: 0.054\n",
            "Epoch 890 loss: 0.832 r2: 0.054\n",
            "Epoch 900 loss: 0.832 r2: 0.054\n",
            "Epoch 910 loss: 0.831 r2: 0.052\n",
            "Epoch 920 loss: 0.829 r2: 0.047\n",
            "Epoch 930 loss: 0.828 r2: 0.046\n",
            "Epoch 940 loss: 0.832 r2: 0.054\n",
            "Epoch 950 loss: 0.832 r2: 0.054\n",
            "Epoch 960 loss: 0.828 r2: 0.046\n",
            "Epoch 970 loss: 0.832 r2: 0.054\n",
            "Epoch 980 loss: 0.832 r2: 0.054\n",
            "Epoch 990 loss: 0.818 r2: 0.011\n",
            "Weights: [-10.511195592152667, -44.23842190989023, -3.7319783291880033, 7.805561565111002, 11.812633199213732, 35.78028416999113, -10.348400608613407, 3.628699307820867]\n",
            "Bias: [-9.993607077707235, 1.8584540228249726, 4.491635692393495]\n",
            "Loss for test dataset\n",
            "Test loss: 0.671, r2: 0.256\n",
            "Loss for training dataset\n",
            "Test loss: 0.830, r2: 0.049\n",
            "Epoch 0 loss: 0.832 r2: 0.054\n",
            "Epoch 10 loss: 0.832 r2: 0.054\n",
            "Epoch 20 loss: 0.831 r2: 0.053\n",
            "Epoch 30 loss: 0.819 r2: 0.015\n",
            "Epoch 40 loss: 0.819 r2: 0.015\n",
            "Epoch 50 loss: 0.819 r2: 0.015\n",
            "Epoch 60 loss: 0.819 r2: 0.015\n",
            "Epoch 70 loss: 0.819 r2: 0.015\n",
            "Epoch 80 loss: 0.819 r2: 0.015\n",
            "Epoch 90 loss: 0.819 r2: 0.015\n",
            "Epoch 100 loss: 0.819 r2: 0.015\n",
            "Epoch 110 loss: 0.819 r2: 0.015\n",
            "Epoch 120 loss: 0.819 r2: 0.015\n",
            "Epoch 130 loss: 0.819 r2: 0.015\n",
            "Epoch 140 loss: 0.819 r2: 0.015\n",
            "Epoch 150 loss: 0.819 r2: 0.015\n",
            "Epoch 160 loss: 0.819 r2: 0.015\n",
            "Epoch 170 loss: 0.819 r2: 0.015\n",
            "Epoch 180 loss: 0.819 r2: 0.015\n",
            "Epoch 190 loss: 0.819 r2: 0.015\n",
            "Epoch 200 loss: 0.819 r2: 0.015\n",
            "Epoch 210 loss: 0.819 r2: 0.015\n",
            "Epoch 220 loss: 0.819 r2: 0.015\n",
            "Epoch 230 loss: 0.819 r2: 0.015\n",
            "Epoch 240 loss: 0.819 r2: 0.015\n",
            "Epoch 250 loss: 0.819 r2: 0.015\n",
            "Epoch 260 loss: 0.819 r2: 0.015\n",
            "Epoch 270 loss: 0.819 r2: 0.015\n",
            "Epoch 280 loss: 0.819 r2: 0.015\n",
            "Epoch 290 loss: 0.819 r2: 0.015\n",
            "Epoch 300 loss: 0.819 r2: 0.015\n",
            "Epoch 310 loss: 0.819 r2: 0.015\n",
            "Epoch 320 loss: 0.819 r2: 0.015\n",
            "Epoch 330 loss: 0.819 r2: 0.015\n",
            "Epoch 340 loss: 0.819 r2: 0.015\n",
            "Epoch 350 loss: 0.819 r2: 0.015\n",
            "Epoch 360 loss: 0.819 r2: 0.015\n",
            "Epoch 370 loss: 0.819 r2: 0.015\n",
            "Epoch 380 loss: 0.819 r2: 0.015\n",
            "Epoch 390 loss: 0.819 r2: 0.015\n",
            "Epoch 400 loss: 0.819 r2: 0.015\n",
            "Epoch 410 loss: 0.819 r2: 0.015\n",
            "Epoch 420 loss: 0.819 r2: 0.015\n",
            "Epoch 430 loss: 0.819 r2: 0.015\n",
            "Epoch 440 loss: 0.819 r2: 0.015\n",
            "Epoch 450 loss: 0.819 r2: 0.015\n",
            "Epoch 460 loss: 0.819 r2: 0.015\n",
            "Epoch 470 loss: 0.819 r2: 0.015\n",
            "Epoch 480 loss: 0.819 r2: 0.015\n",
            "Epoch 490 loss: 0.819 r2: 0.015\n",
            "Epoch 500 loss: 0.819 r2: 0.015\n",
            "Epoch 510 loss: 0.819 r2: 0.015\n",
            "Epoch 520 loss: 0.819 r2: 0.015\n",
            "Epoch 530 loss: 0.819 r2: 0.015\n",
            "Epoch 540 loss: 0.819 r2: 0.015\n",
            "Epoch 550 loss: 0.819 r2: 0.015\n",
            "Epoch 560 loss: 0.819 r2: 0.015\n",
            "Epoch 570 loss: 0.819 r2: 0.015\n",
            "Epoch 580 loss: 0.819 r2: 0.015\n",
            "Epoch 590 loss: 0.819 r2: 0.015\n",
            "Epoch 600 loss: 0.819 r2: 0.015\n",
            "Epoch 610 loss: 0.819 r2: 0.015\n",
            "Epoch 620 loss: 0.819 r2: 0.015\n",
            "Epoch 630 loss: 0.819 r2: 0.015\n",
            "Epoch 640 loss: 0.819 r2: 0.015\n",
            "Epoch 650 loss: 0.819 r2: 0.015\n",
            "Epoch 660 loss: 0.819 r2: 0.015\n",
            "Epoch 670 loss: 0.819 r2: 0.015\n",
            "Epoch 680 loss: 0.819 r2: 0.015\n",
            "Epoch 690 loss: 0.819 r2: 0.015\n",
            "Epoch 700 loss: 0.819 r2: 0.015\n",
            "Epoch 710 loss: 0.819 r2: 0.015\n",
            "Epoch 720 loss: 0.819 r2: 0.015\n",
            "Epoch 730 loss: 0.819 r2: 0.015\n",
            "Epoch 740 loss: 0.819 r2: 0.015\n",
            "Epoch 750 loss: 0.819 r2: 0.015\n",
            "Epoch 760 loss: 0.819 r2: 0.015\n",
            "Epoch 770 loss: 0.819 r2: 0.015\n",
            "Epoch 780 loss: 0.819 r2: 0.015\n",
            "Epoch 790 loss: 0.819 r2: 0.015\n",
            "Epoch 800 loss: 0.819 r2: 0.015\n",
            "Epoch 810 loss: 0.819 r2: 0.015\n",
            "Epoch 820 loss: 0.819 r2: 0.015\n",
            "Epoch 830 loss: 0.819 r2: 0.015\n",
            "Epoch 840 loss: 0.819 r2: 0.015\n",
            "Epoch 850 loss: 0.819 r2: 0.015\n",
            "Epoch 860 loss: 0.819 r2: 0.015\n",
            "Epoch 870 loss: 0.819 r2: 0.015\n",
            "Epoch 880 loss: 0.819 r2: 0.015\n",
            "Epoch 890 loss: 0.819 r2: 0.015\n",
            "Epoch 900 loss: 0.819 r2: 0.015\n",
            "Epoch 910 loss: 0.819 r2: 0.015\n",
            "Epoch 920 loss: 0.819 r2: 0.015\n",
            "Epoch 930 loss: 0.819 r2: 0.015\n",
            "Epoch 940 loss: 0.819 r2: 0.015\n",
            "Epoch 950 loss: 0.819 r2: 0.015\n",
            "Epoch 960 loss: 0.819 r2: 0.015\n",
            "Epoch 970 loss: 0.819 r2: 0.015\n",
            "Epoch 980 loss: 0.819 r2: 0.015\n",
            "Epoch 990 loss: 0.819 r2: 0.015\n",
            "Weights: [-10.52333981513976, -44.218459961383886, -3.7575068330626693, 7.828232003054719, 11.739887028454218, 35.80602588648512, -9.999581354940917, 3.971791903660047]\n",
            "Bias: [-10.034978271708868, 1.924485341270628, 4.842350787849946]\n",
            "Loss for test dataset\n",
            "Test loss: 0.644, r2: 0.243\n",
            "Loss for training dataset\n",
            "Test loss: 0.819, r2: 0.015\n",
            "Epoch 0 loss: 0.818 r2: 0.012\n",
            "Epoch 10 loss: 0.818 r2: 0.012\n",
            "Epoch 20 loss: 0.818 r2: 0.012\n",
            "Epoch 30 loss: 0.818 r2: 0.012\n",
            "Epoch 40 loss: 0.818 r2: 0.012\n",
            "Epoch 50 loss: 0.818 r2: 0.012\n",
            "Epoch 60 loss: 0.818 r2: 0.012\n",
            "Epoch 70 loss: 0.818 r2: 0.012\n",
            "Epoch 80 loss: 0.818 r2: 0.012\n",
            "Epoch 90 loss: 0.818 r2: 0.012\n",
            "Epoch 100 loss: 0.818 r2: 0.012\n",
            "Epoch 110 loss: 0.818 r2: 0.012\n",
            "Epoch 120 loss: 0.818 r2: 0.012\n",
            "Epoch 130 loss: 0.818 r2: 0.012\n",
            "Epoch 140 loss: 0.818 r2: 0.012\n",
            "Epoch 150 loss: 0.818 r2: 0.012\n",
            "Epoch 160 loss: 0.818 r2: 0.012\n",
            "Epoch 170 loss: 0.818 r2: 0.012\n",
            "Epoch 180 loss: 0.818 r2: 0.012\n",
            "Epoch 190 loss: 0.818 r2: 0.012\n",
            "Epoch 200 loss: 0.818 r2: 0.012\n",
            "Epoch 210 loss: 0.818 r2: 0.012\n",
            "Epoch 220 loss: 0.818 r2: 0.012\n",
            "Epoch 230 loss: 0.818 r2: 0.012\n",
            "Epoch 240 loss: 0.818 r2: 0.012\n",
            "Epoch 250 loss: 0.818 r2: 0.012\n",
            "Epoch 260 loss: 0.818 r2: 0.012\n",
            "Epoch 270 loss: 0.818 r2: 0.012\n",
            "Epoch 280 loss: 0.818 r2: 0.012\n",
            "Epoch 290 loss: 0.818 r2: 0.012\n",
            "Epoch 300 loss: 0.818 r2: 0.012\n",
            "Epoch 310 loss: 0.818 r2: 0.012\n",
            "Epoch 320 loss: 0.818 r2: 0.012\n",
            "Epoch 330 loss: 0.818 r2: 0.012\n",
            "Epoch 340 loss: 0.818 r2: 0.012\n",
            "Epoch 350 loss: 0.818 r2: 0.012\n",
            "Epoch 360 loss: 0.818 r2: 0.012\n",
            "Epoch 370 loss: 0.818 r2: 0.012\n",
            "Epoch 380 loss: 0.818 r2: 0.012\n",
            "Epoch 390 loss: 0.818 r2: 0.012\n",
            "Epoch 400 loss: 0.818 r2: 0.012\n",
            "Epoch 410 loss: 0.818 r2: 0.012\n",
            "Epoch 420 loss: 0.818 r2: 0.012\n",
            "Epoch 430 loss: 0.818 r2: 0.012\n",
            "Epoch 440 loss: 0.818 r2: 0.012\n",
            "Epoch 450 loss: 0.818 r2: 0.012\n",
            "Epoch 460 loss: 0.818 r2: 0.012\n",
            "Epoch 470 loss: 0.818 r2: 0.012\n",
            "Epoch 480 loss: 0.818 r2: 0.012\n",
            "Epoch 490 loss: 0.818 r2: 0.012\n",
            "Epoch 500 loss: 0.818 r2: 0.012\n",
            "Epoch 510 loss: 0.818 r2: 0.012\n",
            "Epoch 520 loss: 0.818 r2: 0.012\n",
            "Epoch 530 loss: 0.818 r2: 0.012\n",
            "Epoch 540 loss: 0.818 r2: 0.012\n",
            "Epoch 550 loss: 0.818 r2: 0.012\n",
            "Epoch 560 loss: 0.818 r2: 0.012\n",
            "Epoch 570 loss: 0.818 r2: 0.012\n",
            "Epoch 580 loss: 0.818 r2: 0.012\n",
            "Epoch 590 loss: 0.818 r2: 0.012\n",
            "Epoch 600 loss: 0.818 r2: 0.012\n",
            "Epoch 610 loss: 0.818 r2: 0.012\n",
            "Epoch 620 loss: 0.818 r2: 0.012\n",
            "Epoch 630 loss: 0.818 r2: 0.012\n",
            "Epoch 640 loss: 0.818 r2: 0.012\n",
            "Epoch 650 loss: 0.818 r2: 0.012\n",
            "Epoch 660 loss: 0.818 r2: 0.012\n",
            "Epoch 670 loss: 0.818 r2: 0.012\n",
            "Epoch 680 loss: 0.818 r2: 0.012\n",
            "Epoch 690 loss: 0.818 r2: 0.012\n",
            "Epoch 700 loss: 0.818 r2: 0.012\n",
            "Epoch 710 loss: 0.818 r2: 0.012\n",
            "Epoch 720 loss: 0.818 r2: 0.012\n",
            "Epoch 730 loss: 0.818 r2: 0.012\n",
            "Epoch 740 loss: 0.818 r2: 0.012\n",
            "Epoch 750 loss: 0.818 r2: 0.012\n",
            "Epoch 760 loss: 0.818 r2: 0.012\n",
            "Epoch 770 loss: 0.818 r2: 0.012\n",
            "Epoch 780 loss: 0.818 r2: 0.012\n",
            "Epoch 790 loss: 0.818 r2: 0.012\n",
            "Epoch 800 loss: 0.818 r2: 0.012\n",
            "Epoch 810 loss: 0.818 r2: 0.012\n",
            "Epoch 820 loss: 0.818 r2: 0.012\n",
            "Epoch 830 loss: 0.818 r2: 0.012\n",
            "Epoch 840 loss: 0.818 r2: 0.012\n",
            "Epoch 850 loss: 0.818 r2: 0.012\n",
            "Epoch 860 loss: 0.818 r2: 0.012\n",
            "Epoch 870 loss: 0.818 r2: 0.012\n",
            "Epoch 880 loss: 0.818 r2: 0.012\n",
            "Epoch 890 loss: 0.818 r2: 0.012\n",
            "Epoch 900 loss: 0.818 r2: 0.012\n",
            "Epoch 910 loss: 0.818 r2: 0.012\n",
            "Epoch 920 loss: 0.818 r2: 0.012\n",
            "Epoch 930 loss: 0.818 r2: 0.012\n",
            "Epoch 940 loss: 0.818 r2: 0.012\n",
            "Epoch 950 loss: 0.818 r2: 0.012\n",
            "Epoch 960 loss: 0.818 r2: 0.012\n",
            "Epoch 970 loss: 0.818 r2: 0.012\n",
            "Epoch 980 loss: 0.818 r2: 0.012\n",
            "Epoch 990 loss: 0.818 r2: 0.012\n",
            "Weights: [-10.538443385152, -44.19360408223799, -3.7892862001611936, 7.843111405198132, 11.691133618119926, 35.823326392914005, -9.989022194885676, 3.9800336691985554]\n",
            "Bias: [-10.086512869923586, 1.9691108897823257, 4.8552882419364325]\n",
            "Loss for test dataset\n",
            "Test loss: 0.642, r2: 0.242\n",
            "Loss for training dataset\n",
            "Test loss: 0.818, r2: 0.012\n",
            "Epoch 0 loss: 0.819 r2: 0.016\n",
            "Epoch 10 loss: 0.822 r2: 0.029\n",
            "Epoch 20 loss: 0.823 r2: 0.029\n",
            "Epoch 30 loss: 0.823 r2: 0.029\n",
            "Epoch 40 loss: 0.823 r2: 0.029\n",
            "Epoch 50 loss: 0.823 r2: 0.029\n",
            "Epoch 60 loss: 0.823 r2: 0.029\n",
            "Epoch 70 loss: 0.823 r2: 0.029\n",
            "Epoch 80 loss: 0.823 r2: 0.029\n",
            "Epoch 90 loss: 0.823 r2: 0.029\n",
            "Epoch 100 loss: 0.823 r2: 0.029\n",
            "Epoch 110 loss: 0.823 r2: 0.029\n",
            "Epoch 120 loss: 0.823 r2: 0.029\n",
            "Epoch 130 loss: 0.823 r2: 0.029\n",
            "Epoch 140 loss: 0.823 r2: 0.029\n",
            "Epoch 150 loss: 0.823 r2: 0.029\n",
            "Epoch 160 loss: 0.823 r2: 0.029\n",
            "Epoch 170 loss: 0.823 r2: 0.029\n",
            "Epoch 180 loss: 0.823 r2: 0.029\n",
            "Epoch 190 loss: 0.823 r2: 0.029\n",
            "Epoch 200 loss: 0.823 r2: 0.029\n",
            "Epoch 210 loss: 0.823 r2: 0.029\n",
            "Epoch 220 loss: 0.823 r2: 0.029\n",
            "Epoch 230 loss: 0.823 r2: 0.029\n",
            "Epoch 240 loss: 0.823 r2: 0.029\n",
            "Epoch 250 loss: 0.823 r2: 0.029\n",
            "Epoch 260 loss: 0.823 r2: 0.029\n",
            "Epoch 270 loss: 0.823 r2: 0.029\n",
            "Epoch 280 loss: 0.823 r2: 0.029\n",
            "Epoch 290 loss: 0.823 r2: 0.029\n",
            "Epoch 300 loss: 0.823 r2: 0.029\n",
            "Epoch 310 loss: 0.823 r2: 0.029\n",
            "Epoch 320 loss: 0.823 r2: 0.029\n",
            "Epoch 330 loss: 0.823 r2: 0.029\n",
            "Epoch 340 loss: 0.823 r2: 0.029\n",
            "Epoch 350 loss: 0.823 r2: 0.029\n",
            "Epoch 360 loss: 0.823 r2: 0.029\n",
            "Epoch 370 loss: 0.823 r2: 0.029\n",
            "Epoch 380 loss: 0.823 r2: 0.029\n",
            "Epoch 390 loss: 0.823 r2: 0.029\n",
            "Epoch 400 loss: 0.823 r2: 0.029\n",
            "Epoch 410 loss: 0.823 r2: 0.029\n",
            "Epoch 420 loss: 0.823 r2: 0.029\n",
            "Epoch 430 loss: 0.823 r2: 0.029\n",
            "Epoch 440 loss: 0.823 r2: 0.029\n",
            "Epoch 450 loss: 0.823 r2: 0.029\n",
            "Epoch 460 loss: 0.823 r2: 0.029\n",
            "Epoch 470 loss: 0.823 r2: 0.029\n",
            "Epoch 480 loss: 0.823 r2: 0.029\n",
            "Epoch 490 loss: 0.823 r2: 0.029\n",
            "Epoch 500 loss: 0.823 r2: 0.029\n",
            "Epoch 510 loss: 0.823 r2: 0.029\n",
            "Epoch 520 loss: 0.823 r2: 0.029\n",
            "Epoch 530 loss: 0.823 r2: 0.029\n",
            "Epoch 540 loss: 0.823 r2: 0.029\n",
            "Epoch 550 loss: 0.823 r2: 0.029\n",
            "Epoch 560 loss: 0.823 r2: 0.029\n",
            "Epoch 570 loss: 0.823 r2: 0.029\n",
            "Epoch 580 loss: 0.823 r2: 0.029\n",
            "Epoch 590 loss: 0.823 r2: 0.029\n",
            "Epoch 600 loss: 0.823 r2: 0.029\n",
            "Epoch 610 loss: 0.823 r2: 0.029\n",
            "Epoch 620 loss: 0.823 r2: 0.029\n",
            "Epoch 630 loss: 0.823 r2: 0.029\n",
            "Epoch 640 loss: 0.823 r2: 0.029\n",
            "Epoch 650 loss: 0.823 r2: 0.029\n",
            "Epoch 660 loss: 0.823 r2: 0.029\n",
            "Epoch 670 loss: 0.823 r2: 0.029\n",
            "Epoch 680 loss: 0.823 r2: 0.029\n",
            "Epoch 690 loss: 0.823 r2: 0.029\n",
            "Epoch 700 loss: 0.823 r2: 0.029\n",
            "Epoch 710 loss: 0.823 r2: 0.029\n",
            "Epoch 720 loss: 0.823 r2: 0.029\n",
            "Epoch 730 loss: 0.823 r2: 0.029\n",
            "Epoch 740 loss: 0.823 r2: 0.029\n",
            "Epoch 750 loss: 0.823 r2: 0.029\n",
            "Epoch 760 loss: 0.823 r2: 0.029\n",
            "Epoch 770 loss: 0.823 r2: 0.029\n",
            "Epoch 780 loss: 0.823 r2: 0.029\n",
            "Epoch 790 loss: 0.823 r2: 0.029\n",
            "Epoch 800 loss: 0.823 r2: 0.029\n",
            "Epoch 810 loss: 0.823 r2: 0.029\n",
            "Epoch 820 loss: 0.823 r2: 0.029\n",
            "Epoch 830 loss: 0.823 r2: 0.029\n",
            "Epoch 840 loss: 0.823 r2: 0.029\n",
            "Epoch 850 loss: 0.823 r2: 0.029\n",
            "Epoch 860 loss: 0.823 r2: 0.029\n",
            "Epoch 870 loss: 0.823 r2: 0.029\n",
            "Epoch 880 loss: 0.823 r2: 0.029\n",
            "Epoch 890 loss: 0.823 r2: 0.029\n",
            "Epoch 900 loss: 0.823 r2: 0.029\n",
            "Epoch 910 loss: 0.823 r2: 0.029\n",
            "Epoch 920 loss: 0.823 r2: 0.029\n",
            "Epoch 930 loss: 0.823 r2: 0.029\n",
            "Epoch 940 loss: 0.823 r2: 0.029\n",
            "Epoch 950 loss: 0.823 r2: 0.029\n",
            "Epoch 960 loss: 0.823 r2: 0.029\n",
            "Epoch 970 loss: 0.823 r2: 0.029\n",
            "Epoch 980 loss: 0.823 r2: 0.029\n",
            "Epoch 990 loss: 0.823 r2: 0.029\n",
            "Weights: [-10.549619773483279, -44.17467060612879, -3.8139780382849557, 7.85359961130315, 11.656113212064268, 35.83578054008324, -10.04284554709324, 3.924959692330331]\n",
            "Bias: [-10.126022176454622, 2.0015357531591214, 4.803246666372899]\n",
            "Loss for test dataset\n",
            "Test loss: 0.649, r2: 0.247\n",
            "Loss for training dataset\n",
            "Test loss: 0.821, r2: 0.023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Changing the neural network to accomodate ReLu activation function since the variables are overflowing.\n",
        "\n"
      ],
      "metadata": {
        "id": "QpCTlWcV9OUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = OurNeuralNetwork('reLu')\n",
        "for i in range(1,10):\n",
        "  weights = network.train_relu(np.array(X_train), np.array(Y_train),i/1000,1000)\n",
        "  print(\"Weights:\", weights[:8])\n",
        "  print(\"Bias:\",weights[8:])\n",
        "  print(\"Loss for test dataset\")\n",
        "  network.test(np.array(X_test), np.array(Y_test), weights)\n",
        "  print(\"Loss for training dataset\")\n",
        "  network.test(np.array(X_train), np.array(Y_train), weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL6UQHvk8uHk",
        "outputId": "fd7b92c5-e831-42e6-bd34-c17ff9ef65e3"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: -0.4146527939713658 1.0143989699711682 -0.34100937558685285 -1.8603426502735594 -0.7521826780494949 -0.4949961219540402 -0.5192167437685774 -0.2686870510780135\n",
            "Bias: -2.1181304559775733 2.242212529182273 0.6050155070033114\n",
            "Epoch 0 loss: 0.862 r2: -11.245\n",
            "Epoch 10 loss: 0.857 r2: -8.779\n",
            "Epoch 20 loss: 0.857 r2: -8.917\n",
            "Epoch 30 loss: 0.857 r2: -9.101\n",
            "Epoch 40 loss: 0.858 r2: -9.264\n",
            "Epoch 50 loss: 0.858 r2: -9.407\n",
            "Epoch 60 loss: 0.858 r2: -9.548\n",
            "Epoch 70 loss: 0.859 r2: -9.674\n",
            "Epoch 80 loss: 0.859 r2: -9.789\n",
            "Epoch 90 loss: 0.859 r2: -9.889\n",
            "Epoch 100 loss: 0.860 r2: -9.979\n",
            "Epoch 110 loss: 0.860 r2: -10.063\n",
            "Epoch 120 loss: 0.860 r2: -10.142\n",
            "Epoch 130 loss: 0.860 r2: -10.218\n",
            "Epoch 140 loss: 0.860 r2: -10.303\n",
            "Epoch 150 loss: 0.860 r2: -10.397\n",
            "Epoch 160 loss: 0.860 r2: -10.489\n",
            "Epoch 170 loss: 0.860 r2: -10.577\n",
            "Epoch 180 loss: 0.860 r2: -10.661\n",
            "Epoch 190 loss: 0.860 r2: -10.756\n",
            "Epoch 200 loss: 0.860 r2: -10.880\n",
            "Epoch 210 loss: 0.860 r2: -10.994\n",
            "Epoch 220 loss: 0.860 r2: -11.092\n",
            "Epoch 230 loss: 0.860 r2: -11.174\n",
            "Epoch 240 loss: 0.860 r2: -11.246\n",
            "Epoch 250 loss: 0.860 r2: -11.300\n",
            "Epoch 260 loss: 0.860 r2: -11.333\n",
            "Epoch 270 loss: 0.860 r2: -11.353\n",
            "Epoch 280 loss: 0.860 r2: -11.369\n",
            "Epoch 290 loss: 0.860 r2: -11.386\n",
            "Epoch 300 loss: 0.860 r2: -11.412\n",
            "Epoch 310 loss: 0.860 r2: -11.451\n",
            "Epoch 320 loss: 0.860 r2: -11.507\n",
            "Epoch 330 loss: 0.860 r2: -11.578\n",
            "Epoch 340 loss: 0.860 r2: -11.664\n",
            "Epoch 350 loss: 0.860 r2: -11.761\n",
            "Epoch 360 loss: 0.860 r2: -11.867\n",
            "Epoch 370 loss: 0.860 r2: -11.981\n",
            "Epoch 380 loss: 0.860 r2: -12.102\n",
            "Epoch 390 loss: 0.861 r2: -12.226\n",
            "Epoch 400 loss: 0.861 r2: -12.351\n",
            "Epoch 410 loss: 0.861 r2: -12.474\n",
            "Epoch 420 loss: 0.861 r2: -12.594\n",
            "Epoch 430 loss: 0.861 r2: -12.712\n",
            "Epoch 440 loss: 0.861 r2: -12.829\n",
            "Epoch 450 loss: 0.861 r2: -12.945\n",
            "Epoch 460 loss: 0.861 r2: -13.059\n",
            "Epoch 470 loss: 0.862 r2: -13.174\n",
            "Epoch 480 loss: 0.862 r2: -13.288\n",
            "Epoch 490 loss: 0.862 r2: -13.402\n",
            "Epoch 500 loss: 0.862 r2: -13.516\n",
            "Epoch 510 loss: 0.862 r2: -13.629\n",
            "Epoch 520 loss: 0.863 r2: -13.745\n",
            "Epoch 530 loss: 0.863 r2: -13.859\n",
            "Epoch 540 loss: 0.863 r2: -13.971\n",
            "Epoch 550 loss: 0.863 r2: -14.080\n",
            "Epoch 560 loss: 0.864 r2: -14.188\n",
            "Epoch 570 loss: 0.864 r2: -14.293\n",
            "Epoch 580 loss: 0.864 r2: -14.397\n",
            "Epoch 590 loss: 0.864 r2: -14.500\n",
            "Epoch 600 loss: 0.864 r2: -14.601\n",
            "Epoch 610 loss: 0.865 r2: -14.700\n",
            "Epoch 620 loss: 0.865 r2: -14.796\n",
            "Epoch 630 loss: 0.865 r2: -14.891\n",
            "Epoch 640 loss: 0.865 r2: -14.985\n",
            "Epoch 650 loss: 0.866 r2: -15.079\n",
            "Epoch 660 loss: 0.866 r2: -15.173\n",
            "Epoch 670 loss: 0.866 r2: -15.266\n",
            "Epoch 680 loss: 0.866 r2: -15.360\n",
            "Epoch 690 loss: 0.867 r2: -15.455\n",
            "Epoch 700 loss: 0.867 r2: -15.549\n",
            "Epoch 710 loss: 0.867 r2: -15.642\n",
            "Epoch 720 loss: 0.868 r2: -15.745\n",
            "Epoch 730 loss: 0.868 r2: -15.848\n",
            "Epoch 740 loss: 0.868 r2: -15.950\n",
            "Epoch 750 loss: 0.869 r2: -16.060\n",
            "Epoch 760 loss: 0.869 r2: -16.166\n",
            "Epoch 770 loss: 0.870 r2: -16.268\n",
            "Epoch 780 loss: 0.870 r2: -16.366\n",
            "Epoch 790 loss: 0.870 r2: -16.461\n",
            "Epoch 800 loss: 0.870 r2: -16.554\n",
            "Epoch 810 loss: 0.871 r2: -16.646\n",
            "Epoch 820 loss: 0.871 r2: -16.736\n",
            "Epoch 830 loss: 0.871 r2: -16.824\n",
            "Epoch 840 loss: 0.872 r2: -16.911\n",
            "Epoch 850 loss: 0.872 r2: -16.996\n",
            "Epoch 860 loss: 0.872 r2: -17.081\n",
            "Epoch 870 loss: 0.873 r2: -17.164\n",
            "Epoch 880 loss: 0.873 r2: -17.247\n",
            "Epoch 890 loss: 0.873 r2: -17.330\n",
            "Epoch 900 loss: 0.873 r2: -17.411\n",
            "Epoch 910 loss: 0.874 r2: -17.493\n",
            "Epoch 920 loss: 0.874 r2: -17.573\n",
            "Epoch 930 loss: 0.874 r2: -17.653\n",
            "Epoch 940 loss: 0.875 r2: -17.732\n",
            "Epoch 950 loss: 0.875 r2: -17.809\n",
            "Epoch 960 loss: 0.875 r2: -17.890\n",
            "Epoch 970 loss: 0.875 r2: -17.967\n",
            "Epoch 980 loss: 0.875 r2: -18.042\n",
            "Epoch 990 loss: 0.876 r2: -18.117\n",
            "Weights: [-0.20633278932920548, -0.1864222458561323, -0.8690167020410499, -4.483443305901731, -3.1245352696895408, -1.8469490722217057, -0.0019378125130118506, -0.1353626492026189]\n",
            "Bias: [-2.11814200079983, 0.744123936087759, 0.44326130530756214]\n",
            "Loss for test dataset\n",
            "Test loss: 0.711, r2: -16.404\n",
            "Loss for training dataset\n",
            "Test loss: 0.876, r2: -18.183\n",
            "Epoch 0 loss: 0.874 r2: -17.743\n",
            "Epoch 10 loss: 0.875 r2: -17.745\n",
            "Epoch 20 loss: 0.876 r2: -18.109\n",
            "Epoch 30 loss: 0.877 r2: -18.479\n",
            "Epoch 40 loss: 0.878 r2: -18.854\n",
            "Epoch 50 loss: 0.879 r2: -19.226\n",
            "Epoch 60 loss: 0.880 r2: -19.614\n",
            "Epoch 70 loss: 0.881 r2: -20.005\n",
            "Epoch 80 loss: 0.883 r2: -20.393\n",
            "Epoch 90 loss: 0.884 r2: -20.779\n",
            "Epoch 100 loss: 0.885 r2: -21.167\n",
            "Epoch 110 loss: 0.886 r2: -21.573\n",
            "Epoch 120 loss: 0.887 r2: -21.982\n",
            "Epoch 130 loss: 0.889 r2: -22.391\n",
            "Epoch 140 loss: 0.890 r2: -22.793\n",
            "Epoch 150 loss: 0.891 r2: -23.187\n",
            "Epoch 160 loss: 0.892 r2: -23.577\n",
            "Epoch 170 loss: 0.893 r2: -23.967\n",
            "Epoch 180 loss: 0.894 r2: -24.373\n",
            "Epoch 190 loss: 0.896 r2: -24.783\n",
            "Epoch 200 loss: 0.897 r2: -25.211\n",
            "Epoch 210 loss: 0.898 r2: -25.648\n",
            "Epoch 220 loss: 0.899 r2: -26.077\n",
            "Epoch 230 loss: 0.900 r2: -26.513\n",
            "Epoch 240 loss: 0.901 r2: -26.952\n",
            "Epoch 250 loss: 0.902 r2: -27.399\n",
            "Epoch 260 loss: 0.902 r2: -27.855\n",
            "Epoch 270 loss: 0.903 r2: -28.326\n",
            "Epoch 280 loss: 0.904 r2: -28.808\n",
            "Epoch 290 loss: 0.905 r2: -29.303\n",
            "Epoch 300 loss: 0.906 r2: -29.809\n",
            "Epoch 310 loss: 0.907 r2: -30.327\n",
            "Epoch 320 loss: 0.908 r2: -30.859\n",
            "Epoch 330 loss: 0.909 r2: -31.423\n",
            "Epoch 340 loss: 0.910 r2: -32.000\n",
            "Epoch 350 loss: 0.911 r2: -32.590\n",
            "Epoch 360 loss: 0.912 r2: -33.191\n",
            "Epoch 370 loss: 0.913 r2: -33.840\n",
            "Epoch 380 loss: 0.914 r2: -34.561\n",
            "Epoch 390 loss: 0.916 r2: -35.351\n",
            "Epoch 400 loss: 0.917 r2: -36.153\n",
            "Epoch 410 loss: 0.918 r2: -36.958\n",
            "Epoch 420 loss: 0.919 r2: -37.787\n",
            "Epoch 430 loss: 0.921 r2: -38.638\n",
            "Epoch 440 loss: 0.922 r2: -39.509\n",
            "Epoch 450 loss: 0.923 r2: -40.368\n",
            "Epoch 460 loss: 0.924 r2: -41.239\n",
            "Epoch 470 loss: 0.925 r2: -42.126\n",
            "Epoch 480 loss: 0.927 r2: -43.030\n",
            "Epoch 490 loss: 0.928 r2: -43.967\n",
            "Epoch 500 loss: 0.929 r2: -44.917\n",
            "Epoch 510 loss: 0.930 r2: -45.866\n",
            "Epoch 520 loss: 0.931 r2: -46.846\n",
            "Epoch 530 loss: 0.932 r2: -47.859\n",
            "Epoch 540 loss: 0.933 r2: -48.889\n",
            "Epoch 550 loss: 0.934 r2: -49.931\n",
            "Epoch 560 loss: 0.935 r2: -51.005\n",
            "Epoch 570 loss: 0.936 r2: -52.085\n",
            "Epoch 580 loss: 0.937 r2: -53.213\n",
            "Epoch 590 loss: 0.937 r2: -54.351\n",
            "Epoch 600 loss: 0.938 r2: -55.510\n",
            "Epoch 610 loss: 0.939 r2: -57.092\n",
            "Epoch 620 loss: 0.940 r2: -58.884\n",
            "Epoch 630 loss: 0.942 r2: -60.709\n",
            "Epoch 640 loss: 0.943 r2: -62.540\n",
            "Epoch 650 loss: 0.944 r2: -64.391\n",
            "Epoch 660 loss: 0.945 r2: -66.262\n",
            "Epoch 670 loss: 0.946 r2: -68.278\n",
            "Epoch 680 loss: 0.948 r2: -70.332\n",
            "Epoch 690 loss: 0.949 r2: -72.389\n",
            "Epoch 700 loss: 0.950 r2: -74.467\n",
            "Epoch 710 loss: 0.952 r2: -76.561\n",
            "Epoch 720 loss: 0.953 r2: -78.638\n",
            "Epoch 730 loss: 0.954 r2: -80.694\n",
            "Epoch 740 loss: 0.956 r2: -82.717\n",
            "Epoch 750 loss: 0.957 r2: -84.869\n",
            "Epoch 760 loss: 0.959 r2: -86.978\n",
            "Epoch 770 loss: 0.960 r2: -89.027\n",
            "Epoch 780 loss: 0.962 r2: -91.006\n",
            "Epoch 790 loss: 0.963 r2: -92.919\n",
            "Epoch 800 loss: 0.964 r2: -94.727\n",
            "Epoch 810 loss: 0.966 r2: -96.481\n",
            "Epoch 820 loss: 0.967 r2: -98.195\n",
            "Epoch 830 loss: 0.967 r2: -99.824\n",
            "Epoch 840 loss: 0.968 r2: -101.454\n",
            "Epoch 850 loss: 0.968 r2: -103.075\n",
            "Epoch 860 loss: 0.969 r2: -104.699\n",
            "Epoch 870 loss: 0.969 r2: -106.274\n",
            "Epoch 880 loss: 0.970 r2: -107.835\n",
            "Epoch 890 loss: 0.970 r2: -109.406\n",
            "Epoch 900 loss: 0.970 r2: -111.033\n",
            "Epoch 910 loss: 0.971 r2: -112.632\n",
            "Epoch 920 loss: 0.971 r2: -114.165\n",
            "Epoch 930 loss: 0.971 r2: -115.653\n",
            "Epoch 940 loss: 0.972 r2: -117.124\n",
            "Epoch 950 loss: 0.972 r2: -118.581\n",
            "Epoch 960 loss: 0.972 r2: -120.022\n",
            "Epoch 970 loss: 0.972 r2: -121.442\n",
            "Epoch 980 loss: 0.973 r2: -122.899\n",
            "Epoch 990 loss: 0.973 r2: -124.421\n",
            "Weights: [-0.09288363494054397, -0.1550582544264405, -0.8363511432759386, -14.39906023659222, -3.432698107968215, -3.446786927478966, -0.0014688460336643337, -0.1302499535298943]\n",
            "Bias: [-2.2199672782448614, -13.523897683813079, 0.2033812258096411]\n",
            "Loss for test dataset\n",
            "Test loss: 0.831, r2: -114.907\n",
            "Loss for training dataset\n",
            "Test loss: 0.973, r2: -125.763\n",
            "Epoch 0 loss: 0.978 r2: -194.372\n",
            "Epoch 10 loss: 0.982 r2: -181.164\n",
            "Epoch 20 loss: 0.984 r2: -190.696\n",
            "Epoch 30 loss: 0.986 r2: -198.576\n",
            "Epoch 40 loss: 0.987 r2: -203.511\n",
            "Epoch 50 loss: 0.988 r2: -210.013\n",
            "Epoch 60 loss: 0.989 r2: -215.559\n",
            "Epoch 70 loss: 0.990 r2: -219.422\n",
            "Epoch 80 loss: 0.992 r2: -222.612\n",
            "Epoch 90 loss: 0.993 r2: -224.941\n",
            "Epoch 100 loss: 0.993 r2: -226.382\n",
            "Epoch 110 loss: 0.993 r2: -228.249\n",
            "Epoch 120 loss: 0.993 r2: -230.338\n",
            "Epoch 130 loss: 0.994 r2: -232.465\n",
            "Epoch 140 loss: 0.994 r2: -234.533\n",
            "Epoch 150 loss: 0.994 r2: -236.588\n",
            "Epoch 160 loss: 0.994 r2: -238.642\n",
            "Epoch 170 loss: 0.994 r2: -240.666\n",
            "Epoch 180 loss: 0.995 r2: -242.651\n",
            "Epoch 190 loss: 0.995 r2: -244.573\n",
            "Epoch 200 loss: 0.995 r2: -246.423\n",
            "Epoch 210 loss: 0.995 r2: -248.183\n",
            "Epoch 220 loss: 0.995 r2: -249.838\n",
            "Epoch 230 loss: 0.996 r2: -251.920\n",
            "Epoch 240 loss: 0.996 r2: -254.047\n",
            "Epoch 250 loss: 0.996 r2: -256.179\n",
            "Epoch 260 loss: 0.996 r2: -258.318\n",
            "Epoch 270 loss: 0.996 r2: -260.454\n",
            "Epoch 280 loss: 0.996 r2: -262.849\n",
            "Epoch 290 loss: 0.997 r2: -266.452\n",
            "Epoch 300 loss: 0.997 r2: -269.929\n",
            "Epoch 310 loss: 0.997 r2: -273.254\n",
            "Epoch 320 loss: 0.998 r2: -276.404\n",
            "Epoch 330 loss: 0.998 r2: -279.355\n",
            "Epoch 340 loss: 0.998 r2: -281.935\n",
            "Epoch 350 loss: 0.998 r2: -284.305\n",
            "Epoch 360 loss: 0.999 r2: -286.530\n",
            "Epoch 370 loss: 0.999 r2: -288.605\n",
            "Epoch 380 loss: 0.999 r2: -290.525\n",
            "Epoch 390 loss: 0.999 r2: -292.435\n",
            "Epoch 400 loss: 0.999 r2: -294.899\n",
            "Epoch 410 loss: 0.999 r2: -309.869\n",
            "Epoch 420 loss: 0.933 r2: -45.440\n",
            "Epoch 430 loss: 0.911 r2: -23.699\n",
            "Epoch 440 loss: 0.906 r2: -25.356\n",
            "Epoch 450 loss: 0.912 r2: -30.668\n",
            "Epoch 460 loss: 0.918 r2: -37.488\n",
            "Epoch 470 loss: 0.920 r2: -39.762\n",
            "Epoch 480 loss: 0.923 r2: -42.274\n",
            "Epoch 490 loss: 0.926 r2: -44.836\n",
            "Epoch 500 loss: 0.930 r2: -47.154\n",
            "Epoch 510 loss: 0.933 r2: -49.396\n",
            "Epoch 520 loss: 0.936 r2: -51.605\n",
            "Epoch 530 loss: 0.938 r2: -53.812\n",
            "Epoch 540 loss: 0.940 r2: -56.217\n",
            "Epoch 550 loss: 0.942 r2: -59.513\n",
            "Epoch 560 loss: 0.945 r2: -63.697\n",
            "Epoch 570 loss: 0.948 r2: -68.073\n",
            "Epoch 580 loss: 0.951 r2: -72.548\n",
            "Epoch 590 loss: 0.954 r2: -76.940\n",
            "Epoch 600 loss: 0.957 r2: -81.320\n",
            "Epoch 610 loss: 0.961 r2: -85.695\n",
            "Epoch 620 loss: 0.964 r2: -89.715\n",
            "Epoch 630 loss: 0.967 r2: -93.263\n",
            "Epoch 640 loss: 0.969 r2: -96.613\n",
            "Epoch 650 loss: 0.970 r2: -100.121\n",
            "Epoch 660 loss: 0.971 r2: -103.721\n",
            "Epoch 670 loss: 0.972 r2: -107.247\n",
            "Epoch 680 loss: 0.972 r2: -110.557\n",
            "Epoch 690 loss: 0.973 r2: -114.030\n",
            "Epoch 700 loss: 0.973 r2: -117.535\n",
            "Epoch 710 loss: 0.974 r2: -121.087\n",
            "Epoch 720 loss: 0.974 r2: -124.869\n",
            "Epoch 730 loss: 0.975 r2: -128.727\n",
            "Epoch 740 loss: 0.975 r2: -133.166\n",
            "Epoch 750 loss: 0.976 r2: -138.243\n",
            "Epoch 760 loss: 0.977 r2: -143.431\n",
            "Epoch 770 loss: 0.978 r2: -151.679\n",
            "Epoch 780 loss: 0.979 r2: -154.176\n",
            "Epoch 790 loss: 0.981 r2: -157.090\n",
            "Epoch 800 loss: 0.983 r2: -166.282\n",
            "Epoch 810 loss: 0.985 r2: -174.380\n",
            "Epoch 820 loss: 0.986 r2: -182.909\n",
            "Epoch 830 loss: 0.988 r2: -190.592\n",
            "Epoch 840 loss: 0.989 r2: -197.249\n",
            "Epoch 850 loss: 0.991 r2: -202.851\n",
            "Epoch 860 loss: 0.992 r2: -207.534\n",
            "Epoch 870 loss: 0.993 r2: -211.565\n",
            "Epoch 880 loss: 0.994 r2: -213.879\n",
            "Epoch 890 loss: 0.994 r2: -215.356\n",
            "Epoch 900 loss: 0.994 r2: -216.848\n",
            "Epoch 910 loss: 0.994 r2: -218.500\n",
            "Epoch 920 loss: 0.994 r2: -220.151\n",
            "Epoch 930 loss: 0.995 r2: -221.690\n",
            "Epoch 940 loss: 0.995 r2: -223.259\n",
            "Epoch 950 loss: 0.995 r2: -225.223\n",
            "Epoch 960 loss: 0.995 r2: -227.257\n",
            "Epoch 970 loss: 0.996 r2: -229.168\n",
            "Epoch 980 loss: 0.996 r2: -227.535\n",
            "Epoch 990 loss: 0.996 r2: -221.301\n",
            "Weights: [-17.9971739444012, -1.7288687888876004, -3.6769699718822455, 2.312489334443907, 16.73952052209134, 10.302776345888804, -0.1504438755934423, 0.031062721912958828]\n",
            "Bias: [-19.245571996008014, -25.983527145826994, 0.15384559115596777]\n",
            "Loss for test dataset\n",
            "Test loss: 0.866, r2: -146.620\n",
            "Loss for training dataset\n",
            "Test loss: 0.996, r2: -213.440\n",
            "Epoch 0 loss: 0.997 r2: -263.424\n",
            "Epoch 10 loss: 0.997 r2: -210.179\n",
            "Epoch 20 loss: 0.996 r2: -159.401\n",
            "Epoch 30 loss: 0.993 r2: -99.341\n",
            "Epoch 40 loss: 0.991 r2: -53.862\n",
            "Epoch 50 loss: 0.990 r2: -29.429\n",
            "Epoch 60 loss: 0.993 r2: -18.315\n",
            "Epoch 70 loss: 0.999 r2: -12.716\n",
            "Epoch 80 loss: 1.008 r2: -9.596\n",
            "Epoch 90 loss: 1.013 r2: -7.740\n",
            "Epoch 100 loss: 1.009 r2: -6.704\n",
            "Epoch 110 loss: 1.001 r2: -6.319\n",
            "Epoch 120 loss: 0.991 r2: -6.336\n",
            "Epoch 130 loss: 0.982 r2: -6.394\n",
            "Epoch 140 loss: 0.977 r2: -6.123\n",
            "Epoch 150 loss: 0.980 r2: -5.427\n",
            "Epoch 160 loss: 0.989 r2: -4.588\n",
            "Epoch 170 loss: 1.001 r2: -3.897\n",
            "Epoch 180 loss: 1.014 r2: -3.424\n",
            "Epoch 190 loss: 1.025 r2: -3.118\n",
            "Epoch 200 loss: 1.035 r2: -2.915\n",
            "Epoch 210 loss: 1.043 r2: -2.772\n",
            "Epoch 220 loss: 1.049 r2: -2.666\n",
            "Epoch 230 loss: 1.055 r2: -2.582\n",
            "Epoch 240 loss: 1.060 r2: -2.515\n",
            "Epoch 250 loss: 1.064 r2: -2.459\n",
            "Epoch 260 loss: 1.068 r2: -2.413\n",
            "Epoch 270 loss: 1.072 r2: -2.373\n",
            "Epoch 280 loss: 1.075 r2: -2.339\n",
            "Epoch 290 loss: 1.078 r2: -2.309\n",
            "Epoch 300 loss: 1.081 r2: -2.283\n",
            "Epoch 310 loss: 1.083 r2: -2.259\n",
            "Epoch 320 loss: 1.085 r2: -2.238\n",
            "Epoch 330 loss: 1.087 r2: -2.217\n",
            "Epoch 340 loss: 1.089 r2: -2.205\n",
            "Epoch 350 loss: 1.089 r2: -2.196\n",
            "Epoch 360 loss: 1.090 r2: -2.188\n",
            "Epoch 370 loss: 1.091 r2: -2.180\n",
            "Epoch 380 loss: 1.091 r2: -2.173\n",
            "Epoch 390 loss: 1.092 r2: -2.168\n",
            "Epoch 400 loss: 1.092 r2: -2.164\n",
            "Epoch 410 loss: 1.092 r2: -2.160\n",
            "Epoch 420 loss: 1.092 r2: -2.157\n",
            "Epoch 430 loss: 1.093 r2: -2.154\n",
            "Epoch 440 loss: 1.093 r2: -2.151\n",
            "Epoch 450 loss: 1.093 r2: -2.149\n",
            "Epoch 460 loss: 1.093 r2: -2.147\n",
            "Epoch 470 loss: 1.093 r2: -2.146\n",
            "Epoch 480 loss: 1.093 r2: -2.145\n",
            "Epoch 490 loss: 1.092 r2: -2.144\n",
            "Epoch 500 loss: 1.092 r2: -2.144\n",
            "Epoch 510 loss: 1.092 r2: -2.148\n",
            "Epoch 520 loss: 1.092 r2: -2.145\n",
            "Epoch 530 loss: 1.092 r2: -2.140\n",
            "Epoch 540 loss: 1.092 r2: -2.136\n",
            "Epoch 550 loss: 1.092 r2: -2.132\n",
            "Epoch 560 loss: 1.092 r2: -2.129\n",
            "Epoch 570 loss: 1.092 r2: -2.127\n",
            "Epoch 580 loss: 1.092 r2: -2.126\n",
            "Epoch 590 loss: 1.092 r2: -2.127\n",
            "Epoch 600 loss: 1.092 r2: -2.128\n",
            "Epoch 610 loss: 1.091 r2: -2.130\n",
            "Epoch 620 loss: 1.090 r2: -2.134\n",
            "Epoch 630 loss: 1.089 r2: -2.141\n",
            "Epoch 640 loss: 1.088 r2: -2.150\n",
            "Epoch 650 loss: 1.087 r2: -2.161\n",
            "Epoch 660 loss: 1.085 r2: -2.174\n",
            "Epoch 670 loss: 1.084 r2: -2.189\n",
            "Epoch 680 loss: 1.082 r2: -2.207\n",
            "Epoch 690 loss: 1.080 r2: -2.226\n",
            "Epoch 700 loss: 1.078 r2: -2.246\n",
            "Epoch 710 loss: 1.076 r2: -2.269\n",
            "Epoch 720 loss: 1.074 r2: -2.294\n",
            "Epoch 730 loss: 1.071 r2: -2.321\n",
            "Epoch 740 loss: 1.069 r2: -2.352\n",
            "Epoch 750 loss: 1.066 r2: -2.384\n",
            "Epoch 760 loss: 1.063 r2: -2.420\n",
            "Epoch 770 loss: 1.061 r2: -2.459\n",
            "Epoch 780 loss: 1.058 r2: -2.501\n",
            "Epoch 790 loss: 1.055 r2: -2.546\n",
            "Epoch 800 loss: 1.052 r2: -2.595\n",
            "Epoch 810 loss: 1.049 r2: -2.648\n",
            "Epoch 820 loss: 1.045 r2: -2.705\n",
            "Epoch 830 loss: 1.042 r2: -2.767\n",
            "Epoch 840 loss: 1.039 r2: -2.832\n",
            "Epoch 850 loss: 1.036 r2: -2.901\n",
            "Epoch 860 loss: 1.033 r2: -2.972\n",
            "Epoch 870 loss: 1.030 r2: -3.046\n",
            "Epoch 880 loss: 1.027 r2: -3.123\n",
            "Epoch 890 loss: 1.024 r2: -3.208\n",
            "Epoch 900 loss: 1.021 r2: -3.295\n",
            "Epoch 910 loss: 1.018 r2: -3.382\n",
            "Epoch 920 loss: 1.015 r2: -3.468\n",
            "Epoch 930 loss: 1.012 r2: -3.554\n",
            "Epoch 940 loss: 1.010 r2: -3.638\n",
            "Epoch 950 loss: 1.007 r2: -3.720\n",
            "Epoch 960 loss: 1.005 r2: -3.799\n",
            "Epoch 970 loss: 1.004 r2: -3.875\n",
            "Epoch 980 loss: 1.002 r2: -3.946\n",
            "Epoch 990 loss: 1.001 r2: -4.008\n",
            "Weights: [-33.96134238044515, -0.09319461226353755, -8.208977064291565, 13.25887889433518, 24.978950155615642, 32.88759227762461, -0.07796811241822851, 0.11604228290189383]\n",
            "Bias: [-48.90781236329437, -48.201848595165146, 0.04669218218440266]\n",
            "Loss for test dataset\n",
            "Test loss: 0.940, r2: -1.751\n",
            "Loss for training dataset\n",
            "Test loss: 1.000, r2: -4.063\n",
            "Epoch 0 loss: 1.281 r2: -1.172\n",
            "Epoch 10 loss: 0.988 r2: -7.363\n",
            "Epoch 20 loss: 0.986 r2: -8.104\n",
            "Epoch 30 loss: 0.985 r2: -8.152\n",
            "Epoch 40 loss: 0.985 r2: -8.124\n",
            "Epoch 50 loss: 0.984 r2: -8.055\n",
            "Epoch 60 loss: 0.983 r2: -7.953\n",
            "Epoch 70 loss: 0.983 r2: -7.825\n",
            "Epoch 80 loss: 0.983 r2: -7.678\n",
            "Epoch 90 loss: 0.982 r2: -7.492\n",
            "Epoch 100 loss: 0.983 r2: -7.252\n",
            "Epoch 110 loss: 0.983 r2: -6.995\n",
            "Epoch 120 loss: 0.983 r2: -6.744\n",
            "Epoch 130 loss: 0.984 r2: -6.513\n",
            "Epoch 140 loss: 0.984 r2: -6.309\n",
            "Epoch 150 loss: 0.985 r2: -6.135\n",
            "Epoch 160 loss: 0.985 r2: -5.989\n",
            "Epoch 170 loss: 0.985 r2: -5.868\n",
            "Epoch 180 loss: 0.985 r2: -5.767\n",
            "Epoch 190 loss: 0.985 r2: -5.679\n",
            "Epoch 200 loss: 0.985 r2: -5.602\n",
            "Epoch 210 loss: 0.985 r2: -5.537\n",
            "Epoch 220 loss: 0.984 r2: -5.483\n",
            "Epoch 230 loss: 0.984 r2: -5.438\n",
            "Epoch 240 loss: 0.984 r2: -5.401\n",
            "Epoch 250 loss: 0.983 r2: -5.372\n",
            "Epoch 260 loss: 0.982 r2: -5.348\n",
            "Epoch 270 loss: 0.982 r2: -5.331\n",
            "Epoch 280 loss: 0.981 r2: -5.320\n",
            "Epoch 290 loss: 0.980 r2: -5.315\n",
            "Epoch 300 loss: 0.980 r2: -5.308\n",
            "Epoch 310 loss: 0.979 r2: -5.297\n",
            "Epoch 320 loss: 0.979 r2: -5.286\n",
            "Epoch 330 loss: 0.978 r2: -5.278\n",
            "Epoch 340 loss: 0.978 r2: -5.273\n",
            "Epoch 350 loss: 0.977 r2: -5.272\n",
            "Epoch 360 loss: 0.976 r2: -5.275\n",
            "Epoch 370 loss: 0.976 r2: -5.283\n",
            "Epoch 380 loss: 0.975 r2: -5.295\n",
            "Epoch 390 loss: 0.974 r2: -5.312\n",
            "Epoch 400 loss: 0.973 r2: -5.334\n",
            "Epoch 410 loss: 0.973 r2: -5.359\n",
            "Epoch 420 loss: 0.972 r2: -5.387\n",
            "Epoch 430 loss: 0.971 r2: -5.419\n",
            "Epoch 440 loss: 0.970 r2: -5.460\n",
            "Epoch 450 loss: 0.970 r2: -5.510\n",
            "Epoch 460 loss: 0.969 r2: -5.563\n",
            "Epoch 470 loss: 0.968 r2: -5.622\n",
            "Epoch 480 loss: 0.968 r2: -5.684\n",
            "Epoch 490 loss: 0.967 r2: -5.749\n",
            "Epoch 500 loss: 0.966 r2: -5.817\n",
            "Epoch 510 loss: 0.966 r2: -5.887\n",
            "Epoch 520 loss: 0.965 r2: -5.961\n",
            "Epoch 530 loss: 0.964 r2: -6.038\n",
            "Epoch 540 loss: 0.964 r2: -6.117\n",
            "Epoch 550 loss: 0.964 r2: -6.197\n",
            "Epoch 560 loss: 0.964 r2: -6.275\n",
            "Epoch 570 loss: 0.964 r2: -6.346\n",
            "Epoch 580 loss: 0.964 r2: -6.407\n",
            "Epoch 590 loss: 0.965 r2: -6.471\n",
            "Epoch 600 loss: 0.966 r2: -6.520\n",
            "Epoch 610 loss: 0.968 r2: -6.549\n",
            "Epoch 620 loss: 0.970 r2: -6.555\n",
            "Epoch 630 loss: 0.973 r2: -6.547\n",
            "Epoch 640 loss: 0.977 r2: -6.543\n",
            "Epoch 650 loss: 0.981 r2: -6.587\n",
            "Epoch 660 loss: 0.986 r2: -6.734\n",
            "Epoch 670 loss: 0.989 r2: -7.039\n",
            "Epoch 680 loss: 0.992 r2: -7.522\n",
            "Epoch 690 loss: 0.994 r2: -8.202\n",
            "Epoch 700 loss: 0.995 r2: -9.026\n",
            "Epoch 710 loss: 0.997 r2: -9.980\n",
            "Epoch 720 loss: 0.999 r2: -11.003\n",
            "Epoch 730 loss: 1.000 r2: -12.004\n",
            "Epoch 740 loss: 1.001 r2: -12.922\n",
            "Epoch 750 loss: 1.002 r2: -13.711\n",
            "Epoch 760 loss: 1.003 r2: -14.340\n",
            "Epoch 770 loss: 1.004 r2: -14.800\n",
            "Epoch 780 loss: 1.004 r2: -15.098\n",
            "Epoch 790 loss: 1.005 r2: -15.253\n",
            "Epoch 800 loss: 1.005 r2: -15.280\n",
            "Epoch 810 loss: 1.006 r2: -15.205\n",
            "Epoch 820 loss: 1.006 r2: -15.049\n",
            "Epoch 830 loss: 1.007 r2: -14.823\n",
            "Epoch 840 loss: 1.007 r2: -14.542\n",
            "Epoch 850 loss: 1.008 r2: -14.219\n",
            "Epoch 860 loss: 1.009 r2: -13.863\n",
            "Epoch 870 loss: 1.010 r2: -13.482\n",
            "Epoch 880 loss: 1.010 r2: -13.086\n",
            "Epoch 890 loss: 1.011 r2: -12.629\n",
            "Epoch 900 loss: 1.012 r2: -12.156\n",
            "Epoch 910 loss: 1.013 r2: -11.683\n",
            "Epoch 920 loss: 1.014 r2: -11.221\n",
            "Epoch 930 loss: 1.015 r2: -10.777\n",
            "Epoch 940 loss: 1.016 r2: -10.358\n",
            "Epoch 950 loss: 1.017 r2: -9.966\n",
            "Epoch 960 loss: 1.018 r2: -9.603\n",
            "Epoch 970 loss: 1.019 r2: -9.276\n",
            "Epoch 980 loss: 1.021 r2: -8.985\n",
            "Epoch 990 loss: 1.022 r2: -8.726\n",
            "Weights: [-69.64479565670966, 0.25898483492425733, -11.436443000060917, 15.587907454152163, 26.199952990782258, 63.64354296488914, -0.22458915673819924, 0.1220930498218052]\n",
            "Bias: [-106.012884119956, -73.89946166253385, 0.0424642533213815]\n",
            "Loss for test dataset\n",
            "Test loss: 0.880, r2: -3.489\n",
            "Loss for training dataset\n",
            "Test loss: 1.023, r2: -8.518\n",
            "Epoch 0 loss: 1.037 r2: -7.026\n",
            "Epoch 10 loss: 1.044 r2: -7.418\n",
            "Epoch 20 loss: 1.045 r2: -7.735\n",
            "Epoch 30 loss: 1.044 r2: -7.927\n",
            "Epoch 40 loss: 1.044 r2: -8.064\n",
            "Epoch 50 loss: 1.044 r2: -8.183\n",
            "Epoch 60 loss: 1.043 r2: -8.306\n",
            "Epoch 70 loss: 1.043 r2: -8.446\n",
            "Epoch 80 loss: 1.042 r2: -8.605\n",
            "Epoch 90 loss: 1.042 r2: -8.775\n",
            "Epoch 100 loss: 1.041 r2: -8.955\n",
            "Epoch 110 loss: 1.041 r2: -9.150\n",
            "Epoch 120 loss: 1.040 r2: -9.364\n",
            "Epoch 130 loss: 1.040 r2: -9.591\n",
            "Epoch 140 loss: 1.039 r2: -9.823\n",
            "Epoch 150 loss: 1.038 r2: -10.055\n",
            "Epoch 160 loss: 1.038 r2: -10.282\n",
            "Epoch 170 loss: 1.037 r2: -10.499\n",
            "Epoch 180 loss: 1.037 r2: -10.705\n",
            "Epoch 190 loss: 1.037 r2: -10.899\n",
            "Epoch 200 loss: 1.037 r2: -11.080\n",
            "Epoch 210 loss: 1.037 r2: -11.246\n",
            "Epoch 220 loss: 1.037 r2: -11.398\n",
            "Epoch 230 loss: 1.037 r2: -11.535\n",
            "Epoch 240 loss: 1.037 r2: -11.658\n",
            "Epoch 250 loss: 1.037 r2: -11.769\n",
            "Epoch 260 loss: 1.037 r2: -11.867\n",
            "Epoch 270 loss: 1.037 r2: -12.054\n",
            "Epoch 280 loss: 1.036 r2: -12.346\n",
            "Epoch 290 loss: 1.035 r2: -12.691\n",
            "Epoch 300 loss: 1.035 r2: -13.062\n",
            "Epoch 310 loss: 1.034 r2: -13.446\n",
            "Epoch 320 loss: 1.033 r2: -13.837\n",
            "Epoch 330 loss: 1.032 r2: -14.232\n",
            "Epoch 340 loss: 1.032 r2: -14.629\n",
            "Epoch 350 loss: 1.031 r2: -15.027\n",
            "Epoch 360 loss: 1.031 r2: -15.442\n",
            "Epoch 370 loss: 1.030 r2: -15.869\n",
            "Epoch 380 loss: 1.029 r2: -16.302\n",
            "Epoch 390 loss: 1.029 r2: -16.737\n",
            "Epoch 400 loss: 1.028 r2: -17.173\n",
            "Epoch 410 loss: 1.028 r2: -17.610\n",
            "Epoch 420 loss: 1.027 r2: -18.047\n",
            "Epoch 430 loss: 1.027 r2: -18.485\n",
            "Epoch 440 loss: 1.027 r2: -18.924\n",
            "Epoch 450 loss: 1.026 r2: -19.364\n",
            "Epoch 460 loss: 1.026 r2: -19.804\n",
            "Epoch 470 loss: 1.026 r2: -20.246\n",
            "Epoch 480 loss: 1.025 r2: -20.687\n",
            "Epoch 490 loss: 1.025 r2: -21.128\n",
            "Epoch 500 loss: 1.025 r2: -21.570\n",
            "Epoch 510 loss: 1.024 r2: -22.010\n",
            "Epoch 520 loss: 1.024 r2: -22.449\n",
            "Epoch 530 loss: 1.024 r2: -22.888\n",
            "Epoch 540 loss: 1.024 r2: -23.324\n",
            "Epoch 550 loss: 1.023 r2: -23.759\n",
            "Epoch 560 loss: 1.023 r2: -24.191\n",
            "Epoch 570 loss: 1.023 r2: -24.621\n",
            "Epoch 580 loss: 1.023 r2: -25.048\n",
            "Epoch 590 loss: 1.023 r2: -25.473\n",
            "Epoch 600 loss: 1.022 r2: -25.895\n",
            "Epoch 610 loss: 1.022 r2: -26.313\n",
            "Epoch 620 loss: 1.022 r2: -26.729\n",
            "Epoch 630 loss: 1.022 r2: -27.142\n",
            "Epoch 640 loss: 1.022 r2: -27.552\n",
            "Epoch 650 loss: 1.022 r2: -27.960\n",
            "Epoch 660 loss: 1.022 r2: -28.365\n",
            "Epoch 670 loss: 1.022 r2: -28.768\n",
            "Epoch 680 loss: 1.021 r2: -29.168\n",
            "Epoch 690 loss: 1.021 r2: -29.567\n",
            "Epoch 700 loss: 1.021 r2: -29.963\n",
            "Epoch 710 loss: 1.021 r2: -30.359\n",
            "Epoch 720 loss: 1.021 r2: -30.753\n",
            "Epoch 730 loss: 1.021 r2: -31.146\n",
            "Epoch 740 loss: 1.021 r2: -31.538\n",
            "Epoch 750 loss: 1.021 r2: -31.930\n",
            "Epoch 760 loss: 1.021 r2: -32.321\n",
            "Epoch 770 loss: 1.021 r2: -32.713\n",
            "Epoch 780 loss: 1.021 r2: -33.105\n",
            "Epoch 790 loss: 1.021 r2: -33.497\n",
            "Epoch 800 loss: 1.021 r2: -33.890\n",
            "Epoch 810 loss: 1.020 r2: -34.283\n",
            "Epoch 820 loss: 1.020 r2: -34.677\n",
            "Epoch 830 loss: 1.020 r2: -35.073\n",
            "Epoch 840 loss: 1.020 r2: -35.469\n",
            "Epoch 850 loss: 1.020 r2: -35.866\n",
            "Epoch 860 loss: 1.020 r2: -36.265\n",
            "Epoch 870 loss: 1.020 r2: -36.665\n",
            "Epoch 880 loss: 1.020 r2: -37.066\n",
            "Epoch 890 loss: 1.020 r2: -37.468\n",
            "Epoch 900 loss: 1.020 r2: -37.871\n",
            "Epoch 910 loss: 1.020 r2: -38.276\n",
            "Epoch 920 loss: 1.020 r2: -38.682\n",
            "Epoch 930 loss: 1.020 r2: -39.091\n",
            "Epoch 940 loss: 1.020 r2: -39.502\n",
            "Epoch 950 loss: 1.020 r2: -39.914\n",
            "Epoch 960 loss: 1.020 r2: -40.327\n",
            "Epoch 970 loss: 1.019 r2: -40.746\n",
            "Epoch 980 loss: 1.019 r2: -41.165\n",
            "Epoch 990 loss: 1.019 r2: -41.585\n",
            "Weights: [-97.0673398983904, 1.115451940450877, -13.592109885701003, 27.611393703418717, 39.57195110788588, 104.50044974473026, -0.02317622216747986, 0.06112311702545767]\n",
            "Bias: [-149.72259137138803, -128.31691246092987, 0.05680653485207535]\n",
            "Loss for test dataset\n",
            "Test loss: 0.860, r2: -15.473\n",
            "Loss for training dataset\n",
            "Test loss: 1.019, r2: -41.967\n",
            "Epoch 0 loss: 1.224 r2: -5.482\n",
            "Epoch 10 loss: 1.263 r2: -14.607\n",
            "Epoch 20 loss: 1.272 r2: -14.896\n",
            "Epoch 30 loss: 1.279 r2: -14.999\n",
            "Epoch 40 loss: 1.287 r2: -14.872\n",
            "Epoch 50 loss: 1.295 r2: -14.584\n",
            "Epoch 60 loss: 1.305 r2: -14.214\n",
            "Epoch 70 loss: 1.315 r2: -13.794\n",
            "Epoch 80 loss: 1.325 r2: -13.348\n",
            "Epoch 90 loss: 1.336 r2: -12.890\n",
            "Epoch 100 loss: 1.347 r2: -12.429\n",
            "Epoch 110 loss: 1.358 r2: -11.973\n",
            "Epoch 120 loss: 1.370 r2: -11.527\n",
            "Epoch 130 loss: 1.382 r2: -11.094\n",
            "Epoch 140 loss: 1.394 r2: -10.679\n",
            "Epoch 150 loss: 1.407 r2: -10.280\n",
            "Epoch 160 loss: 1.419 r2: -9.900\n",
            "Epoch 170 loss: 1.432 r2: -9.555\n",
            "Epoch 180 loss: 1.443 r2: -9.246\n",
            "Epoch 190 loss: 1.455 r2: -8.955\n",
            "Epoch 200 loss: 1.466 r2: -8.679\n",
            "Epoch 210 loss: 1.478 r2: -8.419\n",
            "Epoch 220 loss: 1.490 r2: -8.174\n",
            "Epoch 230 loss: 1.501 r2: -7.943\n",
            "Epoch 240 loss: 1.512 r2: -7.725\n",
            "Epoch 250 loss: 1.524 r2: -7.520\n",
            "Epoch 260 loss: 1.535 r2: -7.326\n",
            "Epoch 270 loss: 1.546 r2: -7.146\n",
            "Epoch 280 loss: 1.548 r2: -7.122\n",
            "Epoch 290 loss: 1.546 r2: -7.158\n",
            "Epoch 300 loss: 1.544 r2: -7.195\n",
            "Epoch 310 loss: 1.542 r2: -7.232\n",
            "Epoch 320 loss: 1.540 r2: -7.270\n",
            "Epoch 330 loss: 1.538 r2: -7.309\n",
            "Epoch 340 loss: 1.536 r2: -7.349\n",
            "Epoch 350 loss: 1.534 r2: -7.390\n",
            "Epoch 360 loss: 1.532 r2: -7.436\n",
            "Epoch 370 loss: 1.530 r2: -7.483\n",
            "Epoch 380 loss: 1.528 r2: -7.531\n",
            "Epoch 390 loss: 1.526 r2: -7.580\n",
            "Epoch 400 loss: 1.523 r2: -7.629\n",
            "Epoch 410 loss: 1.521 r2: -7.680\n",
            "Epoch 420 loss: 1.519 r2: -7.731\n",
            "Epoch 430 loss: 1.517 r2: -7.784\n",
            "Epoch 440 loss: 1.514 r2: -7.838\n",
            "Epoch 450 loss: 1.512 r2: -7.893\n",
            "Epoch 460 loss: 1.509 r2: -7.949\n",
            "Epoch 470 loss: 1.507 r2: -8.007\n",
            "Epoch 480 loss: 1.504 r2: -8.065\n",
            "Epoch 490 loss: 1.502 r2: -8.126\n",
            "Epoch 500 loss: 1.499 r2: -8.187\n",
            "Epoch 510 loss: 1.497 r2: -8.250\n",
            "Epoch 520 loss: 1.494 r2: -8.314\n",
            "Epoch 530 loss: 1.492 r2: -8.380\n",
            "Epoch 540 loss: 1.489 r2: -8.448\n",
            "Epoch 550 loss: 1.486 r2: -8.517\n",
            "Epoch 560 loss: 1.484 r2: -8.588\n",
            "Epoch 570 loss: 1.480 r2: -8.678\n",
            "Epoch 580 loss: 1.476 r2: -8.776\n",
            "Epoch 590 loss: 1.473 r2: -8.873\n",
            "Epoch 600 loss: 1.469 r2: -8.972\n",
            "Epoch 610 loss: 1.466 r2: -9.072\n",
            "Epoch 620 loss: 1.462 r2: -9.173\n",
            "Epoch 630 loss: 1.458 r2: -9.275\n",
            "Epoch 640 loss: 1.455 r2: -9.378\n",
            "Epoch 650 loss: 1.452 r2: -9.483\n",
            "Epoch 660 loss: 1.448 r2: -9.591\n",
            "Epoch 670 loss: 1.445 r2: -9.700\n",
            "Epoch 680 loss: 1.441 r2: -9.811\n",
            "Epoch 690 loss: 1.438 r2: -9.925\n",
            "Epoch 700 loss: 1.434 r2: -10.042\n",
            "Epoch 710 loss: 1.431 r2: -10.161\n",
            "Epoch 720 loss: 1.427 r2: -10.283\n",
            "Epoch 730 loss: 1.424 r2: -10.407\n",
            "Epoch 740 loss: 1.421 r2: -10.536\n",
            "Epoch 750 loss: 1.417 r2: -10.667\n",
            "Epoch 760 loss: 1.414 r2: -10.802\n",
            "Epoch 770 loss: 1.410 r2: -10.940\n",
            "Epoch 780 loss: 1.407 r2: -11.083\n",
            "Epoch 790 loss: 1.403 r2: -11.229\n",
            "Epoch 800 loss: 1.399 r2: -11.380\n",
            "Epoch 810 loss: 1.396 r2: -11.536\n",
            "Epoch 820 loss: 1.392 r2: -11.696\n",
            "Epoch 830 loss: 1.389 r2: -11.861\n",
            "Epoch 840 loss: 1.385 r2: -12.031\n",
            "Epoch 850 loss: 1.381 r2: -12.206\n",
            "Epoch 860 loss: 1.378 r2: -12.387\n",
            "Epoch 870 loss: 1.374 r2: -12.574\n",
            "Epoch 880 loss: 1.370 r2: -12.767\n",
            "Epoch 890 loss: 1.367 r2: -12.966\n",
            "Epoch 900 loss: 1.363 r2: -13.172\n",
            "Epoch 910 loss: 1.359 r2: -13.385\n",
            "Epoch 920 loss: 1.355 r2: -13.605\n",
            "Epoch 930 loss: 1.352 r2: -13.832\n",
            "Epoch 940 loss: 1.348 r2: -14.067\n",
            "Epoch 950 loss: 1.344 r2: -14.311\n",
            "Epoch 960 loss: 1.340 r2: -14.563\n",
            "Epoch 970 loss: 1.336 r2: -14.824\n",
            "Epoch 980 loss: 1.333 r2: -15.093\n",
            "Epoch 990 loss: 1.329 r2: -15.372\n",
            "Weights: [-125.74299466152051, 1.4371254560235163, -11.721375055926678, 39.19291943318098, 52.40698676663008, 141.08593309823144, 0.11347764578262713, 0.01925293925543116]\n",
            "Bias: [-186.4330492444356, -177.03526252166418, 0.06822905194309084]\n",
            "Loss for test dataset\n",
            "Test loss: 1.139, r2: -14.676\n",
            "Loss for training dataset\n",
            "Test loss: 1.325, r2: -15.632\n",
            "Epoch 0 loss: 1.487 r2: -7.894\n",
            "Epoch 10 loss: 1.413 r2: -10.763\n",
            "Epoch 20 loss: 1.396 r2: -11.600\n",
            "Epoch 30 loss: 1.381 r2: -12.387\n",
            "Epoch 40 loss: 1.366 r2: -13.195\n",
            "Epoch 50 loss: 1.353 r2: -14.050\n",
            "Epoch 60 loss: 1.340 r2: -14.953\n",
            "Epoch 70 loss: 1.328 r2: -15.903\n",
            "Epoch 80 loss: 1.317 r2: -16.857\n",
            "Epoch 90 loss: 1.311 r2: -17.370\n",
            "Epoch 100 loss: 1.308 r2: -18.165\n",
            "Epoch 110 loss: 1.300 r2: -18.388\n",
            "Epoch 120 loss: 1.292 r2: -19.265\n",
            "Epoch 130 loss: 1.290 r2: -19.412\n",
            "Epoch 140 loss: 1.283 r2: -20.301\n",
            "Epoch 150 loss: 1.280 r2: -20.515\n",
            "Epoch 160 loss: 1.276 r2: -21.370\n",
            "Epoch 170 loss: 1.273 r2: -21.428\n",
            "Epoch 180 loss: 1.274 r2: -22.185\n",
            "Epoch 190 loss: 1.266 r2: -22.299\n",
            "Epoch 200 loss: 1.260 r2: -22.984\n",
            "Epoch 210 loss: 1.261 r2: -23.396\n",
            "Epoch 220 loss: 1.258 r2: -23.449\n",
            "Epoch 230 loss: 1.257 r2: -23.482\n",
            "Epoch 240 loss: 1.254 r2: -24.485\n",
            "Epoch 250 loss: 1.251 r2: -24.478\n",
            "Epoch 260 loss: 1.251 r2: -24.538\n",
            "Epoch 270 loss: 1.249 r2: -24.861\n",
            "Epoch 280 loss: 1.252 r2: -25.222\n",
            "Epoch 290 loss: 1.243 r2: -25.667\n",
            "Epoch 300 loss: 1.243 r2: -26.526\n",
            "Epoch 310 loss: 1.241 r2: -25.841\n",
            "Epoch 320 loss: 1.231 r2: -27.881\n",
            "Epoch 330 loss: 1.228 r2: -28.409\n",
            "Epoch 340 loss: 1.223 r2: -29.370\n",
            "Epoch 350 loss: 1.214 r2: -32.865\n",
            "Epoch 360 loss: 1.202 r2: -35.278\n",
            "Epoch 370 loss: 1.193 r2: -38.192\n",
            "Epoch 380 loss: 1.184 r2: -41.763\n",
            "Epoch 390 loss: 1.183 r2: -42.056\n",
            "Epoch 400 loss: 1.164 r2: -52.023\n",
            "Epoch 410 loss: 1.163 r2: -51.459\n",
            "Epoch 420 loss: 1.142 r2: -69.977\n",
            "Epoch 430 loss: 1.143 r2: -62.007\n",
            "Epoch 440 loss: 1.181 r2: -42.937\n",
            "Epoch 450 loss: 1.180 r2: -43.523\n",
            "Epoch 460 loss: 1.187 r2: -40.397\n",
            "Epoch 470 loss: 1.238 r2: -27.142\n",
            "Epoch 480 loss: 1.247 r2: -25.722\n",
            "Epoch 490 loss: 1.249 r2: -25.316\n",
            "Epoch 500 loss: 1.252 r2: -24.823\n",
            "Epoch 510 loss: 1.252 r2: -24.732\n",
            "Epoch 520 loss: 1.251 r2: -24.905\n",
            "Epoch 530 loss: 1.249 r2: -25.140\n",
            "Epoch 540 loss: 1.248 r2: -25.384\n",
            "Epoch 550 loss: 1.246 r2: -25.634\n",
            "Epoch 560 loss: 1.245 r2: -25.885\n",
            "Epoch 570 loss: 1.243 r2: -26.134\n",
            "Epoch 580 loss: 1.242 r2: -26.381\n",
            "Epoch 590 loss: 1.241 r2: -26.625\n",
            "Epoch 600 loss: 1.239 r2: -26.866\n",
            "Epoch 610 loss: 1.238 r2: -27.104\n",
            "Epoch 620 loss: 1.237 r2: -27.340\n",
            "Epoch 630 loss: 1.236 r2: -27.573\n",
            "Epoch 640 loss: 1.234 r2: -27.804\n",
            "Epoch 650 loss: 1.233 r2: -28.032\n",
            "Epoch 660 loss: 1.232 r2: -28.257\n",
            "Epoch 670 loss: 1.231 r2: -28.480\n",
            "Epoch 680 loss: 1.230 r2: -28.701\n",
            "Epoch 690 loss: 1.229 r2: -28.919\n",
            "Epoch 700 loss: 1.228 r2: -29.134\n",
            "Epoch 710 loss: 1.227 r2: -29.347\n",
            "Epoch 720 loss: 1.226 r2: -29.558\n",
            "Epoch 730 loss: 1.225 r2: -29.767\n",
            "Epoch 740 loss: 1.224 r2: -29.973\n",
            "Epoch 750 loss: 1.223 r2: -30.176\n",
            "Epoch 760 loss: 1.222 r2: -30.378\n",
            "Epoch 770 loss: 1.221 r2: -30.577\n",
            "Epoch 780 loss: 1.221 r2: -30.774\n",
            "Epoch 790 loss: 1.220 r2: -30.969\n",
            "Epoch 800 loss: 1.219 r2: -31.162\n",
            "Epoch 810 loss: 1.218 r2: -31.353\n",
            "Epoch 820 loss: 1.217 r2: -31.541\n",
            "Epoch 830 loss: 1.217 r2: -31.728\n",
            "Epoch 840 loss: 1.216 r2: -31.913\n",
            "Epoch 850 loss: 1.215 r2: -32.096\n",
            "Epoch 860 loss: 1.214 r2: -32.276\n",
            "Epoch 870 loss: 1.214 r2: -32.456\n",
            "Epoch 880 loss: 1.213 r2: -32.633\n",
            "Epoch 890 loss: 1.212 r2: -32.808\n",
            "Epoch 900 loss: 1.212 r2: -32.982\n",
            "Epoch 910 loss: 1.211 r2: -33.154\n",
            "Epoch 920 loss: 1.210 r2: -33.325\n",
            "Epoch 930 loss: 1.210 r2: -33.494\n",
            "Epoch 940 loss: 1.209 r2: -33.661\n",
            "Epoch 950 loss: 1.209 r2: -33.827\n",
            "Epoch 960 loss: 1.208 r2: -33.992\n",
            "Epoch 970 loss: 1.207 r2: -34.155\n",
            "Epoch 980 loss: 1.207 r2: -34.316\n",
            "Epoch 990 loss: 1.206 r2: -34.476\n",
            "Weights: [-171.05781966510366, 2.5874348490268524, -8.302626518427136, 39.884269649351594, 26.979571179518857, 138.6526954900655, 0.0674923470347673, 0.08560714554119914]\n",
            "Bias: [-240.24162701684617, -200.03929153311304, 0.08856298069443287]\n",
            "Loss for test dataset\n",
            "Test loss: 1.072, r2: -25.052\n",
            "Loss for training dataset\n",
            "Test loss: 1.206, r2: -34.620\n",
            "Epoch 0 loss: 1.361 r2: -13.015\n",
            "Epoch 10 loss: 1.254 r2: -23.373\n",
            "Epoch 20 loss: 1.223 r2: -29.853\n",
            "Epoch 30 loss: 1.209 r2: -33.740\n",
            "Epoch 40 loss: 1.203 r2: -35.644\n",
            "Epoch 50 loss: 1.198 r2: -37.132\n",
            "Epoch 60 loss: 1.195 r2: -38.334\n",
            "Epoch 70 loss: 1.192 r2: -39.283\n",
            "Epoch 80 loss: 1.190 r2: -40.087\n",
            "Epoch 90 loss: 1.188 r2: -40.833\n",
            "Epoch 100 loss: 1.186 r2: -41.564\n",
            "Epoch 110 loss: 1.184 r2: -42.301\n",
            "Epoch 120 loss: 1.182 r2: -43.052\n",
            "Epoch 130 loss: 1.181 r2: -43.801\n",
            "Epoch 140 loss: 1.179 r2: -44.560\n",
            "Epoch 150 loss: 1.177 r2: -45.337\n",
            "Epoch 160 loss: 1.175 r2: -46.141\n",
            "Epoch 170 loss: 1.174 r2: -46.975\n",
            "Epoch 180 loss: 1.172 r2: -47.844\n",
            "Epoch 190 loss: 1.170 r2: -48.753\n",
            "Epoch 200 loss: 1.168 r2: -49.705\n",
            "Epoch 210 loss: 1.166 r2: -50.705\n",
            "Epoch 220 loss: 1.164 r2: -51.759\n",
            "Epoch 230 loss: 1.163 r2: -52.871\n",
            "Epoch 240 loss: 1.161 r2: -54.050\n",
            "Epoch 250 loss: 1.159 r2: -55.303\n",
            "Epoch 260 loss: 1.156 r2: -56.638\n",
            "Epoch 270 loss: 1.154 r2: -58.065\n",
            "Epoch 280 loss: 1.152 r2: -59.597\n",
            "Epoch 290 loss: 1.150 r2: -61.246\n",
            "Epoch 300 loss: 1.147 r2: -63.030\n",
            "Epoch 310 loss: 1.145 r2: -64.965\n",
            "Epoch 320 loss: 1.142 r2: -67.075\n",
            "Epoch 330 loss: 1.140 r2: -69.386\n",
            "Epoch 340 loss: 1.137 r2: -71.947\n",
            "Epoch 350 loss: 1.135 r2: -73.907\n",
            "Epoch 360 loss: 1.131 r2: -78.842\n",
            "Epoch 370 loss: 1.126 r2: -86.170\n",
            "Epoch 380 loss: 1.121 r2: -93.688\n",
            "Epoch 390 loss: 1.117 r2: -100.571\n",
            "Epoch 400 loss: 1.113 r2: -106.508\n",
            "Epoch 410 loss: 1.109 r2: -111.317\n",
            "Epoch 420 loss: 1.106 r2: -114.283\n",
            "Epoch 430 loss: 1.104 r2: -114.216\n",
            "Epoch 440 loss: 1.102 r2: -109.300\n",
            "Epoch 450 loss: 1.100 r2: -97.348\n",
            "Epoch 460 loss: 1.101 r2: -77.511\n",
            "Epoch 470 loss: 1.105 r2: -52.778\n",
            "Epoch 480 loss: 1.113 r2: -29.314\n",
            "Epoch 490 loss: 1.139 r2: -13.794\n",
            "Epoch 500 loss: 2.451 r2: -0.867\n",
            "Epoch 510 loss: 1.017 r2: -2117.538\n",
            "Epoch 520 loss: 1.017 r2: -2124.211\n",
            "Epoch 530 loss: 1.017 r2: -2276.874\n",
            "Epoch 540 loss: 1.017 r2: -2643.852\n",
            "Epoch 550 loss: 1.016 r2: -1905.008\n",
            "Epoch 560 loss: 1.016 r2: -2103.892\n",
            "Epoch 570 loss: 1.016 r2: -1975.738\n",
            "Epoch 580 loss: 1.016 r2: -1947.185\n",
            "Epoch 590 loss: 1.016 r2: -1937.093\n",
            "Epoch 600 loss: 1.016 r2: -1933.336\n",
            "Epoch 610 loss: 1.016 r2: -1926.507\n",
            "Epoch 620 loss: 1.022 r2: -6342.575\n",
            "Epoch 630 loss: 1.021 r2: -1487.095\n",
            "Epoch 640 loss: 1.021 r2: -598.944\n",
            "Epoch 650 loss: 1.023 r2: -218.099\n",
            "Epoch 660 loss: 1.023 r2: -618.219\n",
            "Epoch 670 loss: 1.023 r2: -756.659\n",
            "Epoch 680 loss: 1.023 r2: -821.348\n",
            "Epoch 690 loss: 1.023 r2: -755.830\n",
            "Epoch 700 loss: 1.023 r2: -754.846\n",
            "Epoch 710 loss: 1.022 r2: -704.259\n",
            "Epoch 720 loss: 1.022 r2: -381.384\n",
            "Epoch 730 loss: 1.118 r2: -8.664\n",
            "Epoch 740 loss: 1.021 r2: -759.275\n",
            "Epoch 750 loss: 1.022 r2: -755.834\n",
            "Epoch 760 loss: 1.022 r2: -761.456\n",
            "Epoch 770 loss: 1.022 r2: -810.690\n",
            "Epoch 780 loss: 1.022 r2: -1590.843\n",
            "Epoch 790 loss: 1.022 r2: -1315555.813\n",
            "Epoch 800 loss: 1.022 r2: -849.633\n",
            "Epoch 810 loss: 1.021 r2: -766.834\n",
            "Epoch 820 loss: 1.021 r2: -800.519\n",
            "Epoch 830 loss: 1.021 r2: -1066.449\n",
            "Epoch 840 loss: 1.022 r2: -556209.705\n",
            "Epoch 850 loss: 1.022 r2: -12470.325\n",
            "Epoch 860 loss: 1.021 r2: -770.796\n",
            "Epoch 870 loss: 1.021 r2: -791.089\n",
            "Epoch 880 loss: 1.021 r2: -933.190\n",
            "Epoch 890 loss: 1.022 r2: -389751.762\n",
            "Epoch 900 loss: 1.022 r2: -106355292.585\n",
            "Epoch 910 loss: 1.021 r2: -775.858\n",
            "Epoch 920 loss: 1.021 r2: -781.818\n",
            "Epoch 930 loss: 1.021 r2: -865.978\n",
            "Epoch 940 loss: 1.022 r2: -3602.180\n",
            "Epoch 950 loss: 1.021 r2: 0.000\n",
            "Epoch 960 loss: 1.022 r2: -803.186\n",
            "Epoch 970 loss: 1.022 r2: -775.612\n",
            "Epoch 980 loss: 1.021 r2: -827.986\n",
            "Epoch 990 loss: 1.022 r2: -1492.340\n",
            "Weights: [-121.47199006718134, 79.18131876582945, 71.14752327046699, 66.57714774559291, 34.86219996753408, 129.76306076430023, 0.2833234128819244, 0.11374004544347299]\n",
            "Bias: [-290.6717128521856, -221.08417905157293, 0.05541510045423873]\n",
            "Loss for test dataset\n",
            "Test loss: 10.926, r2: -0.168\n",
            "Loss for training dataset\n",
            "Test loss: 1.050, r2: -24.375\n"
          ]
        }
      ]
    }
  ]
}